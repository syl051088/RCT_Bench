---
title: "RCT_analysis"
author: "Yulin Shao"
date: "2025-06-02"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rio)
library(janitor)
library(readxl)
library(striprtf)
library(stringr)
library(tibble)
library(tidyr)
library(stringi)
library(haven)
library(purrr)
library(DescTools)
library(RobinCar)
library(ggplot2)
library(writexl)
library(kableExtra)
library(scales)
library(AIPW)
library(PSweight)
library(patchwork)
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
```

# Load Meta Data

```{r load meta data}
df_comparison = read_xlsx("cleaned_data/meta_data_comparison.xlsx")
df_meta = read_xlsx("cleaned_data/meta_data.xlsx")
df_newcomp = df_comparison
```

# Load Trial Data
```{r load_trial_data}
# Trial datasets
df1 = read_rds("cleaned_data/Non_Clustered_RCT/trial1.rds")
df2 = read_rds("cleaned_data/Non_Clustered_RCT/trial2.rds")
df2 = df2 %>% select(-YP_early_7d, -YP_late_12d)
df3 = read_rds("cleaned_data/Non_Clustered_RCT/trial3.rds")
df4 = read_rds("cleaned_data/Non_Clustered_RCT/trial4.rds")
df5 = read_rds("cleaned_data/Non_Clustered_RCT/trial5.rds")
df6 = read_rds("cleaned_data/Non_Clustered_RCT/trial6.rds")
df7 = read_rds("cleaned_data/Non_Clustered_RCT/trial7.rds")
df8 = read_rds("cleaned_data/Non_Clustered_RCT/trial8.rds")
df9 = read_rds("cleaned_data/Non_Clustered_RCT/trial9.rds")
df10 = read_rds("cleaned_data/Non_Clustered_RCT/trial10.rds")
df11 = read_rds("cleaned_data/Non_Clustered_RCT/trial11.rds")
df12 = read_rds("cleaned_data/Non_Clustered_RCT/trial12.rds")
df13 = read_rds("cleaned_data/Non_Clustered_RCT/trial13.rds")
df14 = read_rds("cleaned_data/Non_Clustered_RCT/trial14.rds")
df15 = read_rds("cleaned_data/Non_Clustered_RCT/trial15.rds")
df16 = read_rds("cleaned_data/Non_Clustered_RCT/trial16.rds")
df17 = read_rds("cleaned_data/Non_Clustered_RCT/trial17.rds")
df18 = read_rds("cleaned_data/Non_Clustered_RCT/trial18.rds") %>% 
  select(-YP_event_disengaged_12m)
df19 = read_rds("cleaned_data/Non_Clustered_RCT/trial19.rds")
df20 = read_rds("cleaned_data/Non_Clustered_RCT/trial20.rds")
df21 = read_rds("cleaned_data/Non_Clustered_RCT/trial21.rds") %>% 
  select(-YP_tb_treatment_initiation)
df22 = read_rds("cleaned_data/Non_Clustered_RCT/trial22.rds")
df23 = read_rds("cleaned_data/Non_Clustered_RCT/trial23.rds") %>% 
  select(-YP_event_28d, -YP_event_90d)
df24 = read_rds("cleaned_data/Non_Clustered_RCT/trial24.rds")
df25 = read_rds("cleaned_data/Non_Clustered_RCT/trial25.rds")
df26 = read_rds("cleaned_data/Non_Clustered_RCT/trial26.rds")
df27 = read_rds("cleaned_data/Non_Clustered_RCT/trial27.rds")
df28 = read_rds("cleaned_data/Non_Clustered_RCT/trial28.rds")
df29 = read_rds("cleaned_data/Non_Clustered_RCT/trial29.rds") %>% 
  select(-YP_death)
df30 = read_rds("cleaned_data/Non_Clustered_RCT/trial30.rds")
df31 = read_rds("cleaned_data/Non_Clustered_RCT/trial31.rds") %>% 
  select(-YP_flu_infection)
df32 = read_rds("cleaned_data/Non_Clustered_RCT/trial32.rds")
df33 = read_rds("cleaned_data/Non_Clustered_RCT/trial33.rds")
df34 = read_rds("cleaned_data/Non_Clustered_RCT/trial34.rds")
df35 = read_rds("cleaned_data/Non_Clustered_RCT/trial35.rds")
df36 = read_rds("cleaned_data/Non_Clustered_RCT/trial36.rds")
df37 = read_rds("cleaned_data/Non_Clustered_RCT/trial37.rds")
df38 = read_rds("cleaned_data/Non_Clustered_RCT/trial38.rds") %>% 
  select(-YP_event_flag)
df39 = read_rds("cleaned_data/Non_Clustered_RCT/trial39.rds") %>% 
  select(-YP_event_flag)
df40 = read_rds("cleaned_data/Non_Clustered_RCT/trial40.rds") %>% 
  select(-YP_success_flag,  -YS_attempt1_time, -YS_attempt2_time, -YS_attempt3_time,
         -YS_attempt1_success, -YS_attempt2_success, -YS_attempt3_success, -YS_attempt2_assigned,-YS_attempt3_assigned)
df41 = read_rds("cleaned_data/Non_Clustered_RCT/trial41.rds")
df42 = read_rds("cleaned_data/Non_Clustered_RCT/trial42.rds") %>% 
  select(-YP_onset_sensory_censor, -YS_med_duration, -YS_med_duration_censor)
df43 = read_rds("cleaned_data/Non_Clustered_RCT/trial43.rds") %>% 
  select(-YP_preterm_flag)
df44 = read_rds("cleaned_data/Non_Clustered_RCT/trial44.rds")
df45 = read_rds("cleaned_data/Non_Clustered_RCT/trial45.rds") %>% 
  select(-YS_delta_icedtea_24w, -YS_delta_alcohol_24w, -YS_delta_salty_24w,
         -YS_delta_fats_24w, -YS_delta_ldl_24w, -YS_delta_tg_24w, -YS_delta_hba1c_24w)
df46 = read_rds("cleaned_data/Non_Clustered_RCT/trial46.rds")
df47 = read_rds("cleaned_data/Non_Clustered_RCT/trial47.rds")
df48 = read_rds("cleaned_data/Non_Clustered_RCT/trial48.rds")
df49 = read_rds("cleaned_data/Non_Clustered_RCT/trial49.rds") %>% 
  select(-YS_t_sondad, -YS_full_oral)
df50 = read_rds("cleaned_data/Non_Clustered_RCT/trial50.rds") %>% 
  select(-YP_first_infection_event)
```

# Function

## variable_selection_correlation()
```{r}
variable_selection_correlation = function(outcome, valid_covariates, df_complete_numeric, n_select = 3) {
  if (length(valid_covariates) > n_select) {
    # Get correlations between this outcome and ALL covariates (convert factors to numeric temporarily)
    cov_values = numeric(length(valid_covariates))
    names(cov_values) = valid_covariates
    
    for (cov in valid_covariates) {
      # Convert covariate to numeric temporarily for correlation computation
      cov_numeric = as.numeric(df_complete_numeric[[cov]])
      cov_values[cov] = cor(df_complete_numeric[[outcome]], cov_numeric, use = "complete.obs")
    }
    
    # Select top n_select by absolute correlation magnitude
    top_idx = order(abs(cov_values), decreasing = TRUE)[1:n_select]
    selected_covariates = valid_covariates[top_idx]
    return(selected_covariates)
  }
  # If ≤n_select valid covariates, use all of them
  return(valid_covariates)
}
```

## variable_selection_manual()
```{r}
variable_selection_manual = function(outcome, valid_covariates, manual_covariates = NULL) {
  # Step 1: Look for baseline measures of the outcome
  baseline_var = NULL
  
  # Extract outcome pattern and timing
  if (startsWith(outcome, "YP_")) {
    # For YP outcomes: YP_abc_7w -> look for X_abc_0w
    # For YP_delta outcomes: YP_delta_abc_7w -> look for X_abc_0w (skip "delta")
    outcome_parts = strsplit(outcome, "_")[[1]]
    if (length(outcome_parts) >= 3) {
      # Check if this is a delta outcome
      if (outcome_parts[2] == "delta") {
        # For YP_delta_abc_7w, extract from position 3 onwards (excluding last part which is timing)
        if (length(outcome_parts) >= 4) {
          middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
          baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
        }
      } else {
        # For regular YP_abc_7w, extract the middle part(s) and construct baseline variable name
        middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
        baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
      }
      
      # Look for variables that start with this pattern (case-insensitive)
      if (exists("baseline_pattern")) {
        # Case-insensitive search using grepl
        pattern_regex = paste0("^", gsub("_", "_", baseline_pattern, fixed = TRUE))
        potential_baseline = valid_covariates[grepl(pattern_regex, valid_covariates, ignore.case = TRUE)]
        if (length(potential_baseline) > 0) {
          baseline_var = potential_baseline[1]  # Take the first match
          cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
        }
      }
    }
  } else if (startsWith(outcome, "YS_")) {
    # For YS outcomes: YS_qwe_8m -> look for X_qwe_0m
    # For YS_delta outcomes: YS_delta_qwe_8m -> look for X_qwe_0m (skip "delta")
    outcome_parts = strsplit(outcome, "_")[[1]]
    if (length(outcome_parts) >= 3) {
      # Check if this is a delta outcome
      if (outcome_parts[2] == "delta") {
        # For YS_delta_qwe_8m, extract from position 3 onwards (excluding last part which is timing)
        if (length(outcome_parts) >= 4) {
          middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
          baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
        }
      } else {
        # For regular YS_qwe_8m, extract the middle part(s) and construct baseline variable name
        middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
        baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
      }
      
      # Look for variables that start with this pattern (case-insensitive)
      if (exists("baseline_pattern")) {
        # Case-insensitive search using grepl
        pattern_regex = paste0("^", gsub("_", "_", baseline_pattern, fixed = TRUE))
        potential_baseline = valid_covariates[grepl(pattern_regex, valid_covariates, ignore.case = TRUE)]
        if (length(potential_baseline) > 0) {
          baseline_var = potential_baseline[1]  # Take the first match
          cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
        }
      }
    }
  }
  
  # Combine baseline variable with manual covariates
  selected_covariates = character(0)
  
  # Add baseline variable if foundíxs
  if (!is.null(baseline_var)) {
    selected_covariates = c(selected_covariates, baseline_var)
  }
  
  # Add manual covariates if provided
  if (!is.null(manual_covariates)) {
    # Filter manual covariates to only include those that exist in valid_covariates
    manual_available = manual_covariates[manual_covariates %in% valid_covariates]
    selected_covariates = c(selected_covariates, manual_available)
  }
  
  # Remove duplicates
  selected_covariates = unique(selected_covariates)
  
  return(selected_covariates)
}
```


## analyze_rct_sl()

```{r}
analyze_rct_sl = function(data,
                          treatment_col  = "Treatment",
                          outcome_cols,
                          covariate_cols,
                          reference_arm  = NULL,
                          K              = 5,
                          SL_methods     = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                          n_cores        = parallel::detectCores() - 2) {
  require(dplyr)
  require(SuperLearner)
  require(foreach)
  require(doSNOW)
  require(doRNG)
  
  n  = nrow(data)
  
  ## ── set up inner cluster ────────────────────────────────────────────────
  cl = makeCluster(n_cores)
  registerDoSNOW(cl)
  registerDoRNG()
  on.exit(stopCluster(cl), add = TRUE)
  
  arms = levels(data[[treatment_col]])
  if (is.null(reference_arm))
    reference_arm = arms[1]
  if (!(reference_arm %in% arms))
    stop("reference_arm must be one of: ", paste(arms, collapse = ", "))
  
  pi_tab = prop.table(table(data[[treatment_col]]))
  
  ## CV splits — handle K = 1 specially
  if (K == 1) {
    splits = list(seq_len(n))
  } else {
    split_ix = sample(rep(1:K, length.out = n))
    splits   = split(seq_len(n), split_ix)
  }
  
  combos = expand.grid(
    Outcome   = outcome_cols,
    Treatment = setdiff(arms, reference_arm),
    stringsAsFactors = FALSE
  )
  
  results = foreach(
    i = seq_len(nrow(combos)),
    .combine = dplyr::bind_rows,
    .packages = c("dplyr", "SuperLearner")
  ) %dopar% {
    Y   = combos$Outcome[i]
    arm = combos$Treatment[i]
    pair_arms = c(reference_arm, arm)
    pi_pair   = pi_tab[pair_arms]
    
    ## matrix to hold EIF contributions for all n rows
    full_preds = matrix(
      NA_real_,
      nrow = n,
      ncol = 2,
      dimnames = list(NULL, pair_arms)
    )
    
    for (k in seq_along(splits)) {
      val_ix   = splits[[k]]
      train_ix = if (K == 1)
        val_ix
      else
        setdiff(seq_len(n), val_ix)
      
      for (a in pair_arms) {
        sel_tr = train_ix[data[[treatment_col]][train_ix] == a]
        
        # Ensure data frames with proper column names
        X_train = as.data.frame(data[sel_tr, covariate_cols, drop = FALSE])
        X_val = as.data.frame(data[val_ix, covariate_cols, drop = FALSE])
        colnames(X_train) = covariate_cols
        colnames(X_val) = covariate_cols
        
        fit = SuperLearner(
          Y          = data[[Y]][sel_tr],
          X          = X_train,
          newX       = X_val,
          family     = gaussian(),
          cvControl  = list(V = min(10, length(sel_tr))),
          SL.library = SL_methods
        )
        
        eta_hat = fit$SL.predict
        A_k     = as.integer(data[[treatment_col]][val_ix] == a)
        full_preds[val_ix, a] =
          A_k / pi_pair[a] * (data[[Y]][val_ix] - eta_hat) + eta_hat
      }
    }
    
    D_i = full_preds[, arm] - full_preds[, reference_arm]
    tibble(
      Outcome   = Y,
      Treatment = arm,
      Control   = reference_arm,
      Est_SL    = mean(D_i),
      SE_SL     = sqrt(var(D_i) / n)
    )
  }
  
  results
}
```


## analyze_rct_dml()

```{r}
analyze_rct_dml = function(df,
                       selection = FALSE,
                       variable_selection_type = 1,  # 1: correlation, 2: manual
                       manual_covariates = NULL,
                       run_individual_SL = TRUE,
                       run_ensemble_SL = TRUE,
                       SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                       n_cores = parallel::detectCores() - 2,
                       seed = 123,
                       outcome_cols = NULL,
                       covariate_col = NULL,
                       treatment_col = "Treatment",
                       K = 5,
                       n_select = 3) {
  require(dplyr)
  require(RobinCar)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection based on type
    if (selection && length(valid_covariates) > 0) {
      if (variable_selection_type == 1) {
        # Correlation-based selection
        selected_covariates = variable_selection_correlation(outcome, valid_covariates, df_complete_numeric, n_select)
      } else if (variable_selection_type == 2) {
        # Manual + baseline selection
        selected_covariates = variable_selection_manual(outcome, valid_covariates, manual_covariates)
        
        # Check if we have any covariates to work with for manual selection
        if (length(selected_covariates) == 0) {
          cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
          
          # Create results with NA values
          treatment_levels = levels(df_complete[[treatment_col]])[-1]  # Exclude control
          n_treat = length(treatment_levels)
          
          # Base tibble with core columns
          outcome_results = tibble(
            Outcome = rep(outcome, n_treat),
            Treatment = treatment_levels,
            Control = rep(control_level, n_treat),
            N = rep(nrow(df_complete), n_treat),
            N_Covariates = rep(0, n_treat),
            Selected_Covariates = rep("", n_treat),
            # Set all estimates and SEs to NA
            Est_UN = rep(NA_real_, n_treat),
            SE_UN = rep(NA_real_, n_treat),
            Est_AC = rep(NA_real_, n_treat),
            SE_AC = rep(NA_real_, n_treat),
            Est_RC_ANCOVA = rep(NA_real_, n_treat),
            SE_RC_ANCOVA = rep(NA_real_, n_treat),
            Est_RC_ANHECOVA = rep(NA_real_, n_treat),
            SE_RC_ANHECOVA = rep(NA_real_, n_treat),
            Est_RC_Logistic_G_Computation = rep(NA_real_, n_treat),
            SE_RC_Logistic_G_Computation = rep(NA_real_, n_treat),
            Est_SL = rep(NA_real_, n_treat),
            SE_SL = rep(NA_real_, n_treat)
          )
          
          # Add individual SL method columns based on what's in SL_methods (excluding SL.glm and SL.mean)
          individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
          for (method in individual_methods) {
            method_clean = gsub("SL\\.", "SL_", method)
            outcome_results[[paste0("Est_", method_clean)]] = rep(NA_real_, n_treat)
            outcome_results[[paste0("SE_", method_clean)]] = rep(NA_real_, n_treat)
          }
          
          valid_outcomes = c(valid_outcomes, outcome)
          all_results[[length(valid_outcomes)]] = outcome_results
          next
        }
      }
      
      # Use the selected covariates
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }
    
    # Fit traditional models (using numeric version)
    coef_unadj = coef(summary(lm(
      reformulate(treatment_col, outcome), df_complete_numeric
    )))
    coef_ancova = coef(summary(lm(
      reformulate(c(treatment_col, valid_covariates), outcome), df_complete_numeric
    )))
    
    # Extract treatment effects
    treat_idx_unadj = which(startsWith(rownames(coef_unadj), treatment_col))
    treat_idx_ancova = which(startsWith(rownames(coef_ancova), treatment_col))
    
    # Create results for this outcome
    n_treat = length(treat_idx_unadj)
    treatment_levels = sub(treat_pattern, "", rownames(coef_unadj)[treat_idx_unadj])
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat),
      # Unadjusted
      Est_UN = coef_unadj[treat_idx_unadj, 1],
      SE_UN = coef_unadj[treat_idx_unadj, 2],
      # ANCOVA
      Est_AC = coef_ancova[treat_idx_ancova, 1],
      SE_AC = coef_ancova[treat_idx_ancova, 2]
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # RobinCar - run both ANCOVA and ANHECOVA (using numeric version)
    rc_fit_ancova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANCOVA",
        contrast_h = "diff"
      )
    )
    rc_result_ancova = rc_fit_ancova$contrast$result
    outcome_results$Est_RC_ANCOVA = rc_result_ancova$estimate
    outcome_results$SE_RC_ANCOVA = rc_result_ancova$se
    
    rc_fit_anhecova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANHECOVA",
        contrast_h = "diff"
      )
    )
    rc_result_anhecova = rc_fit_anhecova$contrast$result
    outcome_results$Est_RC_ANHECOVA = rc_result_anhecova$estimate
    outcome_results$SE_RC_ANHECOVA = rc_result_anhecova$se
    
    # RobinCar GLM for binary outcomes
    if (is_binary) {
      # Create formula for GLM: outcome ~ Treatment + covariates
      formula_terms = c(treatment_col, valid_covariates)
      glm_formula = as.formula(paste(outcome, "~", paste(formula_terms, collapse = " + ")))
      
      rc_fit_logistic_g_computation = suppressWarnings(
        robincar_glm(
          df_complete_numeric,  # Use numeric version (0,1 for binary outcome)
          treatment_col,
          outcome,
          formula = glm_formula,
          g_family = stats::binomial,
          contrast_h = "diff"
        )
      )
      rc_result_logistic_g_computation = rc_fit_logistic_g_computation$contrast$result
      outcome_results$Est_RC_Logistic_G_Computation = rc_result_logistic_g_computation$estimate
      outcome_results$SE_RC_Logistic_G_Computation = rc_result_logistic_g_computation$se
    } else {
      # For non-binary outcomes, set Logistic G-Computation results to NA
      outcome_results$Est_RC_Logistic_G_Computation = rep(NA_real_, n_treat)
      outcome_results$SE_RC_Logistic_G_Computation = rep(NA_real_, n_treat)
    }
    
    # SuperLearner - run ensemble method (only if run_ensemble_SL = TRUE)
    if (run_ensemble_SL) {
      tryCatch({
        sl_res = analyze_rct_sl(
          data = df_complete_numeric,
          outcome_cols = outcome,
          covariate_cols = valid_covariates,
          treatment_col = treatment_col,
          reference_arm = control_level,
          K = K,
          SL_methods = SL_methods,
          n_cores = n_cores
        )
        outcome_results$Est_SL = sl_res$Est_SL
        outcome_results$SE_SL = sl_res$SE_SL
      }, error = function(e) {
        if (grepl("All algorithms dropped from library", e$message)) {
          outcome_results$Est_SL <<- rep(NA_real_, n_treat)
          outcome_results$SE_SL <<- rep(NA_real_, n_treat)
        } else {
          stop(e)
        }
      })
    } else {
      # If not running ensemble SL, set to NA
      outcome_results$Est_SL = rep(NA_real_, n_treat)
      outcome_results$SE_SL = rep(NA_real_, n_treat)
    }
    
    # Run individual SL methods (only if run_individual_SL = TRUE)
    if (run_individual_SL) {
      individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
      for (method in individual_methods) {
        tryCatch({
          sl_res_individual = analyze_rct_sl(
            data = df_complete_numeric,
            outcome_cols = outcome,
            covariate_cols = valid_covariates,
            treatment_col = treatment_col,
            reference_arm = control_level,
            K = K,
            SL_methods = method,
            n_cores = n_cores
          )
          # Clean method name for column naming
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
          outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
        }, error = function(e) {
          # For any error, set to NA
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
          outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
        })
      }
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      Est_RC_ANCOVA,
      SE_RC_ANCOVA,
      Est_RC_ANHECOVA,
      SE_RC_ANHECOVA,
      Est_RC_Logistic_G_Computation,
      SE_RC_Logistic_G_Computation,
      Est_AC,
      SE_AC,
      Est_UN,
      SE_UN,
      Est_SL,
      SE_SL,
      everything()
    )
  
  return(final_results)
}
```

## analyze_rct_sl_tmle()
```{r}
analyze_rct_sl_tmle = function(data,
                               treatment_col  = "Treatment",
                               outcome_cols,
                               covariate_cols,
                               reference_arm  = NULL,
                               K              = 5,
                               q_library      = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                               g_library      = "SL.mean",
                               n_cores        = parallel::detectCores() - 2) {
  require(dplyr)
  require(tmle)
  require(SuperLearner)
  require(foreach)
  require(doSNOW)
  require(doRNG)
  
  n  = nrow(data)
  
  ## ── set up inner cluster ────────────────────────────────────────────────
  cl = makeCluster(n_cores)
  registerDoSNOW(cl)
  registerDoRNG()
  on.exit(stopCluster(cl), add = TRUE)
  
  arms = levels(data[[treatment_col]])
  if (is.null(reference_arm))
    reference_arm = arms[1]
  if (!(reference_arm %in% arms))
    stop("reference_arm must be one of: ", paste(arms, collapse = ", "))
  
  combos = expand.grid(
    Outcome   = outcome_cols,
    Treatment = setdiff(arms, reference_arm),
    stringsAsFactors = FALSE
  )
  
  results = foreach(
    i = seq_len(nrow(combos)),
    .combine = dplyr::bind_rows,
    .packages = c("dplyr", "tmle", "SuperLearner")
  ) %dopar% {
    Y   = combos$Outcome[i]
    arm = combos$Treatment[i]
    pair_arms = c(reference_arm, arm)
    
    # Filter data to only include the two arms being compared for this contrast
    pair_data = data[data[[treatment_col]] %in% pair_arms, ]
    pair_data[[treatment_col]] = factor(pair_data[[treatment_col]], levels = pair_arms)
    
    # Create binary treatment indicator (1 for treatment arm, 0 for reference)
    A = as.numeric(pair_data[[treatment_col]] == arm)
    Y_vec = pair_data[[Y]]
    
    # Handle covariates
    if (length(covariate_cols) > 0) {
      W = pair_data[, covariate_cols, drop = FALSE]
    } else {
      W = NULL  # No covariates case
    }
    
    # Check for sufficient variation in treatment
    if (sum(A) < 2 || sum(1-A) < 2) {
      return(tibble(
        Outcome   = Y,
        Treatment = arm,
        Control   = reference_arm,
        Est_SL    = NA_real_,
        SE_SL     = NA_real_
      ))
    }
    
    # Initialize variables with NA before tryCatch
    Est_SL = NA_real_
    SE_SL = NA_real_
    
    tryCatch({
      # Fit TMLE with CV control
      if (is.null(W)) {
        tmle_fit = tmle(
          Y = Y_vec,
          A = A,
          Q.SL.library = q_library,
          g.SL.library = g_library,
          family = "gaussian",
          V.Q = K,
          V.g = K
        )
      } else {
        tmle_fit = tmle(
          Y = Y_vec,
          A = A,
          W = W,
          Q.SL.library = q_library,
          g.SL.library = g_library,
          family = "gaussian",
          V.Q = K,
          V.g = K
        )
      }
      
      # Extract ATE estimate and SE directly from TMLE
      Est_SL = tmle_fit$estimates$ATE$psi
      SE_SL = sqrt(tmle_fit$estimates$ATE$var.psi)
      
    }, error = function(e) {
      # Variables already initialized above, so this is optional
      # But you could log the error here if desired
      message("Error in TMLE for ", Y, " arm ", arm, ": ", e$message)
    })
    
    tibble(
      Outcome   = Y,
      Treatment = arm,
      Control   = reference_arm,
      Est_SL    = Est_SL,
      SE_SL     = SE_SL
    )
  }
  
  results
}
```


## analyze_rct_tmle()
```{r}
analyze_rct_tmle = function(df,
                            selection = FALSE,
                            variable_selection_type = 1,  # 1: correlation, 2: manual
                            manual_covariates = NULL,
                            K = 5,
                            q_library = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                            g_library = "SL.mean",
                            n_select = 3,
                            n_cores = parallel::detectCores() - 2,
                            run_individual_SL = TRUE,
                            run_ensemble_SL = F,
                            outcome_cols = NULL,
                            covariate_col = NULL,
                            treatment_col = "Treatment",
                            seed = 123) {
  require(dplyr)
  require(tmle)
  require(SuperLearner)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), DescTools::Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection based on type
    if (selection && length(valid_covariates) > 0) {
      if (variable_selection_type == 1) {
        # Correlation-based selection
        selected_covariates = variable_selection_correlation(outcome, valid_covariates, df_complete_numeric, n_select)
      } else if (variable_selection_type == 2) {
        # Manual + baseline selection
        selected_covariates = variable_selection_manual(outcome, valid_covariates, manual_covariates)
        
        # Check if we have any covariates to work with for manual selection
        if (length(selected_covariates) == 0) {
          cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
          
          # Create results with NA values
          treatment_levels = levels(df_complete[[treatment_col]])[-1]  # Exclude control
          n_treat = length(treatment_levels)
          
          # Base tibble with core columns
          outcome_results = tibble(
            Outcome = rep(outcome, n_treat),
            Treatment = treatment_levels,
            Control = rep(control_level, n_treat),
            N = rep(nrow(df_complete), n_treat),
            N_Covariates = rep(0, n_treat)
          )
          
          # Add Selected_Covariates column if selection = TRUE
          if (selection) {
            outcome_results$Selected_Covariates = rep("", n_treat)
          }
          
          # Add ensemble SL columns if requested
          if (run_ensemble_SL) {
            outcome_results$Est_SL = rep(NA_real_, n_treat)
            outcome_results$SE_SL = rep(NA_real_, n_treat)
          }
          
          # Add individual SL method columns if requested (excluding SL.mean)
          if (run_individual_SL) {
            individual_methods = q_library[!q_library %in% c("SL.mean")]
            for (method in individual_methods) {
              method_clean = gsub("SL\\.", "SL_", method)
              outcome_results[[paste0("Est_", method_clean)]] = rep(NA_real_, n_treat)
              outcome_results[[paste0("SE_", method_clean)]] = rep(NA_real_, n_treat)
            }
          }
          
          valid_outcomes = c(valid_outcomes, outcome)
          all_results[[length(valid_outcomes)]] = outcome_results
          next
        }
      }
      
      # Use the selected covariates
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }
    
    # Create results for this outcome
    treatment_levels = setdiff(levels(df_complete[[treatment_col]]), control_level)
    n_treat = length(treatment_levels)
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat)
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # TMLE SuperLearner - run ensemble (using numeric version) if requested
    if (run_ensemble_SL) {
      outcome_results$Est_SL = rep(NA_real_, n_treat)
      outcome_results$SE_SL = rep(NA_real_, n_treat)
      
      tryCatch({
        sl_res = analyze_rct_sl_tmle(
          data = df_complete_numeric,
          outcome_cols = outcome,
          covariate_cols = valid_covariates,
          treatment_col = treatment_col,
          reference_arm = control_level,
          K = K,
          q_library = q_library,
          g_library = g_library,
          n_cores = n_cores
        )
        outcome_results$Est_SL = sl_res$Est_SL
        outcome_results$SE_SL = sl_res$SE_SL
      }, error = function(e) {
        cat("TMLE Ensemble Error for outcome", outcome, ":", e$message, "\n")
        outcome_results$Est_SL <<- rep(NA_real_, n_treat)
        outcome_results$SE_SL <<- rep(NA_real_, n_treat)
      })
    }
    
    # Run individual SL methods (only if run_individual_SL = TRUE)
    if (run_individual_SL) {
      individual_methods = q_library[!q_library %in% c("SL.mean")]
      for (method in individual_methods) {
        tryCatch({
          sl_res_individual = analyze_rct_sl_tmle(
            data = df_complete_numeric,
            outcome_cols = outcome,
            covariate_cols = valid_covariates,
            treatment_col = treatment_col,
            reference_arm = control_level,
            K = K,
            q_library = method,
            g_library = g_library,
            n_cores = n_cores
          )
          # Clean method name for column naming
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
          outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
        }, error = function(e) {
          cat("TMLE Error for outcome", outcome, "with method", method, ":", e$message, "\n")
          # For any error, set to NA
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
          outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
        })
      }
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns - put ensemble SL first, then individual methods
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      any_of(c("Est_SL", "SE_SL")),
      everything()
    )
  
  return(final_results)
}
```

## analyze_rct_aipw()
```{r}
analyze_rct_aipw = function(df,
                           selection = FALSE,
                           variable_selection_type = 1,  # 1: correlation, 2: manual
                           manual_covariates = NULL,
                           Q_SL_library = c("SL.glm", "SL.mean", "SL.rpart", "SL.gam", "SL.glmnet"),
                           g_SL_library = "SL.mean",
                           run_individual_SL = TRUE,
                           run_ensemble_SL = FALSE,
                           k_split = 5,
                           g_bound = 0.05,
                           seed = 123,
                           outcome_cols = NULL,
                           covariate_col = NULL,
                           treatment_col = "Treatment",
                           n_select = 3) {
  require(dplyr)
  require(AIPW)
  require(SuperLearner)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  # Get treatment arms - first level is the reference/control arm
  arms = levels(df[[treatment_col]])
  control_level = arms[1]  # Reference arm (set in data cleaning)
  treatment_levels = arms[-1]  # All non-reference treatment arms
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # Convert data to numeric for AIPW
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection based on type (using full dataset before pairwise splitting)
    if (selection && length(valid_covariates) > 0) {
      if (variable_selection_type == 1) {
        # Correlation-based selection
        selected_covariates = variable_selection_correlation(outcome, valid_covariates, df_complete_numeric, n_select)
      } else if (variable_selection_type == 2) {
        # Manual + baseline selection
        selected_covariates = variable_selection_manual(outcome, valid_covariates, manual_covariates)
        
        # Check if we have any covariates to work with for manual selection
        if (length(selected_covariates) == 0) {
          cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
          
          # Create NA results for all treatment arms
          outcome_results_list = lapply(treatment_levels, function(treat_level) {
            base_result = tibble(
              Outcome = outcome,
              Treatment = treat_level,
              Control = control_level,
              N = sum(df_complete[[treatment_col]] %in% c(control_level, treat_level)),
              N_Covariates = 0
            )
            
            # Add Selected_Covariates column if selection = TRUE
            if (selection) {
              base_result$Selected_Covariates = ""
            }
            
            # Add ensemble SL columns if requested
            if (run_ensemble_SL) {
              base_result$Est_AIPW = NA_real_
              base_result$SE_AIPW = NA_real_
            }
            
            # Add individual SL method columns if requested (excluding SL.mean)
            if (run_individual_SL) {
              individual_methods = Q_SL_library[!Q_SL_library %in% c("SL.mean")]
              for (method in individual_methods) {
                method_clean = gsub("SL\\.", "SL_", method)
                base_result[[paste0("Est_AIPW_", method_clean)]] = NA_real_
                base_result[[paste0("SE_AIPW_", method_clean)]] = NA_real_
              }
            }
            
            base_result
          })
          outcome_results = bind_rows(outcome_results_list)
          
          valid_outcomes = c(valid_outcomes, outcome)
          all_results[[length(valid_outcomes)]] = outcome_results
          next
        }
      }
      
      # Use the selected covariates
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## PAIRWISE COMPARISONS: Loop through each treatment arm vs reference
    ## ────────────────────────────────────────────────────────────────
    
    outcome_results_list = vector("list", length(treatment_levels))
    
    for (j in seq_along(treatment_levels)) {
      treat_level = treatment_levels[j]
      
      # Subset data to only reference arm and current treatment arm
      df_pairwise = df_complete_numeric %>%
        filter(!!sym(treatment_col) %in% c(control_level, treat_level))
      
      # Create binary treatment (0 = reference, 1 = current treatment)
      df_pairwise_binary = df_pairwise
      df_pairwise_binary[[treatment_col]] = as.numeric(df_pairwise_binary[[treatment_col]] == treat_level)
      
      # Prepare covariate matrix
      W_matrix = df_pairwise_binary[, valid_covariates, drop = FALSE]
      
      # Convert factors to numeric if needed
      for (col in names(W_matrix)) {
        if (is.factor(W_matrix[[col]])) {
          W_matrix[[col]] = as.numeric(W_matrix[[col]])
        }
      }
      
      # Create base result tibble
      base_result = tibble(
        Outcome = outcome,
        Treatment = treat_level,
        Control = control_level,
        N = nrow(df_pairwise),
        N_Covariates = length(valid_covariates)
      )
      
      # Add Selected_Covariates column only if selection = TRUE
      if (selection) {
        base_result$Selected_Covariates = paste(valid_covariates, collapse = ", ")
      }
      
      # Run ensemble AIPW if requested
      if (run_ensemble_SL) {
        aipw_result = tryCatch({
          aipw_fit = suppressWarnings(aipw_wrapper(
            Y = df_pairwise_binary[[outcome]],
            A = df_pairwise_binary[[treatment_col]],
            W = W_matrix,
            Q.SL.library = Q_SL_library,
            g.SL.library = g_SL_library,
            k_split = k_split,
            g.bound = g_bound,
            stratified_fit = TRUE,
            verbose = FALSE
          ))
          
          # Extract estimates
          list(
            est = aipw_fit$estimates$RD[[1]],
            se = aipw_fit$estimates$RD[[2]],
            success = TRUE
          )
          
        }, error = function(e) {
          # Silently return NA results on any error
          list(
            est = NA_real_,
            se = NA_real_,
            success = FALSE
          )
        })
        
        base_result$Est_AIPW = aipw_result$est
        base_result$SE_AIPW = aipw_result$se
      }
      
      # Run individual SL methods if requested
      if (run_individual_SL) {
        individual_methods = Q_SL_library[!Q_SL_library %in% c("SL.mean")]
        
        for (method in individual_methods) {
          method_clean = gsub("SL\\.", "SL_", method)
          
          aipw_individual = tryCatch({
            aipw_fit_individual = aipw_wrapper(
              Y = df_pairwise_binary[[outcome]],
              A = df_pairwise_binary[[treatment_col]],
              W = W_matrix,
              Q.SL.library = method,  # Single method
              g.SL.library = g_SL_library,
              k_split = k_split,
              g.bound = g_bound,
              stratified_fit = FALSE,
              verbose = FALSE
            )
            
            # Extract estimates
            list(
              est = aipw_fit_individual$estimates$RD[[1]],
              se = aipw_fit_individual$estimates$RD[[2]],
              success = TRUE
            )
            
          }, error = function(e) {
            cat("AIPW Error for outcome", outcome, "with method", method, ":", e$message, "\n")
            # Silently return NA results on any error
            list(
              est = NA_real_,
              se = NA_real_,
              success = FALSE
            )
          })
          
          base_result[[paste0("Est_AIPW_", method_clean)]] = aipw_individual$est
          base_result[[paste0("SE_AIPW_", method_clean)]] = aipw_individual$se
        }
      }
      
      outcome_results_list[[j]] = base_result
    }
    
    # Combine results from all treatment arms for this outcome
    outcome_results = bind_rows(outcome_results_list)
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns - put ensemble AIPW first, then individual methods
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      any_of(c("Est_AIPW", "SE_AIPW")),
      everything()
    )
  
  return(final_results)
}
```

## analyze_rct_ipw()
```{r}
analyze_rct_ipw = function(df,
                           selection = FALSE,
                           variable_selection_type = 1,   # 1: correlation, 2: manual
                           manual_covariates = NULL,
                           weight_method = "IPW",         # PSweight keywords: "IPW","treated","overlap","matching","entropy"
                           n_select = 3,
                           outcome_cols = NULL,
                           covariate_col = NULL,
                           treatment_col = "Treatment",
                           seed = 123) {
  suppressPackageStartupMessages({
    require(dplyr)
    require(PSweight)
    require(DescTools)
  })

  set.seed(seed)

  # --- Outcomes autodetect ---
  if (is.null(outcome_cols)) {
    yp_cols = names(df)[startsWith(names(df), "YP")]
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) && length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    outcome_cols = c(yp_cols, ys_valid)
    cat("Auto-detected", length(outcome_cols), "outcome columns:", paste(outcome_cols, collapse = ", "), "\n")
  }

  # --- Covariates ---
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    if ("n_participants" %in% names(df)) covariates = c(covariates, "n_participants")
  } else {
    covariates = covariate_col
  }

  # --- Simple imputations for covariates ---
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), DescTools::Mode(., na.rm = TRUE)[1])
    }))

  # --- Arms (first level is control) ---
  arms = levels(df[[treatment_col]])
  control_level = arms[1]
  treatment_levels = arms[-1]

  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)

  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]

    # Skip high-missing outcomes
    miss = mean(is.na(df[[outcome]]))
    if (miss > 0.4) {
      cat("REMOVED outcome:", outcome, "- Missing proportion:", round(miss, 3), "(> 0.4)\n")
      next
    }

    # Complete cases for current outcome + treatment + covariates
    keep_vars = c(outcome, treatment_col, covariates)
    idx = complete.cases(df[, keep_vars, drop = FALSE])
    df_complete = df[idx, , drop = FALSE]
    cat("Outcome:", outcome, "- Sample size:", nrow(df_complete), "(", nrow(df) - nrow(df_complete), "rows removed)\n")

    # Remove degenerate outcome
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:", outcome, "- Only one level after filtering\n")
      next
    }

    # Drop covariates with single level post-filter
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat("REMOVED covariate:", cov, "- Only one level after filtering (outcome:", outcome, ")\n")
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }

    # Force numeric outcome; we’ll fit Gaussian for all outcomes
    df_complete_num = df_complete
    df_complete_num[[outcome]] = as.numeric(df_complete_num[[outcome]])

    # Optional variable selection
    if (selection && length(valid_covariates) > 0) {
      if (variable_selection_type == 1) {
        selected_covariates = variable_selection_correlation(outcome, valid_covariates, df_complete_num, n_select)
      } else {
        selected_covariates = variable_selection_manual(outcome, valid_covariates, manual_covariates)
        if (length(selected_covariates) == 0) {
          cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
          outcome_results_list = lapply(treatment_levels, function(trt) {
            tibble(Outcome = outcome,
                   Treatment = trt,
                   Control = control_level,
                   N = sum(df_complete[[treatment_col]] %in% c(control_level, trt)),
                   N_Covariates = 0,
                   Est_IPW = NA_real_,
                   SE_IPW = NA_real_)
          })
          if (selection) {
            outcome_results_list = lapply(outcome_results_list, function(x) { x$Selected_Covariates = ""; x })
          }
          outcome_results = bind_rows(outcome_results_list)
          valid_outcomes = c(valid_outcomes, outcome)
          all_results[[length(valid_outcomes)]] = outcome_results
          next
        }
      }
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }

    # Pairwise treatment vs control
    outcome_results_list = vector("list", length(treatment_levels))

    for (j in seq_along(treatment_levels)) {
      trt = treatment_levels[j]
      df_pair = df_complete_num %>% dplyr::filter(!!rlang::sym(treatment_col) %in% c(control_level, trt))
      df_pair$Z = as.numeric(df_pair[[treatment_col]] == trt)

      ps.formula = if (length(valid_covariates) > 0) {
        as.formula(paste("Z ~", paste(valid_covariates, collapse = " + ")))
      } else {
        as.formula("Z ~ 1")
      }

      # ---- PSweight block (Gaussian for all outcomes) ----
      ipw = tryCatch({
        # PSweight is sensitive to list/data.frame cols; sanitize to base data.frame with atomic columns
        keep_cols = c("Z", outcome, valid_covariates)
        clean_df = as.data.frame(df_pair[, keep_cols, drop = FALSE])
        ok = vapply(clean_df, function(x) is.atomic(x) || is.factor(x), logical(1))
        if (!all(ok)) {
          bad = names(clean_df)[!ok]
          cat("Dropping non-atomic columns for PSweight:", paste(bad, collapse = ", "), "\n")
          clean_df = clean_df[, ok, drop = FALSE]
          valid_covariates2 = intersect(valid_covariates, names(clean_df))
          ps.formula = if (length(valid_covariates2) > 0) {
            as.formula(paste("Z ~", paste(valid_covariates2, collapse = " + ")))
          } else as.formula("Z ~ 1")
        }

        # Ensure numeric
        clean_df$Z = as.numeric(clean_df$Z)
        clean_df[[outcome]] = as.numeric(clean_df[[outcome]])

        # Fit PSweight and get DIF summary
        psw_fit = PSweight(
          ps.formula = ps.formula,
          yname = outcome,
          data = clean_df,
          weight = weight_method,    # must be PSweight keyword
          augmentation = FALSE,
          bootstrap = FALSE,
          family = "gaussian"
        )
        psw_sum = summary(psw_fit, type = "DIF")

        est = as.numeric(psw_sum$estimates[1, "Estimate"])
        se  = as.numeric(psw_sum$estimates[1, "Std.Error"])
        list(est = est, se = se, success = TRUE)
      }, error = function(e) {
        cat("IPW Error for outcome", outcome, "treatment", trt, ":", e$message, "\n")
        list(est = NA_real_, se = NA_real_, success = FALSE)
      })
      # ---- end PSweight block ----

      res_row = tibble(
        Outcome = outcome,
        Treatment = trt,
        Control = control_level,
        N = nrow(df_pair),
        N_Covariates = length(valid_covariates),
        Est_IPW = ipw$est,
        SE_IPW  = ipw$se
      )
      if (selection) res_row$Selected_Covariates = paste(valid_covariates, collapse = ", ")
      outcome_results_list[[j]] = res_row
    }

    outcome_results = bind_rows(outcome_results_list)
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }

  if (length(valid_outcomes) == 0) stop("No valid outcomes remaining after data cleaning")

  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"),  ~ round(.x, 5)))
  return(final_results)
}

```



## update_df_dml()
```{r}
update_df_dml = function(trial_no,
                     outcome_type,
                     results,
                     suffix = "",
                     ensemble = 1,
                     contrast = "diff",
                     df = df_comparison,
                     update_ensemble_SL = TRUE,  # NEW: Whether to update ensemble SL columns
                     update_individual_SL = TRUE) {  # NEW: Whether to update individual SL columns

  library(dplyr)

  ## ────────────────────────────────────────────────────────────────
  ## 0) Check if all N_Covariates are 0 - if so, skip update entirely
  ##    Otherwise, filter to only rows with covariates
  ## ────────────────────────────────────────────────────────────────
  if (all(results$N_Covariates == 0)) {
    cat("Skipping update for trial", trial_no, "- All outcomes have N_Covariates = 0\n")
    return(df)
  }
  
  # Store original results for outcome_type mapping
  results_original = results
  
  # Filter to only rows with covariates
  results_with_covariates = results[results$N_Covariates > 0, ]
  
  if (nrow(results_with_covariates) == 0) {
    cat("Skipping update for trial", trial_no, "- No outcomes with covariates after filtering\n")
    return(df)
  }
  
  if (nrow(results_with_covariates) < nrow(results)) {
    cat("Note: Processing", nrow(results_with_covariates), "out of", nrow(results), 
        "outcomes (skipping", nrow(results) - nrow(results_with_covariates), "with N_Covariates = 0)\n")
  }
  
  # Use filtered results for the rest of the function
  results = results_with_covariates

  ## ────────────────────────────────────────────────────────────────
  ## 1)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  
  # Determine the multiplier (number of comparisons per outcome)
  # This is always nrow(results_original) / length(outcome_type)
  multiplier = nrow(results_original) / length(outcome_type)
  
  if (multiplier != round(multiplier)) {
    stop("Number of rows in results (", nrow(results_original), 
         ") is not a multiple of length of outcome_type (", length(outcome_type), ")")
  }
  
  # Create outcome_type mapping for filtered results
  # For each row in results, find which outcome_type it corresponds to
  outcome_type_expanded = rep(outcome_type, each = multiplier)
  
  # Now subset this expanded vector to match the filtered results
  # We need to find the indices of results_with_covariates in results_original
  original_indices = match(
    paste(results_with_covariates$Outcome, 
          results_with_covariates$Treatment, 
          results_with_covariates$Control),
    paste(results_original$Outcome, 
          results_original$Treatment, 
          results_original$Control)
  )
  
  outcome_type_filtered = outcome_type_expanded[original_indices]
  
  unique_outcomes = unique(results$Outcome)
  
  # Create mapping based on filtered data
  outcome_type_map = tibble(
    Outcome = results$Outcome,
    `Outcome Type` = outcome_type_filtered
  ) %>%
    distinct(Outcome, .keep_all = TRUE)

  ## Dynamically detect SL members from results columns (excluding glm/mean)
  est_cols = names(results)[grepl("^Est_SL_", names(results))]
  sl_members = gsub("^Est_", "", est_cols)
  
  # Remove any glm or mean methods if they exist
  sl_members = sl_members[!grepl("^SL_glm$|^SL_mean$", sl_members, ignore.case = TRUE)]

  ## ────────────────────────────────────────────────────────────────
  ## 2)  Process results with the given suffix
  ## ────────────────────────────────────────────────────────────────
  
  # Start with core columns that we want to keep
  core_cols = c("Outcome", "Treatment", "Control")
  results_processed = results[, core_cols, drop = FALSE]
  
  # Add Selected_Covariates with suffix if it exists
  if ("Selected_Covariates" %in% names(results)) {
    if (suffix == "") {
      results_processed$Selected_Covariates = results$Selected_Covariates
    } else {
      results_processed[[paste0("Selected_Covariates_", suffix)]] = results$Selected_Covariates
    }
  }
  
  # Determine SL column names based on ensemble argument
  if (ensemble == 1) {
    sl_base_name = paste0("SL", ensemble)
  } else if (ensemble == 2) {
    sl_base_name = "DML"
  } else {
    sl_base_name = paste0("SL", ensemble)
  }
  
  if (suffix == "") {
    results_processed = results_processed %>%
      mutate(
        ANCOVA_est                         = results$Est_RC_ANCOVA,
        ANCOVA_robust_se                   = results$SE_RC_ANCOVA,
        ANCOVA_pval                        = 2 * pnorm(-abs(results$Est_RC_ANCOVA / results$SE_RC_ANCOVA)),
        ANHECOVA_est                       = results$Est_RC_ANHECOVA,
        ANHECOVA_robust_se                 = results$SE_RC_ANHECOVA,
        ANHECOVA_pval                      = 2 * pnorm(-abs(results$Est_RC_ANHECOVA / results$SE_RC_ANHECOVA)),
        `Logistic G-Computation_est`       = results$Est_RC_Logistic_G_Computation,
        `Logistic G-Computation_robust_se` = results$SE_RC_Logistic_G_Computation,
        `Logistic G-Computation_pval`      = 2 * pnorm(-abs(results$Est_RC_Logistic_G_Computation / results$SE_RC_Logistic_G_Computation)),
        ANCOVA_model_based_se              = results$SE_AC,
        Unadjust_est                       = results$Est_UN,
        Unadjust_se                        = results$SE_UN,
        Unadjust_pval                      = 2 * pnorm(-abs(results$Est_UN / results$SE_UN))
      )
    
    # Add ensemble SL columns only if update_ensemble_SL = TRUE
    if (update_ensemble_SL) {
      results_processed = results_processed %>%
        mutate(
          !!paste0(sl_base_name, "_est") := results$Est_SL,
          !!paste0(sl_base_name, "_se")  := results$SE_SL,
          !!paste0(sl_base_name, "_pval") := 2 * pnorm(-abs(results$Est_SL / results$SE_SL))
        )
    }
  } else {
    # For suffixed version, add suffix to method names
    suffix_clean = paste0("_", suffix)
    results_processed = results_processed %>%
      mutate(
        !!paste0("ANCOVA", suffix_clean, "_est")                         := results$Est_RC_ANCOVA,
        !!paste0("ANCOVA", suffix_clean, "_robust_se")                   := results$SE_RC_ANCOVA,
        !!paste0("ANCOVA", suffix_clean, "_pval")                        := 2 * pnorm(-abs(results$Est_RC_ANCOVA / results$SE_RC_ANCOVA)),
        !!paste0("ANHECOVA", suffix_clean, "_est")                       := results$Est_RC_ANHECOVA,
        !!paste0("ANHECOVA", suffix_clean, "_robust_se")                 := results$SE_RC_ANHECOVA,
        !!paste0("ANHECOVA", suffix_clean, "_pval")                      := 2 * pnorm(-abs(results$Est_RC_ANHECOVA / results$SE_RC_ANHECOVA)),
        !!paste0("Logistic G-Computation", suffix_clean, "_est")         := results$Est_RC_Logistic_G_Computation,
        !!paste0("Logistic G-Computation", suffix_clean, "_robust_se")   := results$SE_RC_Logistic_G_Computation,
        !!paste0("Logistic G-Computation", suffix_clean, "_pval")        := 2 * pnorm(-abs(results$Est_RC_Logistic_G_Computation / results$SE_RC_Logistic_G_Computation)),
        !!paste0("ANCOVA", suffix_clean, "_model_based_se")              := results$SE_AC,
        Unadjust_est                                                     := results$Est_UN,
        Unadjust_se                                                      := results$SE_UN,
        Unadjust_pval                                                    := 2 * pnorm(-abs(results$Est_UN / results$SE_UN))
      )
    
    # Add ensemble SL columns only if update_ensemble_SL = TRUE
    if (update_ensemble_SL) {
      results_processed = results_processed %>%
        mutate(
          !!paste0(sl_base_name, suffix_clean, "_est")                     := results$Est_SL,
          !!paste0(sl_base_name, suffix_clean, "_se")                      := results$SE_SL,
          !!paste0(sl_base_name, suffix_clean, "_pval")                    := 2 * pnorm(-abs(results$Est_SL / results$SE_SL))
        )
    }
  }

  ## ── Add individual SL member columns (only if update_individual_SL = TRUE) ─────────────────────────────
  if (update_individual_SL) {
    for (m in sl_members) {
      old_est = paste0("Est_", m)
      old_se  = paste0("SE_",  m)
      
      if (suffix == "") {
        new_est = paste0(m, "_est")
        new_se  = paste0(m, "_se")
        new_pval = paste0(m, "_pval")
      } else {
        new_est = paste0(m, "_", suffix, "_est")
        new_se  = paste0(m, "_", suffix, "_se")
        new_pval = paste0(m, "_", suffix, "_pval")
      }
      
      # Only add if the original columns exist in results
      if (old_est %in% names(results)) {
        results_processed[[new_est]] = results[[old_est]]
      }
      if (old_se %in% names(results)) {
        results_processed[[new_se]] = results[[old_se]]
        # Calculate p-value if both est and se exist
        if (old_est %in% names(results)) {
          results_processed[[new_pval]] = 2 * pnorm(-abs(results[[old_est]] / results[[old_se]]))
        }
      }
    }
  }

  ## ── attach meta data ───────────────────────────────────────────
  results_processed = results_processed %>%
    left_join(outcome_type_map, by = "Outcome") %>%
    mutate(
      Trial_No     = trial_no,
      Sample_Size  = results$N,  # Use results$N for Sample_Size but don't keep N column
      !!ifelse(suffix == "", "N_Covariates", paste0("N_Covariates_", suffix)) := results$N_Covariates,
      Contrast     = contrast
    )

  ## ── precision gain and difference calculations ────────────────
  # Get the appropriate SL column names for calculations
  if (suffix == "") {
    sl_se_col = paste0(sl_base_name, "_se")
    sl_est_col = paste0(sl_base_name, "_est")
  } else {
    suffix_clean = paste0("_", suffix)
    sl_se_col = paste0(sl_base_name, suffix_clean, "_se")
    sl_est_col = paste0(sl_base_name, suffix_clean, "_est")
  }
  
  if (suffix == "") {
    results_processed = results_processed %>%
      mutate(
        `How much precision gain can ANCOVA provide?`                     = (ANCOVA_robust_se / Unadjust_se)^2,
        `How much precision gain can ANHECOVA provide?`                   = (ANHECOVA_robust_se / Unadjust_se)^2,
        `How much precision gain can Logistic G-Computation provide?`     = (`Logistic G-Computation_robust_se` / Unadjust_se)^2,
        `ANCOVA vs ANHECOVA variance ratio`             = (ANCOVA_robust_se / ANHECOVA_robust_se)^2,
        `The ratio between robust and model-based variance estimators` =
          (ANCOVA_robust_se / ANCOVA_model_based_se)^2,
        `The difference between unadjusted and ANCOVA point estimates` =
          (ANCOVA_est - Unadjust_est) / Unadjust_se,
        `The difference between unadjusted and ANHECOVA point estimates` =
          (ANHECOVA_est - Unadjust_est) / Unadjust_se,
        `The difference between unadjusted and Logistic G-Computation point estimates` =
          (`Logistic G-Computation_est` - Unadjust_est) / Unadjust_se
      )
    
    # Add ensemble SL precision gain and difference only if update_ensemble_SL = TRUE
    if (update_ensemble_SL) {
      results_processed = results_processed %>%
        mutate(
          !!paste0("How much precision gain can ", sl_base_name, " provide?") := 
            (.data[[sl_se_col]] / Unadjust_se)^2,
          !!paste0("The difference between unadjusted and ", sl_base_name, " point estimates") :=
            (.data[[sl_est_col]] - Unadjust_est) / Unadjust_se
        )
    }
  } else {
    # For suffixed version
    suffix_clean = paste0("_", suffix)
    ancova_se_col = paste0("ANCOVA", suffix_clean, "_robust_se")
    anhecova_se_col = paste0("ANHECOVA", suffix_clean, "_robust_se")
    logistic_g_computation_se_col = paste0("Logistic G-Computation", suffix_clean, "_robust_se")
    ancova_model_se_col = paste0("ANCOVA", suffix_clean, "_model_based_se")
    
    ancova_est_col = paste0("ANCOVA", suffix_clean, "_est")
    anhecova_est_col = paste0("ANHECOVA", suffix_clean, "_est")
    logistic_g_computation_est_col = paste0("Logistic G-Computation", suffix_clean, "_est")
    
    results_processed = results_processed %>%
      mutate(
        !!paste0("How much precision gain can ANCOVA", suffix_clean, " provide?") := 
          (.data[[ancova_se_col]] / Unadjust_se)^2,
        !!paste0("How much precision gain can ANHECOVA", suffix_clean, " provide?") := 
          (.data[[anhecova_se_col]] / Unadjust_se)^2,
        !!paste0("How much precision gain can Logistic G-Computation", suffix_clean, " provide?") := 
          (.data[[logistic_g_computation_se_col]] / Unadjust_se)^2,
        !!paste0("ANCOVA", suffix_clean, " vs ANHECOVA", suffix_clean, " variance ratio") := 
          (.data[[ancova_se_col]] / .data[[anhecova_se_col]])^2,
        !!paste0("The ratio between robust and model-based variance estimators", suffix_clean) := 
          (.data[[ancova_se_col]] / .data[[ancova_model_se_col]])^2,
        !!paste0("The difference between unadjusted and ANCOVA", suffix_clean, " point estimates") := 
          (.data[[ancova_est_col]] - Unadjust_est) / Unadjust_se,
        !!paste0("The difference between unadjusted and ANHECOVA", suffix_clean, " point estimates") := 
          (.data[[anhecova_est_col]] - Unadjust_est) / Unadjust_se,
        !!paste0("The difference between unadjusted and Logistic G-Computation", suffix_clean, " point estimates") := 
          (.data[[logistic_g_computation_est_col]] - Unadjust_est) / Unadjust_se
      )
    
    # Add ensemble SL precision gain and difference only if update_ensemble_SL = TRUE
    if (update_ensemble_SL) {
      results_processed = results_processed %>%
        mutate(
          !!paste0("How much precision gain can ", sl_base_name, suffix_clean, " provide?") := 
            (.data[[sl_se_col]] / Unadjust_se)^2,
          !!paste0("The difference between unadjusted and ", sl_base_name, suffix_clean, " point estimates") := 
            (.data[[sl_est_col]] - Unadjust_est) / Unadjust_se
        )
    }
  }

  ## ── explicit SL-member precision gains & diffs (only if update_individual_SL = TRUE) ─────────────────
  if (update_individual_SL) {
    for (m in sl_members) {
      if (suffix == "") {
        se_col  = paste0(m, "_se")
        est_col = paste0(m, "_est")
        pg_col  = paste0("How much precision gain can ", m, " provide?")
        df_col  = paste0("The difference between unadjusted and ", m, " point estimates")
      } else {
        suffix_clean = paste0("_", suffix)
        se_col  = paste0(m, suffix_clean, "_se")
        est_col = paste0(m, suffix_clean, "_est")
        pg_col  = paste0("How much precision gain can ", m, suffix_clean, " provide?")
        df_col  = paste0("The difference between unadjusted and ", m, suffix_clean, " point estimates")
      }
      
      if (all(c(se_col, est_col) %in% names(results_processed))) {
        results_processed = results_processed %>%
          mutate(
            !!pg_col := (.data[[se_col]] / Unadjust_se)^2,
            !!df_col := (.data[[est_col]] - Unadjust_est) / Unadjust_se
          )
      }
    }
  }

  ## ────────────────────────────────────────────────────────────────
  ## 3)  Overwrite / append in df_comparison (with column addition support)
  ## ────────────────────────────────────────────────────────────────
  new_rows = results_processed
  
  for (i in seq_len(nrow(new_rows))) {
    row_i = new_rows[i, ]

    idx = which(
      df$Trial_No == row_i$Trial_No &
      df$Outcome   == row_i$Outcome &
      df$Treatment == row_i$Treatment &
      df$Control   == row_i$Control
    )

    if (length(idx) > 0) {
      # Update existing row - add new columns if they don't exist
      for (col_name in names(row_i)) {
        if (!col_name %in% names(df)) {
          df[[col_name]] = NA  # Add new column with NA values
        }
        df[idx[1], col_name] = row_i[[col_name]]
      }
    } else {
      # Append new row - add missing columns with NA values
      for (col_name in names(df)) {
        if (!col_name %in% names(row_i)) {
          row_i[[col_name]] = NA
        }
      }
      df = dplyr::bind_rows(df, row_i)
    }
  }

  df
}
```


## update_df_tmle()
```{r}
update_df_tmle = function(trial_no,
                          outcome_type,
                          results,
                          suffix = "",
                          contrast = "diff",
                          df = df_comparison) {
  
  library(dplyr)
  
  ## ────────────────────────────────────────────────────────────────
  ## 0) Check if all N_Covariates are 0 - if so, skip update entirely
  ##    Otherwise, filter to only rows with covariates
  ## ────────────────────────────────────────────────────────────────
  if (all(results$N_Covariates == 0)) {
    cat("Skipping TMLE update for trial", trial_no, "- All outcomes have N_Covariates = 0\n")
    return(df)
  }
  
  # Store original results for outcome_type mapping
  results_original = results
  
  # Filter to only rows with covariates
  results_with_covariates = results[results$N_Covariates > 0, ]
  
  if (nrow(results_with_covariates) == 0) {
    cat("Skipping TMLE update for trial", trial_no, "- No outcomes with covariates after filtering\n")
    return(df)
  }
  
  if (nrow(results_with_covariates) < nrow(results)) {
    cat("Note: Processing", nrow(results_with_covariates), "out of", nrow(results), 
        "outcomes (skipping", nrow(results) - nrow(results_with_covariates), "with N_Covariates = 0)\n")
  }
  
  # Use filtered results for the rest of the function
  results = results_with_covariates
  
  ## ────────────────────────────────────────────────────────────────
  ## 1)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  
  # Determine the multiplier (number of comparisons per outcome)
  # This is always nrow(results_original) / length(outcome_type)
  multiplier = nrow(results_original) / length(outcome_type)
  
  if (multiplier != round(multiplier)) {
    stop("Number of rows in results (", nrow(results_original), 
         ") is not a multiple of length of outcome_type (", length(outcome_type), ")")
  }
  
  # Create outcome_type mapping for filtered results
  # For each row in results, find which outcome_type it corresponds to
  outcome_type_expanded = rep(outcome_type, each = multiplier)
  
  # Now subset this expanded vector to match the filtered results
  # We need to find the indices of results_with_covariates in results_original
  original_indices = match(
    paste(results_with_covariates$Outcome, 
          results_with_covariates$Treatment, 
          results_with_covariates$Control),
    paste(results_original$Outcome, 
          results_original$Treatment, 
          results_original$Control)
  )
  
  outcome_type_filtered = outcome_type_expanded[original_indices]
  
  unique_outcomes = unique(results$Outcome)
  
  # Create mapping based on filtered data
  outcome_type_map = tibble(
    Outcome = results$Outcome,
    `Outcome Type` = outcome_type_filtered
  ) %>%
    distinct(Outcome, .keep_all = TRUE)
  
  ## Dynamically detect SL members from results columns (excluding glm/mean)
  est_cols = names(results)[grepl("^Est_SL_", names(results))]
  sl_members = gsub("^Est_", "", est_cols)
  
  # Remove any mean methods if they exist
  sl_members = sl_members[!grepl("^SL_mean$", sl_members, ignore.case = TRUE)]
  
  ## ────────────────────────────────────────────────────────────────
  ## 2) Process each row in results and update TMLE columns
  ## ────────────────────────────────────────────────────────────────
  
  for (i in seq_len(nrow(results))) {
    row_i = results[i, ]
    
    # Find matching row in df
    idx = which(
      df$Trial_No == trial_no &
        df$Outcome   == row_i$Outcome &
        df$Treatment == row_i$Treatment &
        df$Control   == row_i$Control
    )
    
    if (length(idx) == 0) {
      warning("No matching row found in df for Trial_No=", trial_no, 
              ", Outcome=", row_i$Outcome, ", Treatment=", row_i$Treatment)
      next
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## 2a) Update ensemble TMLE estimate columns (if Est_SL exists)
    ## ────────────────────────────────────────────────────────────────
    
    if ("Est_SL" %in% names(row_i)) {
      if (suffix == "") {
        tmle_est_col = "TMLE_est"
        tmle_se_col = "TMLE_se"
        tmle_pval_col = "TMLE_pval"
      } else {
        suffix_clean = paste0("_", suffix)
        tmle_est_col = paste0("TMLE", suffix_clean, "_est")
        tmle_se_col = paste0("TMLE", suffix_clean, "_se")
        tmle_pval_col = paste0("TMLE", suffix_clean, "_pval")
      }
      
      # Add columns if they don't exist
      if (!tmle_est_col %in% names(df)) {
        df[[tmle_est_col]] = NA_real_
      }
      if (!tmle_se_col %in% names(df)) {
        df[[tmle_se_col]] = NA_real_
      }
      if (!tmle_pval_col %in% names(df)) {
        df[[tmle_pval_col]] = NA_real_
      }
      
      # Update values
      df[idx[1], tmle_est_col] = row_i$Est_SL
      df[idx[1], tmle_se_col] = row_i$SE_SL
      
      # Calculate p-value
      tmle_est = row_i$Est_SL
      tmle_se = row_i$SE_SL
      if (!is.na(tmle_est) && !is.na(tmle_se) && tmle_se > 0) {
        df[idx[1], tmle_pval_col] = 2 * pnorm(-abs(tmle_est / tmle_se))
      }
      
      ## ────────────────────────────────────────────────────────────────
      ## 2b) Calculate and update derived metrics for ensemble TMLE
      ## ────────────────────────────────────────────────────────────────
      
      # Only if Unadjust_se and Unadjust_est exist in df
      if ("Unadjust_se" %in% names(df) && "Unadjust_est" %in% names(df)) {
        unadjust_se = df[idx[1], "Unadjust_se"]
        unadjust_est = df[idx[1], "Unadjust_est"]
        
        if (suffix == "") {
          pg_col = "How much precision gain can TMLE provide?"
          diff_col = "The difference between unadjusted and TMLE point estimates"
        } else {
          suffix_clean = paste0("_", suffix)
          pg_col = paste0("How much precision gain can TMLE", suffix_clean, " provide?")
          diff_col = paste0("The difference between unadjusted and TMLE", suffix_clean, " point estimates")
        }
        
        # Add derived metric columns if they don't exist
        if (!pg_col %in% names(df)) {
          df[[pg_col]] = NA_real_
        }
        if (!diff_col %in% names(df)) {
          df[[diff_col]] = NA_real_
        }
        
        # Calculate precision gain
        if (!is.na(tmle_se) && !is.na(unadjust_se) && unadjust_se != 0) {
          df[idx[1], pg_col] = (tmle_se / unadjust_se)^2
        }
        
        # Calculate point estimate difference (using unadjust_se only)
        if (!is.na(tmle_est) && !is.na(unadjust_est) && !is.na(unadjust_se) && unadjust_se > 0) {
          df[idx[1], diff_col] = (tmle_est - unadjust_est) / unadjust_se
        }
      }
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## 2c) Update individual SL method columns
    ## ────────────────────────────────────────────────────────────────
    
    for (m in sl_members) {
      old_est = paste0("Est_", m)
      old_se  = paste0("SE_",  m)
      
      # Only process if these columns exist in results
      if (old_est %in% names(row_i) && old_se %in% names(row_i)) {
        if (suffix == "") {
          new_est = paste0(m, "_TMLE_est")
          new_se  = paste0(m, "_TMLE_se")
          new_pval = paste0(m, "_TMLE_pval")
        } else {
          new_est = paste0(m, "_TMLE_", suffix, "_est")
          new_se  = paste0(m, "_TMLE_", suffix, "_se")
          new_pval = paste0(m, "_TMLE_", suffix, "_pval")
        }
        
        # Add columns if they don't exist
        if (!new_est %in% names(df)) {
          df[[new_est]] = NA_real_
        }
        if (!new_se %in% names(df)) {
          df[[new_se]] = NA_real_
        }
        if (!new_pval %in% names(df)) {
          df[[new_pval]] = NA_real_
        }
        
        # Update values
        df[idx[1], new_est] = row_i[[old_est]]
        df[idx[1], new_se] = row_i[[old_se]]
        
        # Calculate p-value
        method_est = row_i[[old_est]]
        method_se = row_i[[old_se]]
        if (!is.na(method_est) && !is.na(method_se) && method_se > 0) {
          df[idx[1], new_pval] = 2 * pnorm(-abs(method_est / method_se))
        }
        
        ## ────────────────────────────────────────────────────────────────
        ## 2d) Calculate and update derived metrics for individual methods
        ## ────────────────────────────────────────────────────────────────
        
        # Only if Unadjust_se and Unadjust_est exist in df
        if ("Unadjust_se" %in% names(df) && "Unadjust_est" %in% names(df)) {
          unadjust_se = df[idx[1], "Unadjust_se"]
          unadjust_est = df[idx[1], "Unadjust_est"]
          
          if (suffix == "") {
            pg_col_method = paste0("How much precision gain can ", m, "_TMLE provide?")
            diff_col_method = paste0("The difference between unadjusted and ", m, "_TMLE point estimates")
          } else {
            pg_col_method = paste0("How much precision gain can ", m, "_TMLE_", suffix, " provide?")
            diff_col_method = paste0("The difference between unadjusted and ", m, "_TMLE_", suffix, " point estimates")
          }
          
          # Add derived metric columns if they don't exist
          if (!pg_col_method %in% names(df)) {
            df[[pg_col_method]] = NA_real_
          }
          if (!diff_col_method %in% names(df)) {
            df[[diff_col_method]] = NA_real_
          }
          
          # Calculate precision gain for this method
          if (!is.na(method_se) && !is.na(unadjust_se) && unadjust_se != 0) {
            df[idx[1], pg_col_method] = (method_se / unadjust_se)^2
          }
          
          # Calculate point estimate difference for this method
          if (!is.na(method_est) && !is.na(unadjust_est) && !is.na(unadjust_se) && unadjust_se > 0) {
            df[idx[1], diff_col_method] = (method_est - unadjust_est) / unadjust_se
          }
        }
      }
    }
  }
  
  df
}
```




## update_df_aipw()
```{r}
update_df_aipw = function(trial_no,
                          outcome_type,
                          results,
                          method = "AIPW",  # Determines which columns to update in df
                          suffix = "",
                          contrast = "diff",
                          df = df_comparison) {
  
  library(dplyr)
  
  ## ────────────────────────────────────────────────────────────────
  ## 0) Check if all N_Covariates are 0 - if so, skip update entirely
  ##    Otherwise, filter to only rows with covariates
  ## ────────────────────────────────────────────────────────────────
  if (all(results$N_Covariates == 0)) {
    cat("Skipping", method, "update for trial", trial_no, "- All outcomes have N_Covariates = 0\n")
    return(df)
  }
  
  ## Validate method parameter
  method = toupper(method)
  if (!method %in% c("AIPW", "IPW")) {
    stop("method must be either 'AIPW' or 'IPW'")
  }
  
  # Store original results for outcome_type mapping
  results_original = results
  
  # Filter to only rows with covariates
  results_with_covariates = results[results$N_Covariates > 0, ]
  
  if (nrow(results_with_covariates) == 0) {
    cat("Skipping", method, "update for trial", trial_no, "- No outcomes with covariates after filtering\n")
    return(df)
  }
  
  if (nrow(results_with_covariates) < nrow(results)) {
    cat("Note: Processing", nrow(results_with_covariates), "out of", nrow(results), 
        "outcomes (skipping", nrow(results) - nrow(results_with_covariates), "with N_Covariates = 0)\n")
  }
  
  # Use filtered results for the rest of the function
  results = results_with_covariates
  
  ## ────────────────────────────────────────────────────────────────
  ## 1)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  
  # Determine the multiplier (number of comparisons per outcome)
  # This is always nrow(results_original) / length(outcome_type)
  multiplier = nrow(results_original) / length(outcome_type)
  
  if (multiplier != round(multiplier)) {
    stop("Number of rows in results (", nrow(results_original), 
         ") is not a multiple of length of outcome_type (", length(outcome_type), ")")
  }
  
  # Create outcome_type mapping for filtered results
  # For each row in results, find which outcome_type it corresponds to
  outcome_type_expanded = rep(outcome_type, each = multiplier)
  
  # Now subset this expanded vector to match the filtered results
  # We need to find the indices of results_with_covariates in results_original
  original_indices = match(
    paste(results_with_covariates$Outcome, 
          results_with_covariates$Treatment, 
          results_with_covariates$Control),
    paste(results_original$Outcome, 
          results_original$Treatment, 
          results_original$Control)
  )
  
  outcome_type_filtered = outcome_type_expanded[original_indices]
  
  unique_outcomes = unique(results$Outcome)
  
  # Create mapping based on filtered data
  outcome_type_map = tibble(
    Outcome = results$Outcome,
    `Outcome Type` = outcome_type_filtered
  ) %>%
    distinct(Outcome, .keep_all = TRUE)
  
  ## Dynamically detect SL members from results columns (excluding mean)
  est_cols = names(results)[grepl("^Est_AIPW_SL_", names(results))]
  sl_members = gsub("^Est_", "", est_cols)
  
  # Remove any mean methods if they exist
  sl_members = sl_members[!grepl("^AIPW_SL_mean$", sl_members, ignore.case = TRUE)]
  
  ## ────────────────────────────────────────────────────────────────
  ## 2) Process each row in results and update AIPW columns
  ## ────────────────────────────────────────────────────────────────
  
  for (i in seq_len(nrow(results))) {
    row_i = results[i, ]
    
    # Find matching row in df
    idx = which(
      df$Trial_No == trial_no &
        df$Outcome   == row_i$Outcome &
        df$Treatment == row_i$Treatment &
        df$Control   == row_i$Control
    )
    
    if (length(idx) == 0) {
      warning("No matching row found in df for Trial_No=", trial_no, 
              ", Outcome=", row_i$Outcome, ", Treatment=", row_i$Treatment)
      next
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## 2a) Update ensemble AIPW estimate columns (if Est_AIPW exists)
    ## ────────────────────────────────────────────────────────────────
    
    if ("Est_AIPW" %in% names(row_i)) {
      if (suffix == "") {
        aipw_est_col = paste0(method, "_est")
        aipw_se_col = paste0(method, "_se")
        aipw_pval_col = paste0(method, "_pval")
      } else {
        suffix_clean = paste0("_", suffix)
        aipw_est_col = paste0(method, suffix_clean, "_est")
        aipw_se_col = paste0(method, suffix_clean, "_se")
        aipw_pval_col = paste0(method, suffix_clean, "_pval")
      }
      
      # Add columns if they don't exist
      if (!aipw_est_col %in% names(df)) {
        df[[aipw_est_col]] = NA_real_
      }
      if (!aipw_se_col %in% names(df)) {
        df[[aipw_se_col]] = NA_real_
      }
      if (!aipw_pval_col %in% names(df)) {
        df[[aipw_pval_col]] = NA_real_
      }
      
      # Update values
      df[idx[1], aipw_est_col] = row_i$Est_AIPW
      df[idx[1], aipw_se_col] = row_i$SE_AIPW
      
      # Calculate p-value
      aipw_est = row_i$Est_AIPW
      aipw_se = row_i$SE_AIPW
      if (!is.na(aipw_est) && !is.na(aipw_se) && aipw_se > 0) {
        df[idx[1], aipw_pval_col] = 2 * pnorm(-abs(aipw_est / aipw_se))
      }
      
      ## ────────────────────────────────────────────────────────────────
      ## 2b) Calculate and update derived metrics for ensemble AIPW
      ## ────────────────────────────────────────────────────────────────
      
      # Only if Unadjust_se and Unadjust_est exist in df
      if ("Unadjust_se" %in% names(df) && "Unadjust_est" %in% names(df)) {
        unadjust_se = df[idx[1], "Unadjust_se"]
        unadjust_est = df[idx[1], "Unadjust_est"]
        
        if (suffix == "") {
          pg_col = paste0("How much precision gain can ", method, " provide?")
          diff_col = paste0("The difference between unadjusted and ", method, " point estimates")
        } else {
          suffix_clean = paste0("_", suffix)
          pg_col = paste0("How much precision gain can ", method, suffix_clean, " provide?")
          diff_col = paste0("The difference between unadjusted and ", method, suffix_clean, " point estimates")
        }
        
        # Add derived metric columns if they don't exist
        if (!pg_col %in% names(df)) {
          df[[pg_col]] = NA_real_
        }
        if (!diff_col %in% names(df)) {
          df[[diff_col]] = NA_real_
        }
        
        # Calculate precision gain
        if (!is.na(aipw_se) && !is.na(unadjust_se) && unadjust_se != 0) {
          df[idx[1], pg_col] = (aipw_se / unadjust_se)^2
        }
        
        # Calculate point estimate difference (using unadjust_se only)
        if (!is.na(aipw_est) && !is.na(unadjust_est) && !is.na(unadjust_se) && unadjust_se > 0) {
          df[idx[1], diff_col] = (aipw_est - unadjust_est) / unadjust_se
        }
      }
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## 2c) Update individual SL method columns
    ## ────────────────────────────────────────────────────────────────
    
    for (m in sl_members) {
      old_est = paste0("Est_", m)
      old_se  = paste0("SE_",  m)
      
      # Only process if these columns exist in results
      if (old_est %in% names(row_i) && old_se %in% names(row_i)) {
        # Clean method name for column naming (e.g., AIPW_SL_glm -> SL_glm_AIPW)
        method_clean = gsub("^AIPW_", "", m)
        
        if (suffix == "") {
          new_est = paste0(method_clean, "_", method, "_est")
          new_se  = paste0(method_clean, "_", method, "_se")
          new_pval = paste0(method_clean, "_", method, "_pval")
        } else {
          new_est = paste0(method_clean, "_", method, "_", suffix, "_est")
          new_se  = paste0(method_clean, "_", method, "_", suffix, "_se")
          new_pval = paste0(method_clean, "_", method, "_", suffix, "_pval")
        }
        
        # Add columns if they don't exist
        if (!new_est %in% names(df)) {
          df[[new_est]] = NA_real_
        }
        if (!new_se %in% names(df)) {
          df[[new_se]] = NA_real_
        }
        if (!new_pval %in% names(df)) {
          df[[new_pval]] = NA_real_
        }
        
        # Update values
        df[idx[1], new_est] = row_i[[old_est]]
        df[idx[1], new_se] = row_i[[old_se]]
        
        # Calculate p-value
        method_est = row_i[[old_est]]
        method_se = row_i[[old_se]]
        if (!is.na(method_est) && !is.na(method_se) && method_se > 0) {
          df[idx[1], new_pval] = 2 * pnorm(-abs(method_est / method_se))
        }
        
        ## ────────────────────────────────────────────────────────────────
        ## 2d) Calculate and update derived metrics for individual methods
        ## ────────────────────────────────────────────────────────────────
        
        # Only if Unadjust_se and Unadjust_est exist in df
        if ("Unadjust_se" %in% names(df) && "Unadjust_est" %in% names(df)) {
          unadjust_se = df[idx[1], "Unadjust_se"]
          unadjust_est = df[idx[1], "Unadjust_est"]
          
          if (suffix == "") {
            pg_col_method = paste0("How much precision gain can ", method_clean, "_", method, " provide?")
            diff_col_method = paste0("The difference between unadjusted and ", method_clean, "_", method, " point estimates")
          } else {
            pg_col_method = paste0("How much precision gain can ", method_clean, "_", method, "_", suffix, " provide?")
            diff_col_method = paste0("The difference between unadjusted and ", method_clean, "_", method, "_", suffix, " point estimates")
          }
          
          # Add derived metric columns if they don't exist
          if (!pg_col_method %in% names(df)) {
            df[[pg_col_method]] = NA_real_
          }
          if (!diff_col_method %in% names(df)) {
            df[[diff_col_method]] = NA_real_
          }
          
          # Calculate precision gain for this method
          if (!is.na(method_se) && !is.na(unadjust_se) && unadjust_se != 0) {
            df[idx[1], pg_col_method] = (method_se / unadjust_se)^2
          }
          
          # Calculate point estimate difference for this method
          if (!is.na(method_est) && !is.na(unadjust_est) && !is.na(unadjust_se) && unadjust_se > 0) {
            df[idx[1], diff_col_method] = (method_est - unadjust_est) / unadjust_se
          }
        }
      }
    }
  }
  
  df
}
```

## update_df_ipw()
```{r}
update_df_ipw = function(trial_no,
                         outcome_type,
                         results,
                         suffix = "",
                         contrast = "diff",
                         df = df_comparison) {
  
  library(dplyr)
  
  ## ────────────────────────────────────────────────────────────────
  ## 0) Check if all N_Covariates are 0 - if so, skip update entirely
  ##    Otherwise, filter to only rows with covariates
  ## ────────────────────────────────────────────────────────────────
  if (all(results$N_Covariates == 0)) {
    cat("Skipping IPW update for trial", trial_no, "- All outcomes have N_Covariates = 0\n")
    return(df)
  }
  
  # Store original results for outcome_type mapping
  results_original = results
  
  # Filter to only rows with covariates
  results_with_covariates = results[results$N_Covariates > 0, ]
  
  if (nrow(results_with_covariates) == 0) {
    cat("Skipping IPW update for trial", trial_no, "- No outcomes with covariates after filtering\n")
    return(df)
  }
  
  if (nrow(results_with_covariates) < nrow(results)) {
    cat("Note: Processing", nrow(results_with_covariates), "out of", nrow(results), 
        "outcomes (skipping", nrow(results) - nrow(results_with_covariates), "with N_Covariates = 0)\n")
  }
  
  # Use filtered results for the rest of the function
  results = results_with_covariates
  
  ## ────────────────────────────────────────────────────────────────
  ## 1)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  
  # Determine the multiplier (number of comparisons per outcome)
  # This is always nrow(results_original) / length(outcome_type)
  multiplier = nrow(results_original) / length(outcome_type)
  
  if (multiplier != round(multiplier)) {
    stop("Number of rows in results (", nrow(results_original), 
         ") is not a multiple of length of outcome_type (", length(outcome_type), ")")
  }
  
  # Create outcome_type mapping for filtered results
  # For each row in results, find which outcome_type it corresponds to
  outcome_type_expanded = rep(outcome_type, each = multiplier)
  
  # Now subset this expanded vector to match the filtered results
  # We need to find the indices of results_with_covariates in results_original
  original_indices = match(
    paste(results_with_covariates$Outcome, 
          results_with_covariates$Treatment, 
          results_with_covariates$Control),
    paste(results_original$Outcome, 
          results_original$Treatment, 
          results_original$Control)
  )
  
  outcome_type_filtered = outcome_type_expanded[original_indices]
  
  unique_outcomes = unique(results$Outcome)
  
  # Create mapping based on filtered data
  outcome_type_map = tibble(
    Outcome = results$Outcome,
    `Outcome Type` = outcome_type_filtered
  ) %>%
    distinct(Outcome, .keep_all = TRUE)
  
  ## ────────────────────────────────────────────────────────────────
  ## 2) Process each row in results and update IPW columns
  ## ────────────────────────────────────────────────────────────────
  
  for (i in seq_len(nrow(results))) {
    row_i = results[i, ]
    
    # Find matching row in df
    idx = which(
      df$Trial_No == trial_no &
        df$Outcome   == row_i$Outcome &
        df$Treatment == row_i$Treatment &
        df$Control   == row_i$Control
    )
    
    if (length(idx) == 0) {
      warning("No matching row found in df for Trial_No=", trial_no, 
              ", Outcome=", row_i$Outcome, ", Treatment=", row_i$Treatment)
      next
    }
    
    ## ────────────────────────────────────────────────────────────────
    ## 2a) Update IPW estimate columns (if Est_IPW exists)
    ## ────────────────────────────────────────────────────────────────
    
    if ("Est_IPW" %in% names(row_i)) {
      if (suffix == "") {
        ipw_est_col = "IPW_est"
        ipw_se_col = "IPW_se"
        ipw_pval_col = "IPW_pval"
      } else {
        suffix_clean = paste0("_", suffix)
        ipw_est_col = paste0("IPW", suffix_clean, "_est")
        ipw_se_col = paste0("IPW", suffix_clean, "_se")
        ipw_pval_col = paste0("IPW", suffix_clean, "_pval")
      }
      
      # Add columns if they don't exist
      if (!ipw_est_col %in% names(df)) {
        df[[ipw_est_col]] = NA_real_
      }
      if (!ipw_se_col %in% names(df)) {
        df[[ipw_se_col]] = NA_real_
      }
      if (!ipw_pval_col %in% names(df)) {
        df[[ipw_pval_col]] = NA_real_
      }
      
      # Update values
      df[idx[1], ipw_est_col] = row_i$Est_IPW
      df[idx[1], ipw_se_col] = row_i$SE_IPW
      
      # Calculate p-value
      ipw_est = row_i$Est_IPW
      ipw_se = row_i$SE_IPW
      if (!is.na(ipw_est) && !is.na(ipw_se) && ipw_se > 0) {
        df[idx[1], ipw_pval_col] = 2 * pnorm(-abs(ipw_est / ipw_se))
      }
      
      ## ────────────────────────────────────────────────────────────────
      ## 2b) Calculate and update derived metrics for IPW
      ## ────────────────────────────────────────────────────────────────
      
      # Only if Unadjust_se and Unadjust_est exist in df
      if ("Unadjust_se" %in% names(df) && "Unadjust_est" %in% names(df)) {
        unadjust_se = df[idx[1], "Unadjust_se"]
        unadjust_est = df[idx[1], "Unadjust_est"]
        
        if (suffix == "") {
          pg_col = "How much precision gain can IPW provide?"
          diff_col = "The difference between unadjusted and IPW point estimates"
        } else {
          suffix_clean = paste0("_", suffix)
          pg_col = paste0("How much precision gain can IPW", suffix_clean, " provide?")
          diff_col = paste0("The difference between unadjusted and IPW", suffix_clean, " point estimates")
        }
        
        # Add derived metric columns if they don't exist
        if (!pg_col %in% names(df)) {
          df[[pg_col]] = NA_real_
        }
        if (!diff_col %in% names(df)) {
          df[[diff_col]] = NA_real_
        }
        
        # Calculate precision gain
        if (!is.na(ipw_se) && !is.na(unadjust_se) && unadjust_se != 0) {
          df[idx[1], pg_col] = (ipw_se / unadjust_se)^2
        }
        
        # Calculate point estimate difference (using unadjust_se only)
        if (!is.na(ipw_est) && !is.na(unadjust_est) && !is.na(unadjust_se) && unadjust_se > 0) {
          df[idx[1], diff_col] = (ipw_est - unadjust_est) / unadjust_se
        }
      }
    }
  }
  
  df
}
```

## process_single_trial_tmle()
```{r}
process_single_trial_tmle = function(trial_no,
                                     df,
                                     manual_covariates,
                                     outcome_type_vec,
                                     selection = TRUE,
                                     variable_selection_type = 2,
                                     run_individual_SL = TRUE,
                                     run_ensemble_SL = F,
                                     q_library = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                                     g_library = "SL.mean",
                                     n_cores = parallel::detectCores() - 2,
                                     K = 5,
                                     df_comparison) {
  
  # Determine suffix based on selection and variable_selection_type
  if (selection) {
    suffix = paste0("VS", variable_selection_type)
  } else {
    suffix = ""
  }
  
  cat("\n========================================\n")
  cat("Processing Trial", trial_no, "with TMLE\n")
  cat("Selection:", selection, "| Type:", variable_selection_type, "| Suffix:", suffix, "\n")
  cat("Ensemble SL:", run_ensemble_SL, "| Individual SL:", run_individual_SL, "\n")
  cat("========================================\n")
  
  # Run analyze_rct_tmle
  res_tmle = analyze_rct_tmle(
    df, 
    selection = selection, 
    variable_selection_type = variable_selection_type,
    manual_covariates = manual_covariates,
    run_individual_SL = run_individual_SL,
    run_ensemble_SL = run_ensemble_SL,
    q_library = q_library,
    g_library = g_library,
    n_cores = n_cores,
    K = K
  )
  
  # Update df_comparison with the results
  df_comparison = update_df_tmle(
    trial_no = trial_no,
    outcome_type = outcome_type_vec,
    results = res_tmle,
    suffix = suffix,
    contrast = "diff",
    df = df_comparison
  )
  
  cat("✓ Successfully processed Trial", trial_no, "with TMLE\n")
  
  return(df_comparison)
}
```

## process_single_trial_aipw()
```{r}
process_single_trial_aipw = function(trial_no,
                                     df,
                                     manual_covariates,
                                     outcome_type_vec,
                                     selection = TRUE,
                                     variable_selection_type = 2,
                                     run_individual_SL = TRUE,
                                     run_ensemble_SL = FALSE,
                                     Q_SL_library = c("SL.glm", "SL.mean", "SL.rpart", "SL.gam", "SL.glmnet"),
                                     g_SL_library = "SL.mean",
                                     k_split = 5,
                                     g_bound = 0.05,
                                     seed = 123,
                                     df_comparison) {
  
  cat("\n========================================\n")
  cat("Processing Trial", trial_no, "\n")
  cat("========================================\n")
  
  ## ────────────────────────────────────────────────────────────────
  ## 1) Run AIPW analysis
  ## ────────────────────────────────────────────────────────────────
  
  cat("\n--- Running AIPW Analysis ---\n")
  
    # Determine suffix based on selection and variable_selection_type
  if (selection) {
    suffix = paste0("VS", variable_selection_type)
  } else {
    suffix = ""
  }
  
  results_aipw = tryCatch({
    analyze_rct_aipw(
      df = df,
      selection = selection,
      variable_selection_type = variable_selection_type,
      manual_covariates = manual_covariates,
      Q_SL_library = Q_SL_library,
      g_SL_library = g_SL_library,
      run_individual_SL = run_individual_SL,
      run_ensemble_SL = run_ensemble_SL,
      k_split = k_split,
      g_bound = g_bound,
      seed = seed
    )
  }, error = function(e) {
    message("✗ AIPW analysis failed for trial ", trial_no, ": ", e$message)
    return(NULL)
  })
  
  if (is.null(results_aipw)) {
    message("Skipping trial ", trial_no, " - AIPW analysis returned NULL")
    return(df_comparison)
  }
  
  ## ────────────────────────────────────────────────────────────────
  ## 2) Update df_comparison with AIPW results
  ## ────────────────────────────────────────────────────────────────
  
  cat("\n--- Updating Comparison DataFrame ---\n")
  
  df_comparison = tryCatch({
    update_df_aipw(
      trial_no = trial_no,
      outcome_type = outcome_type_vec,
      results = results_aipw,
      method = "AIPW",
      suffix = suffix,
      df = df_comparison
    )
  }, error = function(e) {
    message("✗ Failed to update df_comparison for trial ", trial_no, ": ", e$message)
    return(df_comparison)
  })
  
  cat("✓ Trial", trial_no, "completed successfully\n")
  
  return(df_comparison)
}
```

## process_single_trial_ipw()
```{r}
process_single_trial_ipw = function(trial_no,
                                    df,
                                    manual_covariates,
                                    outcome_type_vec,
                                    selection = TRUE,
                                    variable_selection_type = 2,
                                    weight_method = "IPW",   # PSweight keywords: "IPW","treated","overlap","matching","entropy"
                                    n_select = 3,
                                    seed = 123,
                                    df_comparison) {
  
  cat("\n========================================\n")
  cat("Processing Trial", trial_no, "\n")
  cat("========================================\n")
  
  ## ────────────────────────────────────────────────────────────────
  ## 1) Run IPW analysis (PSweight)
  ## ────────────────────────────────────────────────────────────────
  cat("\n--- Running IPW Analysis ---\n")
  
  results_ipw = tryCatch({
    analyze_rct_ipw(
      df = df,
      selection = selection,
      variable_selection_type = variable_selection_type,
      manual_covariates = manual_covariates,
      weight_method = weight_method,   # pass straight through
      n_select = n_select,
      seed = seed
    )
  }, error = function(e) {
    message("✗ IPW analysis failed for trial ", trial_no, ": ", e$message)
    return(NULL)
  })
  
  if (is.null(results_ipw)) {
    message("Skipping trial ", trial_no, " - IPW analysis returned NULL")
    return(df_comparison)
  }
  
  ## ────────────────────────────────────────────────────────────────
  ## 2) Determine suffix based on selection settings
  ## ────────────────────────────────────────────────────────────────
  if (selection) {
    if (variable_selection_type == 1) {
      suffix = "VS1"
    } else if (variable_selection_type == 2) {
      suffix = "VS2"
    } else {
      suffix = ""
    }
  } else {
    suffix = ""
  }
  
  ## ────────────────────────────────────────────────────────────────
  ## 3) Update df_comparison with IPW results
  ## ────────────────────────────────────────────────────────────────
  cat("\n--- Updating Comparison DataFrame ---\n")
  
  df_comparison = tryCatch({
    update_df_ipw(
      trial_no = trial_no,
      outcome_type = outcome_type_vec,
      results = results_ipw,
      suffix = suffix,
      df = df_comparison
    )
  }, error = function(e) {
    message("✗ Failed to update df_comparison for trial ", trial_no, ": ", e$message)
    return(df_comparison)
  })
  
  cat("✓ Trial", trial_no, "completed successfully\n")
  return(df_comparison)
}

```

## process_single_trial_dml()
```{r}
process_single_trial_dml = function(trial_no,
                                    df,
                                    manual_covariates,
                                    outcome_type_vec,
                                    selection = TRUE,
                                    variable_selection_type = 2,
                                    run_individual_SL = TRUE,
                                    run_ensemble_SL = TRUE,
                                    SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                                    n_cores = parallel::detectCores() - 2,
                                    K = 5,
                                    df_comparison) {
  
  # Determine suffix based on selection and variable_selection_type
  if (selection) {
    suffix = paste0("VS", variable_selection_type)
  } else {
    suffix = ""
  }
  
  cat("\n========================================\n")
  cat("Processing Trial", trial_no, "with DML\n")
  cat("Selection:", selection, "| Type:", variable_selection_type, "| Suffix:", suffix, "\n")
  cat("Ensemble SL:", run_ensemble_SL, "| Individual SL:", run_individual_SL, "\n")
  cat("========================================\n")
  
  # Run analyze_rct_dml
  res_dml = analyze_rct_dml(
    df, 
    selection = selection, 
    variable_selection_type = variable_selection_type,
    manual_covariates = manual_covariates,
    run_individual_SL = run_individual_SL,
    run_ensemble_SL = run_ensemble_SL,
    SL_methods = SL_methods,
    n_cores = n_cores,
    K = K
  )
  
  # Update df_comparison with the results
  df_comparison = update_df_dml(
    trial_no = trial_no,
    outcome_type = outcome_type_vec,
    results = res_dml,
    suffix = suffix,
    ensemble = 2,  # ensemble = 2 for DML
    contrast = "diff",
    df = df_comparison,
    update_ensemble_SL = run_ensemble_SL,
    update_individual_SL = run_individual_SL
  )
  
  cat("✓ Successfully processed Trial", trial_no, "with DML\n")
  
  return(df_comparison)
}
```

## run_tmle_analysis()
```{r}
run_tmle_analysis = function(df_indices = 1:50, 
                             selection = TRUE, 
                             variable_selection_type = 2,
                             run_individual_SL = TRUE,
                             run_ensemble_SL = TRUE,
                             q_library = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                             g_library = "SL.mean",
                             n_cores = parallel::detectCores() - 2,
                             K = 5,
                             df_comparison) {
  
  # Initialize df_comparison if NULL
  if (is.null(df_comparison)) {
    df_comparison = data.frame()
  }
  
  manual_covariates_list = list(
    df1 = c("X_Age_0m", "X_Weight_0m"),
    df2 = c("X_agegrp_0d", "X_sex_0d"),
    df3 = c("X_age_0m", "X_sex_0m"),
    df4 = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w"),
    df5 = c("X_age_0m", "X_sex_0m"),
    df6 = c("X_age_0m", "X_sex_0m"),
    df7 = c("X_Age_0h", "X_Gender_0h"),
    df8 = c("X_Age_0d", "X_Sex_0d"),
    df9 = c("X_age_0d"),
    df10 = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d"),
    df11 = c("X_sex_0w"),
    df12 = c("X_hba1c_cat_control_0m", "X_rural_site_0m", "X_age_0m", "X_sex_0m", "X_weight_0m"),
    df13 = c("X_AGE_0min"),
    df14 = c("X_center_0w", "X_sex_0w", "X_age_0w"),
    df15 = character(0),
    df16 = c("X_age_0w", "X_sex_0w"),
    df17 = c("X_age_0w", "X_sex_0w", "X_BMI_0w"),
    df18 = c("X_AgeCat_0m", "X_Gender_0m"),
    df19 = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d"),
    df20 = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w"),
    df21 = character(0),
    df22 = c("X_age_0w"),
    df23 = character(0),
    df24 = c("X_Age_0d", "X_Weight_0d"),
    df25 = c("X_Sex_0w", "X_BMI_0w"),
    df26 = c("X_Agecat_0m", "X_weight_0m"),
    df27 = character(0),
    df28 = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m"),
    df29 = c("X_age_0w", "X_sex_0w", "X_on_art_0w"),
    df30 = c("X_Sex_0d", "X_Age_0d"),
    df31 = c("X_age_0w"),
    df32 = c("X_sex_0m", "X_age_0m"),
    df33 = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w"),
    df34 = c("X_wt_0d", "X_sex_0d"),
    df35 = c("X_BMI_0w"),
    df36 = character(0),
    df37 = c("X_site_0d", "X_age_0d", "X_gender_0d"),
    df38 = c("X_age_0w", "X_weight_0w", "X_gender_0w"),
    df39 = c("X_age_0w", "X_sex_0w", "X_substance_0w"),
    df40 = c("X_age_0d", "X_gender_0d", "X_BMI_0d"),
    df41 = c("X_gender_0h", "X_BMI_0h", "X_age_0h"),
    df42 = c("X_gender_0h", "X_bmi_0h", "X_age_0h"),
    df43 = c("X_Age_0d", "X_BMI_0d"),
    df44 = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m"),
    df45 = c("X_weight_8w", "X_store_0w"),
    df46 = c("X_Age_0y"),
    df47 = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h"),
    df48 = c("X_AGE_0w", "X_SEX_0w", "X_STATUS_0w", "X_WEIGHT_0w"),
    df49 = c("X_gestAge_0w", "X_birthWt_0d"),
    df50 = c("X_sex_0w", "X_inherit_0w", "X_age_0w", "X_weight_0w")
  )
  
  outcome_type_list = list(
    df1 = rep("continuous", 15),
    df2 = c("time to event", "binary", "binary"),
    df3 = c("binary", "time to event", rep("binary", 4), "continuous", "binary"),
    df4 = c("continuous", "continuous", "continuous", "continuous"),
    df5 = c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"),
    df6 = rep("continuous", 21),
    df7 = rep("continuous", 8),
    df8 = rep("binary", 6),
    df9 = c("binary", rep("continuous", 4), rep("binary", 10), "continuous", rep("binary", 2), "continuous", rep("binary", 2)),
    df10 = c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)),
    df11 = rep("continuous", 11),
    df12 = c(rep("continuous", 9), rep("binary", 6), rep("continuous", 9), rep("binary", 2), rep("continuous", 13), rep("binary", 6), rep("continuous", 6)),
    df13 = c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5)),
    df14 = c(rep("continuous", 23-5), rep("binary", 5)),
    df15 = rep("continuous", 14),
    df16 = rep("continuous", 5),
    df17 = rep("continuous", 4),
    df18 = c("time to event", rep("continuous", 12-1)),
    df19 = c(rep("continuous", 11-1), "binary"),
    df20 = rep("continuous", 10),
    df21 = c("time to event", rep("binary", 4), "continuous"),
    df22 = c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"),
    df23 = c("time to event", "time to event", rep("continuous", 14 - 2)),
    df24 = c("binary", "continuous", "continuous"),
    df25 = c(rep("continuous", 11), "binary", rep("continuous", 5)),
    df26 = c("continuous", "binary", "categorical", rep("continuous", 7-3)),
    df27 = c("categorical", "binary", "continuous", "categorical", "continuous", "continuous", "binary", "continuous"),
    df28 = c("binary", rep("continuous", 7), "binary", "continuous", "binary", rep("continuous", 2)),
    df29 = c("time to event", "binary", "binary", "continuous"),
    df30 = c(rep("continuous", 6), "binary", rep("continuous", 2)),
    df31 = c("time to event", "continuous", "continuous", "binary", "binary"),
    df32 = c(rep("continuous", 4), "binary", "continuous", rep("binary", 3)),
    df33 = c("continuous", "binary"),
    df34 = c("binary", "continuous", rep("binary", 6)),
    df35 = c("continuous", "continuous", "continuous", "binary", rep("continuous", 6)),
    df36 = rep("continuous", 11),
    df37 = rep("binary", 1),
    df38 = c("time to event", "continuous", "continuous"),
    df39 = c("time to event"),
    df40 = c("time to event", "continuous", "continuous", "binary", "continuous", "continuous", "binary"),
    df41 = rep("binary", 5),
    df42 = c("time to event", rep("continuous", 5)),
    df43 = c("time to event", rep("continuous", 3), "binary"),
    df44 = c("binary", rep("continuous", 3)),
    df45 = rep("continuous", 27),
    df46 = rep("continuous", 6),
    df47 = c("binary", "continuous", "binary", "binary"),
    df48 = c("continuous"),
    df49 = c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)),
    df50 = c("time to event", "continuous")
  )
  
  # Process each trial sequentially
  for (i in df_indices) {
    df_name = paste0("df", i)
    df = get(df_name)
    
    manual_covs = manual_covariates_list[[df_name]]
    if (is.null(manual_covs)) {
      manual_covs = character(0)
    }
    
    outcome_type_vec = outcome_type_list[[df_name]]
    if (is.null(outcome_type_vec) || length(outcome_type_vec) == 0) {
      message("Warning: No outcome types found for ", df_name, " - skipping")
      next
    }
    
    tryCatch({
      df_comparison = process_single_trial_tmle(
        trial_no = i,
        df = df,
        manual_covariates = manual_covs,
        outcome_type_vec = outcome_type_vec,
        selection = selection,
        variable_selection_type = variable_selection_type,
        run_individual_SL = run_individual_SL,
        run_ensemble_SL = run_ensemble_SL,
        q_library = q_library,
        g_library = g_library,
        n_cores = n_cores,
        K = K,
        df_comparison = df_comparison
      )
    }, error = function(e) {
      message("✗ Error in ", df_name, ": ", e$message)
    })
  }
  
  cat("\n========================================\n")
  cat("All trials processed\n")
  cat("========================================\n")
  
  return(df_comparison)
}
```





## run_aipw_analysis()
```{r}
run_aipw_analysis = function(df_indices = 1:50, 
                             selection = TRUE, 
                             variable_selection_type = 2,
                             run_individual_SL = TRUE,
                             run_ensemble_SL = FALSE,
                             Q_SL_library = c("SL.glm", "SL.mean", "SL.rpart", "SL.gam", "SL.glmnet"),
                             g_SL_library = "SL.mean",
                             k_split = 5,
                             g_bound = 0.05,
                             seed = 123,
                             df_comparison) {
  
  # Initialize df_comparison if NULL
  if (is.null(df_comparison)) {
    df_comparison = data.frame()
  }
  
  manual_covariates_list = list(
    df1 = c("X_Age_0m", "X_Weight_0m"),
    df2 = c("X_agegrp_0d", "X_sex_0d"),
    df3 = c("X_age_0m", "X_sex_0m"),
    df4 = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w"),
    df5 = c("X_age_0m", "X_sex_0m"),
    df6 = c("X_age_0m", "X_sex_0m"),
    df7 = c("X_Age_0h", "X_Gender_0h"),
    df8 = c("X_Age_0d", "X_Sex_0d"),
    df9 = c("X_age_0d"),
    df10 = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d"),
    df11 = c("X_sex_0w"),
    df12 = c("X_hba1c_cat_control_0m", "X_rural_site_0m", "X_age_0m", "X_sex_0m", "X_weight_0m"),
    df13 = c("X_AGE_0min"),
    df14 = c("X_center_0w", "X_sex_0w", "X_age_0w"),
    df15 = character(0),
    df16 = c("X_age_0w", "X_sex_0w"),
    df17 = c("X_age_0w", "X_sex_0w", "X_BMI_0w"),
    df18 = c("X_AgeCat_0m", "X_Gender_0m"),
    df19 = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d"),
    df20 = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w"),
    df21 = character(0),
    df22 = c("X_age_0w"),
    df23 = character(0),
    df24 = c("X_Age_0d", "X_Weight_0d"),
    df25 = c("X_Sex_0w", "X_BMI_0w"),
    df26 = c("X_Agecat_0m", "X_weight_0m"),
    df27 = character(0),
    df28 = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m"),
    df29 = c("X_age_0w", "X_sex_0w", "X_on_art_0w"),
    df30 = c("X_Sex_0d", "X_Age_0d"),
    df31 = c("X_age_0w"),
    df32 = c("X_sex_0m", "X_age_0m"),
    df33 = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w"),
    df34 = c("X_wt_0d", "X_sex_0d"),
    df35 = c("X_BMI_0w"),
    df36 = character(0),
    df37 = c("X_site_0d", "X_age_0d", "X_gender_0d"),
    df38 = c("X_age_0w", "X_weight_0w", "X_gender_0w"),
    df39 = c("X_age_0w", "X_sex_0w", "X_substance_0w"),
    df40 = c("X_age_0d", "X_gender_0d", "X_BMI_0d"),
    df41 = c("X_gender_0h", "X_BMI_0h", "X_age_0h"),
    df42 = c("X_gender_0h", "X_bmi_0h", "X_age_0h"),
    df43 = c("X_Age_0d", "X_BMI_0d"),
    df44 = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m"),
    df45 = c("X_weight_8w", "X_store_0w"),
    df46 = c("X_Age_0y"),
    df47 = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h"),
    df48 = c("X_AGE_0w", "X_SEX_0w", "X_STATUS_0w", "X_WEIGHT_0w"),
    df49 = c("X_gestAge_0w", "X_birthWt_0d"),
    df50 = c("X_sex_0w", "X_inherit_0w", "X_age_0w", "X_weight_0w")
  )
  
  outcome_type_list = list(
    df1 = rep("continuous", 15),
    df2 = c("time to event", "binary", "binary"),
    df3 = c("binary", "time to event", rep("binary", 4), "continuous", "binary"),
    df4 = c("continuous", "continuous", "continuous", "continuous"),
    df5 = c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"),
    df6 = rep("continuous", 21),
    df7 = rep("continuous", 8),
    df8 = rep("binary", 6),
    df9 = c("binary", rep("continuous", 4), rep("binary", 10), "continuous", rep("binary", 2), "continuous", rep("binary", 2)),
    df10 = c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)),
    df11 = rep("continuous", 11),
    df12 = c(rep("continuous", 9), rep("binary", 6), rep("continuous", 9), rep("binary", 2), rep("continuous", 13), rep("binary", 6), rep("continuous", 6)),
    df13 = c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5)),
    df14 = c(rep("continuous", 23-5), rep("binary", 5)),
    df15 = rep("continuous", 14),
    df16 = rep("continuous", 5),
    df17 = rep("continuous", 4),
    df18 = c("time to event", rep("continuous", 12-1)),
    df19 = c(rep("continuous", 11-1), "binary"),
    df20 = rep("continuous", 10),
    df21 = c("time to event", rep("binary", 4), "continuous"),
    df22 = c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"),
    df23 = c("time to event", "time to event", rep("continuous", 14 - 2)),
    df24 = c("binary", "continuous", "continuous"),
    df25 = c(rep("continuous", 11), "binary", rep("continuous", 5)),
    df26 = c("continuous", "binary", "categorical", rep("continuous", 7-3)),
    df27 = c("categorical", "binary", "continuous", "categorical", "continuous", "continuous", "binary", "continuous"),
    df28 = c("binary", rep("continuous", 7), "binary", "continuous", "binary", rep("continuous", 2)),
    df29 = c("time to event", "binary", "binary", "continuous"),
    df30 = c(rep("continuous", 6), "binary", rep("continuous", 2)),
    df31 = c("time to event", "continuous", "continuous", "binary", "binary"),
    df32 = c(rep("continuous", 4), "binary", "continuous", rep("binary", 3)),
    df33 = c("continuous", "binary"),
    df34 = c("binary", "continuous", rep("binary", 6)),
    df35 = c("continuous", "continuous", "continuous", "binary", rep("continuous", 6)),
    df36 = rep("continuous", 11),
    df37 = rep("binary", 1),
    df38 = c("time to event", "continuous", "continuous"),
    df39 = c("time to event"),
    df40 = c("time to event", "continuous", "continuous", "binary", "continuous", "continuous", "binary"),
    df41 = rep("binary", 5),
    df42 = c("time to event", rep("continuous", 5)),
    df43 = c("time to event", rep("continuous", 3), "binary"),
    df44 = c("binary", rep("continuous", 3)),
    df45 = rep("continuous", 27),
    df46 = rep("continuous", 6),
    df47 = c("binary", "continuous", "binary", "binary"),
    df48 = c("continuous"),
    df49 = c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)),
    df50 = c("time to event", "continuous")
  )
  
  # Process each trial sequentially
  for (i in df_indices) {
    df_name = paste0("df", i)
    df = get(df_name)
    
    manual_covs = manual_covariates_list[[df_name]]
    if (is.null(manual_covs)) {
      manual_covs = character(0)
    }
    
    outcome_type_vec = outcome_type_list[[df_name]]
    if (is.null(outcome_type_vec) || length(outcome_type_vec) == 0) {
      message("Warning: No outcome types found for ", df_name, " - skipping")
      next
    }
    
    tryCatch({
      df_comparison = process_single_trial_aipw(
        trial_no = i,
        df = df,
        manual_covariates = manual_covs,
        outcome_type_vec = outcome_type_vec,
        selection = selection,
        variable_selection_type = variable_selection_type,
        run_individual_SL = run_individual_SL,
        run_ensemble_SL = run_ensemble_SL,
        Q_SL_library = Q_SL_library,
        g_SL_library = g_SL_library,
        k_split = k_split,
        g_bound = g_bound,
        seed = seed,
        df_comparison = df_comparison
      )
    }, error = function(e) {
      message("✗ Error in ", df_name, ": ", e$message)
    })
  }
  
  cat("\n========================================\n")
  cat("All trials processed\n")
  cat("========================================\n")
  
  return(df_comparison)
}
```




## run_ipw_analysis()
```{r}
run_ipw_analysis = function(df_indices = 1:50, 
                            selection = TRUE, 
                            variable_selection_type = 2,
                            weight_method = "IPW",   # PSweight keywords only
                            n_select = 3,
                            seed = 123,
                            df_comparison) {
  
  # Initialize df_comparison if NULL
  if (is.null(df_comparison)) {
    df_comparison = data.frame()
  }
  
  manual_covariates_list = list(
    df1 = c("X_Age_0m", "X_Weight_0m"),
    df2 = c("X_agegrp_0d", "X_sex_0d"),
    df3 = c("X_age_0m", "X_sex_0m"),
    df4 = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w"),
    df5 = c("X_age_0m", "X_sex_0m"),
    df6 = c("X_age_0m", "X_sex_0m"),
    df7 = c("X_Age_0h", "X_Gender_0h"),
    df8 = c("X_Age_0d", "X_Sex_0d"),
    df9 = c("X_age_0d"),
    df10 = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d"),
    df11 = c("X_sex_0w"),
    df12 = c("X_hba1c_cat_control_0m", "X_rural_site_0m", "X_age_0m", "X_sex_0m", "X_weight_0m"),
    df13 = c("X_AGE_0min"),
    df14 = c("X_center_0w", "X_sex_0w", "X_age_0w"),
    df15 = character(0),
    df16 = c("X_age_0w", "X_sex_0w"),
    df17 = c("X_age_0w", "X_sex_0w", "X_BMI_0w"),
    df18 = c("X_AgeCat_0m", "X_Gender_0m"),
    df19 = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d"),
    df20 = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w"),
    df21 = character(0),
    df22 = c("X_age_0w"),
    df23 = character(0),
    df24 = c("X_Age_0d", "X_Weight_0d"),
    df25 = c("X_Sex_0w", "X_BMI_0w"),
    df26 = c("X_Agecat_0m", "X_weight_0m"),
    df27 = character(0),
    df28 = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m"),
    df29 = c("X_age_0w", "X_sex_0w", "X_on_art_0w"),
    df30 = c("X_Sex_0d", "X_Age_0d"),
    df31 = c("X_age_0w"),
    df32 = c("X_sex_0m", "X_age_0m"),
    df33 = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w"),
    df34 = c("X_wt_0d", "X_sex_0d"),
    df35 = c("X_BMI_0w"),
    df36 = character(0),
    df37 = c("X_site_0d", "X_age_0d", "X_gender_0d"),
    df38 = c("X_age_0w", "X_weight_0w", "X_gender_0w"),
    df39 = c("X_age_0w", "X_sex_0w", "X_substance_0w"),
    df40 = c("X_age_0d", "X_gender_0d", "X_BMI_0d"),
    df41 = c("X_gender_0h", "X_BMI_0h", "X_age_0h"),
    df42 = c("X_gender_0h", "X_bmi_0h", "X_age_0h"),
    df43 = c("X_Age_0d", "X_BMI_0d"),
    df44 = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m"),
    df45 = c("X_weight_8w", "X_store_0w"),
    df46 = c("X_Age_0y"),
    df47 = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h"),
    df48 = c("X_AGE_0w", "X_SEX_0w", "X_STATUS_0w", "X_WEIGHT_0w"),
    df49 = c("X_gestAge_0w", "X_birthWt_0d"),
    df50 = c("X_sex_0w", "X_inherit_0w", "X_age_0w", "X_weight_0w")
  )
  
  outcome_type_list = list(
    df1 = rep("continuous", 15),
    df2 = c("time to event", "binary", "binary"),
    df3 = c("binary", "time to event", rep("binary", 4), "continuous", "binary"),
    df4 = c("continuous", "continuous", "continuous", "continuous"),
    df5 = c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"),
    df6 = rep("continuous", 21),
    df7 = rep("continuous", 8),
    df8 = rep("binary", 6),
    df9 = c("binary", rep("continuous", 4), rep("binary", 10), "continuous", rep("binary", 2), "continuous", rep("binary", 2)),
    df10 = c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)),
    df11 = rep("continuous", 11),
    df12 = c(rep("continuous", 9), rep("binary", 6), rep("continuous", 9), rep("binary", 2), rep("continuous", 13), rep("binary", 6), rep("continuous", 6)),
    df13 = c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5)),
    df14 = c(rep("continuous", 23-5), rep("binary", 5)),
    df15 = rep("continuous", 14),
    df16 = rep("continuous", 5),
    df17 = rep("continuous", 4),
    df18 = c("time to event", rep("continuous", 12-1)),
    df19 = c(rep("continuous", 11-1), "binary"),
    df20 = rep("continuous", 10),
    df21 = c("time to event", rep("binary", 4), "continuous"),
    df22 = c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"),
    df23 = c("time to event", "time to event", rep("continuous", 14 - 2)),
    df24 = c("binary", "continuous", "continuous"),
    df25 = c(rep("continuous", 11), "binary", rep("continuous", 5)),
    df26 = c("continuous", "binary", "categorical", rep("continuous", 7-3)),
    df27 = c("categorical", "binary", "continuous", "categorical", "continuous", "continuous", "binary", "continuous"),
    df28 = c("binary", rep("continuous", 7), "binary", "continuous", "binary", rep("continuous", 2)),
    df29 = c("time to event", "binary", "binary", "continuous"),
    df30 = c(rep("continuous", 6), "binary", rep("continuous", 2)),
    df31 = c("time to event", "continuous", "continuous", "binary", "binary"),
    df32 = c(rep("continuous", 4), "binary", "continuous", rep("binary", 3)),
    df33 = c("continuous", "binary"),
    df34 = c("binary", "continuous", rep("binary", 6)),
    df35 = c("continuous", "continuous", "continuous", "binary", rep("continuous", 6)),
    df36 = rep("continuous", 11),
    df37 = rep("binary", 1),
    df38 = c("time to event", "continuous", "continuous"),
    df39 = c("time to event"),
    df40 = c("time to event", "continuous", "continuous", "binary", "continuous", "continuous", "binary"),
    df41 = rep("binary", 5),
    df42 = c("time to event", rep("continuous", 5)),
    df43 = c("time to event", rep("continuous", 3), "binary"),
    df44 = c("binary", rep("continuous", 3)),
    df45 = rep("continuous", 27),
    df46 = rep("continuous", 6),
    df47 = c("binary", "continuous", "binary", "binary"),
    df48 = c("continuous"),
    df49 = c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)),
    df50 = c("time to event", "continuous")
  )
  
  for (i in df_indices) {
    df_name = paste0("df", i)
    df = get(df_name)
    
    manual_covs = manual_covariates_list[[df_name]]
    if (is.null(manual_covs)) manual_covs = character(0)
    
    outcome_type_vec = outcome_type_list[[df_name]]
    if (is.null(outcome_type_vec) || length(outcome_type_vec) == 0) {
      message("Warning: No outcome types found for ", df_name, " - skipping")
      next
    }
    
    tryCatch({
      df_comparison = process_single_trial_ipw(
        trial_no = i,
        df = df,
        manual_covariates = manual_covs,
        outcome_type_vec = outcome_type_vec,
        selection = selection,
        variable_selection_type = variable_selection_type,
        weight_method = weight_method,  # pass PSweight keyword directly
        n_select = n_select,
        seed = seed,
        df_comparison = df_comparison
      )
    }, error = function(e) {
      message("✗ Error in ", df_name, ": ", e$message)
    })
  }
  
  cat("\n========================================\n")
  cat("All trials processed\n")
  cat("========================================\n")
  
  return(df_comparison)
}

```

## run_dml_analysis()
```{r}
run_dml_analysis = function(df_indices = 1:50, 
                            selection = TRUE, 
                            variable_selection_type = 2,
                            run_individual_SL = F,
                            run_ensemble_SL = TRUE,
                            SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.gam"),
                            n_cores = parallel::detectCores() - 2,
                            K = 5,
                            df_comparison) {
  
  # Initialize df_comparison if NULL
  if (is.null(df_comparison)) {
    df_comparison = data.frame()
  }
  
  manual_covariates_list = list(
    df1 = c("X_Age_0m", "X_Weight_0m"),
    df2 = c("X_agegrp_0d", "X_sex_0d"),
    df3 = c("X_age_0m", "X_sex_0m"),
    df4 = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w"),
    df5 = c("X_age_0m", "X_sex_0m"),
    df6 = c("X_age_0m", "X_sex_0m"),
    df7 = c("X_Age_0h", "X_Gender_0h"),
    df8 = c("X_Age_0d", "X_Sex_0d"),
    df9 = c("X_age_0d"),
    df10 = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d"),
    df11 = c("X_sex_0w"),
    df12 = c("X_hba1c_cat_control_0m", "X_rural_site_0m", "X_age_0m", "X_sex_0m", "X_weight_0m"),
    df13 = c("X_AGE_0min"),
    df14 = c("X_center_0w", "X_sex_0w", "X_age_0w"),
    df15 = character(0),
    df16 = c("X_age_0w", "X_sex_0w"),
    df17 = c("X_age_0w", "X_sex_0w", "X_BMI_0w"),
    df18 = c("X_AgeCat_0m", "X_Gender_0m"),
    df19 = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d"),
    df20 = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w"),
    df21 = character(0),
    df22 = c("X_age_0w"),
    df23 = character(0),
    df24 = c("X_Age_0d", "X_Weight_0d"),
    df25 = c("X_Sex_0w", "X_BMI_0w"),
    df26 = c("X_Agecat_0m", "X_weight_0m"),
    df27 = character(0),
    df28 = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m"),
    df29 = c("X_age_0w", "X_sex_0w", "X_on_art_0w"),
    df30 = c("X_Sex_0d", "X_Age_0d"),
    df31 = c("X_age_0w"),
    df32 = c("X_sex_0m", "X_age_0m"),
    df33 = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w"),
    df34 = c("X_wt_0d", "X_sex_0d"),
    df35 = c("X_BMI_0w"),
    df36 = character(0),
    df37 = c("X_site_0d", "X_age_0d", "X_gender_0d"),
    df38 = c("X_age_0w", "X_weight_0w", "X_gender_0w"),
    df39 = c("X_age_0w", "X_sex_0w", "X_substance_0w"),
    df40 = c("X_age_0d", "X_gender_0d", "X_BMI_0d"),
    df41 = c("X_gender_0h", "X_BMI_0h", "X_age_0h"),
    df42 = c("X_gender_0h", "X_bmi_0h", "X_age_0h"),
    df43 = c("X_Age_0d", "X_BMI_0d"),
    df44 = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m"),
    df45 = c("X_weight_8w", "X_store_0w"),
    df46 = c("X_Age_0y"),
    df47 = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h"),
    df48 = c("X_AGE_0w", "X_SEX_0w", "X_STATUS_0w", "X_WEIGHT_0w"),
    df49 = c("X_gestAge_0w", "X_birthWt_0d"),
    df50 = c("X_sex_0w", "X_inherit_0w", "X_age_0w", "X_weight_0w")
  )
  
  outcome_type_list = list(
    df1 = rep("continuous", 15),
    df2 = c("time to event", "binary", "binary"),
    df3 = c("binary", "time to event", rep("binary", 4), "continuous", "binary"),
    df4 = c("continuous", "continuous", "continuous", "continuous"),
    df5 = c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"),
    df6 = rep("continuous", 21),
    df7 = rep("continuous", 8),
    df8 = rep("binary", 6),
    df9 = c("binary", rep("continuous", 4), rep("binary", 10), "continuous", rep("binary", 2), "continuous", rep("binary", 2)),
    df10 = c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)),
    df11 = rep("continuous", 11),
    df12 = c(rep("continuous", 9), rep("binary", 6), rep("continuous", 9), rep("binary", 2), rep("continuous", 13), rep("binary", 6), rep("continuous", 6)),
    df13 = c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5)),
    df14 = c(rep("continuous", 23-5), rep("binary", 5)),
    df15 = rep("continuous", 14),
    df16 = rep("continuous", 5),
    df17 = rep("continuous", 4),
    df18 = c("time to event", rep("continuous", 12-1)),
    df19 = c(rep("continuous", 11-1), "binary"),
    df20 = rep("continuous", 10),
    df21 = c("time to event", rep("binary", 4), "continuous"),
    df22 = c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"),
    df23 = c("time to event", "time to event", rep("continuous", 14 - 2)),
    df24 = c("binary", "continuous", "continuous"),
    df25 = c(rep("continuous", 11), "binary", rep("continuous", 5)),
    df26 = c("continuous", "binary", "categorical", rep("continuous", 7-3)),
    df27 = c("categorical", "binary", "continuous", "categorical", "continuous", "continuous", "binary", "continuous"),
    df28 = c("binary", rep("continuous", 7), "binary", "continuous", "binary", rep("continuous", 2)),
    df29 = c("time to event", "binary", "binary", "continuous"),
    df30 = c(rep("continuous", 6), "binary", rep("continuous", 2)),
    df31 = c("time to event", "continuous", "continuous", "binary", "binary"),
    df32 = c(rep("continuous", 4), "binary", "continuous", rep("binary", 3)),
    df33 = c("continuous", "binary"),
    df34 = c("binary", "continuous", rep("binary", 6)),
    df35 = c("continuous", "continuous", "continuous", "binary", rep("continuous", 6)),
    df36 = rep("continuous", 11),
    df37 = rep("binary", 1),
    df38 = c("time to event", "continuous", "continuous"),
    df39 = c("time to event"),
    df40 = c("time to event", "continuous", "continuous", "binary", "continuous", "continuous", "binary"),
    df41 = rep("binary", 5),
    df42 = c("time to event", rep("continuous", 5)),
    df43 = c("time to event", rep("continuous", 3), "binary"),
    df44 = c("binary", rep("continuous", 3)),
    df45 = rep("continuous", 27),
    df46 = rep("continuous", 6),
    df47 = c("binary", "continuous", "binary", "binary"),
    df48 = c("continuous"),
    df49 = c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)),
    df50 = c("time to event", "continuous")
  )
  
  # Process each trial sequentially
  for (i in df_indices) {
    df_name = paste0("df", i)
    df = get(df_name)
    
    manual_covs = manual_covariates_list[[df_name]]
    if (is.null(manual_covs)) {
      manual_covs = character(0)
    }
    
    outcome_type_vec = outcome_type_list[[df_name]]
    if (is.null(outcome_type_vec) || length(outcome_type_vec) == 0) {
      message("Warning: No outcome types found for ", df_name, " - skipping")
      next
    }
    
    tryCatch({
      df_comparison = process_single_trial_dml(
        trial_no = i,
        df = df,
        manual_covariates = manual_covs,
        outcome_type_vec = outcome_type_vec,
        selection = selection,
        variable_selection_type = variable_selection_type,
        run_individual_SL = run_individual_SL,
        run_ensemble_SL = run_ensemble_SL,
        SL_methods = SL_methods,
        n_cores = n_cores,
        K = K,
        df_comparison = df_comparison
      )
    }, error = function(e) {
      message("✗ Error in ", df_name, ": ", e$message)
    })
  }
  
  cat("\n========================================\n")
  cat("All trials processed with DML\n")
  cat("========================================\n")
  
  return(df_comparison)
}
```



# Setting
```{r}
SL2_lib = c("SL.glm", "SL.glmnet", "SL.bartMachine", "SL.randomForest")
```


# DML & Robincar
```{r}
# ALL
df_comparison = run_dml_analysis(
  df_indices = 50,
  selection = F,
  variable_selection_type = 1,
  run_individual_SL = F,
  run_ensemble_SL = TRUE,
  SL_methods = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)

# Top3
df_comparison = run_dml_analysis(
  df_indices = c(1:4, 6:50),
  selection = T,
  variable_selection_type = 1,
  run_individual_SL = F,
  run_ensemble_SL = TRUE,
  SL_methods = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)

# Baseline+
df_comparison = run_dml_analysis(
  df_indices = 1:49,
  selection = T,
  variable_selection_type = 2,
  run_individual_SL = F,
  run_ensemble_SL = TRUE,
  SL_methods = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)
```

# TMLE
## Simple G
```{r}
# Run TMLE analysis on all 50 trials (individual)
df_comparison = run_tmle_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = F,                      # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = TRUE,              # Run individual SL methods
  run_ensemble_SL = F,                # Run ensemble SL
  # q_library = c("SL.glm", "SL.glmnet", "SL.rpart", "SL.gam", "SL.nnet", "SL.svm",
  #                "SL.xgboost","SL.bartMachine"),
  q_library = c("SL.randomForest"),
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)

# ALL
df_comparison = run_tmle_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = F,                      # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)

# Top3
df_comparison = run_tmle_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = T,                      # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)

# Baseline+
df_comparison = run_tmle_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = T,                      # Use variable selection
  variable_selection_type = 2,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_comparison
)
```

## Complex G
```{r}
# ALL
df_comparison = run_tmle_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = F,                      # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  g_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_newcomp
)

# Top3
df_comparison = run_tmle_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = T,                      # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  g_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_newcomp
)

# Baseline+
df_comparison = run_tmle_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = T,                      # Use variable selection
  variable_selection_type = 2,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,                # Run ensemble SL
  q_library = SL2_lib,
  g_library = SL2_lib,
  n_cores = parallel::detectCores() - 2,
  K = 5,
  df_comparison = df_newcomp
)
```

# AIPW
## Simple G
```{r}
# Run AIPW analysis on all 50 trials (individual)
df_comparison = run_aipw_analysis(
  df_indices = 1:49,                    # Which trials to analyze
  selection = FALSE,                     # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = TRUE,              # Run individual SL methods
  run_ensemble_SL = FALSE,               # Run ensemble SL
  Q_SL_library = c("SL.glm", "SL.glmnet", "SL.rpart", "SL.gam", "SL.nnet", "SL.svm",
                 "SL.xgboost","SL.bartMachine", "SL.randomForest"),   # SuperLearner library for outcome model
  g_SL_library = "SL.mean",              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_comparison
)

# ALL
df_comparison = run_aipw_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = FALSE,                     # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = "SL.mean",              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_comparison
)

# TOP3
df_comparison = run_aipw_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = T,                     # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = "SL.mean",              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_comparison
)

# Baseline+
df_comparison = run_aipw_analysis(
  df_indices = 50,                    # Which trials to analyze
  selection = T,                     # Use variable selection
  variable_selection_type = 2,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = "SL.mean",              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_comparison
)
```
## Complex G
```{r}
# ALL
df_comparison = run_aipw_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = FALSE,                     # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = SL2_lib,              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_newcomp
)

# TOP3
df_comparison = run_aipw_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = T,                     # Use variable selection
  variable_selection_type = 1,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = SL2_lib,              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_newcomp
)

# Baseline+
df_comparison = run_aipw_analysis(
  df_indices = 1:50,                    # Which trials to analyze
  selection = T,                     # Use variable selection
  variable_selection_type = 2,           # Manual selection (1 = correlation, 2 = manual)
  run_individual_SL = F,              # Run individual SL methods
  run_ensemble_SL = T,               # Run ensemble SL
  Q_SL_library = SL2_lib,   # SuperLearner library for outcome model
  g_SL_library = SL2_lib,              # SuperLearner library for propensity score
  k_split = 5,                           # Number of folds for cross-validation
  g_bound = 0.05,                        # Truncation level for propensity scores
  seed = 123,                            # Random seed for reproducibility
  df_comparison = df_newcomp
)
```

# IPW
```{r}
# ALL
df_comparison = run_ipw_analysis(
  df_indices = 1:50,
  selection = FALSE,            # no variable selection
  variable_selection_type = 1,
  weight_method = "IPW",        # PSweight keyword for ATE
  n_select = 3,
  seed = 123,
  df_comparison = df_comparison
)

# Top3
df_comparison = run_ipw_analysis(
  df_indices = 1:50,
  selection = TRUE,             # variable selection on
  variable_selection_type = 1,  # correlation-based (Top3)
  weight_method = "IPW",        # ATE
  n_select = 3,
  seed = 123,
  df_comparison = df_comparison
)

# Baseline+
df_comparison = run_ipw_analysis(
  df_indices = 1:50,
  selection = TRUE,             # variable selection on
  variable_selection_type = 2,  # manual/baseline+
  weight_method = "IPW",        # ATE
  n_select = 3,
  seed = 123,
  df_comparison = df_comparison
)

```


# Export
```{r}
write_xlsx(df_comparison, "cleaned_data/meta_data_comparison.xlsx")
write_xlsx(df_newcomp, "cleaned_data/meta_data_comparison_new.xlsx")
```


# Summary Data
```{r}
# Create outcome_group variable
df_new = df_comparison %>%
  mutate(
    outcome_group = case_when(
      `Outcome Type` %in% c("continuous", "continuous proportion") ~ "continuous",
      `Outcome Type` %in% c("ordinal", "categorical") ~ "categorical", 
      `Outcome Type` %in% c("binary", "composite binary") ~ "binary",
      `Outcome Type` == "time to event" ~ "time_to_event",
      TRUE ~ "other"
    )
  )

# Rename all precision gain and variance ratio columns
df_new = df_new %>%
  rename(
    # All (base) precision gain columns
    precision_gain_ANCOVA = `How much precision gain can ANCOVA provide?`,
    precision_gain_ANHECOVA = `How much precision gain can ANHECOVA provide?`,
    precision_gain_G_Logistic = `How much precision gain can Logistic G-Computation provide?`,
    precision_gain_SL1 = `How much precision gain can SL1 provide?`,
    precision_gain_SL_rpart = `How much precision gain can SL_rpart provide?`,
    precision_gain_SL_randomForest = `How much precision gain can SL_randomForest provide?`,
    precision_gain_SL_glmnet = `How much precision gain can SL_glmnet provide?`,
    precision_gain_SL_gam = `How much precision gain can SL_gam provide?`,
    precision_gain_SL_bartMachine = `How much precision gain can SL_bartMachine provide?`,
    precision_gain_DML = `How much precision gain can DML provide?`,
    precision_gain_TMLE = `How much precision gain can TMLE provide?`,
    precision_gain_AIPW = `How much precision gain can AIPW provide?`,
    precision_gain_IPW = `How much precision gain can IPW provide?`,
    
    # Top-3 (VS1) precision gain columns
    `precision_gain_ANCOVA_Top-3` = `How much precision gain can ANCOVA_VS1 provide?`,
    `precision_gain_ANHECOVA_Top-3` = `How much precision gain can ANHECOVA_VS1 provide?`,
    `precision_gain_G_Logistic_Top-3` = `How much precision gain can Logistic G-Computation_VS1 provide?`,
    `precision_gain_SL1_Top-3` = `How much precision gain can SL1_VS1 provide?`,
    `precision_gain_SL_rpart_Top-3` = `How much precision gain can SL_rpart_VS1 provide?`,
    `precision_gain_SL_randomForest_Top-3` = `How much precision gain can SL_randomForest_VS1 provide?`,
    `precision_gain_SL_glmnet_Top-3` = `How much precision gain can SL_glmnet_VS1 provide?`,
    `precision_gain_SL_gam_Top-3` = `How much precision gain can SL_gam_VS1 provide?`,
    `precision_gain_SL_bartMachine_Top-3` = `How much precision gain can SL_bartMachine_VS1 provide?`,
    `precision_gain_DML_Top-3` = `How much precision gain can DML_VS1 provide?`,
    `precision_gain_TMLE_Top-3` = `How much precision gain can TMLE_VS1 provide?`,
    `precision_gain_AIPW_Top-3` = `How much precision gain can AIPW_VS1 provide?`,
    `precision_gain_IPW_Top-3` = `How much precision gain can IPW_VS1 provide?`,
    
    # Baseline+ (VS2) precision gain columns
    `precision_gain_ANCOVA_Baseline+` = `How much precision gain can ANCOVA_VS2 provide?`,
    `precision_gain_ANHECOVA_Baseline+` = `How much precision gain can ANHECOVA_VS2 provide?`,
    `precision_gain_G_Logistic_Baseline+` = `How much precision gain can Logistic G-Computation_VS2 provide?`,
    `precision_gain_SL1_Baseline+` = `How much precision gain can SL1_VS2 provide?`,
    `precision_gain_SL_rpart_Baseline+` = `How much precision gain can SL_rpart_VS2 provide?`,
    `precision_gain_SL_randomForest_Baseline+` = `How much precision gain can SL_randomForest_VS2 provide?`,
    `precision_gain_SL_glmnet_Baseline+` = `How much precision gain can SL_glmnet_VS2 provide?`,
    `precision_gain_SL_gam_Baseline+` = `How much precision gain can SL_gam_VS2 provide?`,
    `precision_gain_SL_bartMachine_Baseline+` = `How much precision gain can SL_bartMachine_VS2 provide?`,
    `precision_gain_DML_Baseline+` = `How much precision gain can DML_VS2 provide?`,
    `precision_gain_TMLE_Baseline+` = `How much precision gain can TMLE_VS2 provide?`,
    `precision_gain_AIPW_Baseline+` = `How much precision gain can AIPW_VS2 provide?`,
    `precision_gain_IPW_Baseline+` = `How much precision gain can IPW_VS2 provide?`,
    
    # All (base) variance ratio columns
    variance_ratio_robust_model = `The ratio between robust and model-based variance estimators`,
    variance_ratio_ANCOVA_ANHECOVA = `ANCOVA vs ANHECOVA variance ratio`,
    
    # Top-3 (VS1) variance ratio columns  
    `variance_ratio_robust_model_Top-3` = `The ratio between robust and model-based variance estimators_VS1`,
    `variance_ratio_ANCOVA_ANHECOVA_Top-3` = `ANCOVA_VS1 vs ANHECOVA_VS1 variance ratio`,
    
    # Baseline+ (VS2) variance ratio columns
    `variance_ratio_robust_model_Baseline+` = `The ratio between robust and model-based variance estimators_VS2`,
    `variance_ratio_ANCOVA_ANHECOVA_Baseline+` = `ANCOVA_VS2 vs ANHECOVA_VS2 variance ratio`,
    
    # All (base) difference columns
    diff_ANCOVA = `The difference between unadjusted and ANCOVA point estimates`,
    diff_ANHECOVA = `The difference between unadjusted and ANHECOVA point estimates`,
    diff_G_Logistic = `The difference between unadjusted and Logistic G-Computation point estimates`,
    diff_SL1 = `The difference between unadjusted and SL1 point estimates`,
    diff_SL_rpart = `The difference between unadjusted and SL_rpart point estimates`,
    diff_SL_randomForest = `The difference between unadjusted and SL_randomForest point estimates`,
    diff_SL_glmnet = `The difference between unadjusted and SL_glmnet point estimates`,
    diff_SL_gam = `The difference between unadjusted and SL_gam point estimates`,
    diff_SL_bartMachine = `The difference between unadjusted and SL_bartMachine point estimates`,
    diff_TMLE = `The difference between unadjusted and TMLE point estimates`,
    diff_DML = `The difference between unadjusted and DML point estimates`,
    diff_AIPW = `The difference between unadjusted and AIPW point estimates`,
    diff_IPW = `The difference between unadjusted and IPW point estimates`,
    
    # Top-3 (VS1) difference columns
    `diff_ANCOVA_Top-3` = `The difference between unadjusted and ANCOVA_VS1 point estimates`,
    `diff_ANHECOVA_Top-3` = `The difference between unadjusted and ANHECOVA_VS1 point estimates`,
    `diff_G_Logistic_Top-3` = `The difference between unadjusted and Logistic G-Computation_VS1 point estimates`,
    `diff_SL1_Top-3` = `The difference between unadjusted and SL1_VS1 point estimates`,
    `diff_SL_rpart_Top-3` = `The difference between unadjusted and SL_rpart_VS1 point estimates`,
    `diff_SL_randomForest_Top-3` = `The difference between unadjusted and SL_randomForest_VS1 point estimates`,
    `diff_SL_glmnet_Top-3` = `The difference between unadjusted and SL_glmnet_VS1 point estimates`,
    `diff_SL_gam_Top-3` = `The difference between unadjusted and SL_gam_VS1 point estimates`,
    `diff_SL_bartMachine_Top-3` = `The difference between unadjusted and SL_bartMachine_VS1 point estimates`,
    `diff_TMLE_Top-3` = `The difference between unadjusted and TMLE_VS1 point estimates`,
    `diff_DML_Top-3` = `The difference between unadjusted and DML_VS1 point estimates`,
    `diff_AIPW_Top-3` = `The difference between unadjusted and AIPW_VS1 point estimates`,
    `diff_IPW_Top-3` = `The difference between unadjusted and IPW_VS1 point estimates`,
    
    # Baseline+ (VS2) difference columns
    `diff_ANCOVA_Baseline+` = `The difference between unadjusted and ANCOVA_VS2 point estimates`,
    `diff_ANHECOVA_Baseline+` = `The difference between unadjusted and ANHECOVA_VS2 point estimates`,
    `diff_G_Logistic_Baseline+` = `The difference between unadjusted and Logistic G-Computation_VS2 point estimates`,
    `diff_SL1_Baseline+` = `The difference between unadjusted and SL1_VS2 point estimates`,
    `diff_SL_rpart_Baseline+` = `The difference between unadjusted and SL_rpart_VS2 point estimates`,
    `diff_SL_randomForest_Baseline+` = `The difference between unadjusted and SL_randomForest_VS2 point estimates`,
    `diff_SL_glmnet_Baseline+` = `The difference between unadjusted and SL_glmnet_VS2 point estimates`,
    `diff_SL_gam_Baseline+` = `The difference between unadjusted and SL_gam_VS2 point estimates`,
    `diff_SL_bartMachine_Baseline+` = `The difference between unadjusted and SL_bartMachine_VS2 point estimates`,
    `diff_TMLE_Baseline+` = `The difference between unadjusted and TMLE_VS2 point estimates`,
    `diff_DML_Baseline+` = `The difference between unadjusted and DML_VS2 point estimates`,
    `diff_AIPW_Baseline+` = `The difference between unadjusted and AIPW_VS2 point estimates`,
    `diff_IPW_Baseline+` = `The difference between unadjusted and IPW_VS2 point estimates`
  )
```

# Box Plots
## Efficiency Gain
```{r}
# First need to filter df_new to get primary and all outcomes datasets
df_new_all_outcomes = df_new  # All outcomes

# Primary outcomes only (outcomes starting with YP_)
df_new_primary = df_new %>%
  filter(str_detect(Outcome, "^YP_"))

# Function to prepare long data
prepare_long_data = function(data) {
  data %>%
    select(outcome_group, starts_with("precision_gain_")) %>%
    pivot_longer(cols      = starts_with("precision_gain_"),
                 names_to  = "method_raw",
                 values_to = "pg") %>%
    mutate(
      # Keep track of the adjustment type
      adjustment_type = case_when(
        grepl("_Top-3$", method_raw) ~ "Top-3",
        grepl("_Baseline\\+$", method_raw) ~ "Baseline+",
        TRUE ~ "All"
      ),
      # Simplified method names
      method = case_match(
        method_raw,
        # All methods - excluding SL1 and individual SL methods and AIPW
        "precision_gain_ANCOVA"                       ~ "ANCOVA",
        "precision_gain_ANHECOVA"                     ~ "ANHECOVA",
        "precision_gain_G_Logistic"                   ~ "G-Logistic",
        "precision_gain_DML"                          ~ "DML",
        "precision_gain_TMLE"                         ~ "TMLE",
        "precision_gain_IPW"                          ~ "IPW",
        
        # Top-3 methods (same names, no suffix)
        "precision_gain_ANCOVA_Top-3"                 ~ "ANCOVA",
        "precision_gain_ANHECOVA_Top-3"               ~ "ANHECOVA",
        "precision_gain_G_Logistic_Top-3"             ~ "G-Logistic",
        "precision_gain_DML_Top-3"                    ~ "DML",
        "precision_gain_TMLE_Top-3"                   ~ "TMLE",
        "precision_gain_IPW_Top-3"                    ~ "IPW",
        
        # Baseline+ methods (same names, no suffix)
        "precision_gain_ANCOVA_Baseline+"             ~ "ANCOVA",
        "precision_gain_ANHECOVA_Baseline+"           ~ "ANHECOVA",
        "precision_gain_G_Logistic_Baseline+"         ~ "G-Logistic",
        "precision_gain_DML_Baseline+"                ~ "DML",
        "precision_gain_TMLE_Baseline+"               ~ "TMLE",
        "precision_gain_IPW_Baseline+"                ~ "IPW"
      )) %>%
    filter(!is.na(method))  # Remove rows where method couldn't be matched
}

# Create long data for both datasets
df_long_full_all = prepare_long_data(df_new_all_outcomes)
df_long_full_primary = prepare_long_data(df_new_primary)

# Manual outlier threshold for precision gain
pg_manual_threshold = 5

###############################################################################
##  1.  Build ONE comprehensive summary table for ALL plots ------------------
##      Columns: Method | #NA | #Outlier(Manual) | #Tukey | #Shown | Panel
##      * #NA:               missing pg in the raw slice
##      * #Outlier(Manual):  pg >= pg_manual_threshold in raw non-NA
##      * #Tukey:            Tukey outliers hidden by outlier.shape=NA
##      * #Shown:            count after removing manual outliers (shown in plots)
###############################################################################

# Methods that appear on plots by outcome type
.method_set = list(
  binary     = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW"),
  continuous = c("ANCOVA", "ANHECOVA",               "DML", "TMLE", "IPW")
)

# Compute Tukey bounds per METHOD within the provided panel slice
compute_tukey_bounds = function(panel_df) {
  panel_df %>%
    filter(!is.na(pg)) %>%
    group_by(method) %>%
    summarise(
      Q1    = quantile(pg, 0.25, na.rm = TRUE),
      Q3    = quantile(pg, 0.75, na.rm = TRUE),
      IQR   = Q3 - Q1,
      lower = Q1 - 1.5 * IQR,
      upper = Q3 + 1.5 * IQR,
      .groups = "drop"
    )
}

build_comprehensive_summary_table = function() {
  outcome_types    = c("binary", "continuous")
  adjustment_types = c("All", "Top-3", "Baseline+")
  data_types       = c("all", "primary")
  
  all_rows = list()
  
  for (data_type in data_types) {
    df_raw = if (data_type == "primary") df_long_full_primary else df_long_full_all
    
    for (outcome_type in outcome_types) {
      shown_methods = .method_set[[outcome_type]]
      
      for (vs_type in adjustment_types) {
        # ---------- RAW slice (restrict to methods that are actually shown on plots)
        raw_slice = df_raw %>%
          filter(outcome_group == outcome_type,
                 adjustment_type == vs_type,
                 method %in% shown_methods)
        
        # #NA
        na_tbl = raw_slice %>%
          group_by(method) %>%
          summarise(`#NA` = sum(is.na(pg)), .groups = "drop")
        
        # Non-NA for outlier counting
        non_na = raw_slice %>% filter(!is.na(pg))
        
        # Manual outliers (pg >= threshold)
        manual_tbl = non_na %>%
          group_by(method) %>%
          summarise(`#Outlier(Manual)` = sum(pg >= pg_manual_threshold, na.rm = TRUE),
                    .groups = "drop")
        
        # Tukey outliers (for reference - hidden by outlier.shape=NA in plots)
        tb = compute_tukey_bounds(raw_slice)
        tukey_tbl = non_na %>%
          inner_join(tb, by = "method") %>%
          group_by(method) %>%
          summarise(`#Tukey` = sum(pg < lower | pg > upper, na.rm = TRUE),
                    .groups = "drop")
        
        # #Shown = after removing manual outliers (what appears in plots)
        shown_tbl = non_na %>%
          filter(pg < pg_manual_threshold) %>%
          group_by(method) %>%
          summarise(`#Shown` = n(), .groups = "drop")
        
        # ---------- Combine and order
        combo = na_tbl %>%
          full_join(manual_tbl, by = "method") %>%
          full_join(tukey_tbl,  by = "method") %>%
          full_join(shown_tbl,  by = "method") %>%
          mutate(across(-method, ~ replace_na(., 0L))) %>%
          filter(method %in% shown_methods) %>%
          arrange(factor(method, levels = shown_methods)) %>%
          mutate(Panel = paste(data_type, outcome_type, vs_type, sep = "_")) %>%
          select(Method = method, `#NA`, `#Outlier(Manual)`, `#Tukey`, `#Shown`, Panel)
        
        all_rows[[length(all_rows) + 1]] = combo
      }
    }
  }
  
  bind_rows(all_rows)
}

###############################################################################
##  2.  Color palette matching smooth plots ---------------------------------
###############################################################################
# Define color palette (IPW changed to purple to differentiate from ANCOVA)
method_colors = c(
  "ANCOVA"     = "#F8766D",    # Red
  "ANHECOVA"   = "#B79F00",    # Gold/Yellow
  "G-Logistic" = "#00BA38",    # Green
  "DML"        = "#00BFC4",    # Cyan
  "TMLE"       = "#619CFF",    # Blue
  "IPW"        = "#C77CFF"     # Purple
)

###############################################################################
##  3.  Plot function with colors and improved text size ---------------------
###############################################################################
make_plot = function(data, outcome_type) {
  
  # Transform variance ratio to proportional variance reduction (1 - original value)
  data = data %>%
    mutate(prop_var_reduction = 1 - precision_gain)
  
  # Set factor levels based on outcome type
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW")
  } else {
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE", "IPW")  # no G-Logistic
  }
  
  data = data %>%
    mutate(method = factor(method, levels = method_levels))
  
  # Counts for labels
  method_counts = data %>%
    group_by(method) %>%
    summarise(n = n(), .groups = "drop")
  
  # x-axis label positions
  x_labels_df = data.frame(
    method = method_levels[method_levels %in% unique(data$method)],
    x_pos  = 1:length(method_levels[method_levels %in% unique(data$method)])
  )
  
  x_labels_counts = x_labels_df %>%
    left_join(method_counts, by = "method")
  
  p = ggplot(data, aes(method, prop_var_reduction, fill = method)) +
    geom_boxplot(colour = "grey25", alpha = .50, width = 0.5, outlier.shape = NA) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey40") +
    scale_fill_manual(values = method_colors) +
    labs(x = NULL, y = "Proportional Variance Reduction") +
    coord_cartesian(ylim = c(-1, 1), clip = "off") +
    theme_minimal(base_size = 18) +
    theme(
      axis.text.x   = element_blank(),
      axis.ticks.x  = element_blank(),
      axis.text.y   = element_text(size = 16),
      axis.title.y  = element_text(size = 18),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", colour = NA),
      plot.background  = element_rect(fill = "white", colour = NA),
      legend.position  = "none",
      plot.margin      = margin(t = 5, r = 10, b = 60, l = 10)
    ) +
    geom_text(data = x_labels_counts, 
              aes(x = x_pos, y = -1.15, label = method),
              inherit.aes = FALSE, size = 5.5, lineheight = 0.85, hjust = 0.5) +
    geom_text(data = x_labels_counts, 
              aes(x = x_pos, y = -1.35, label = paste0("(", n, ")")),
              inherit.aes = FALSE, size = 4.5, hjust = 0.5)
  
  return(p)
}

###############################################################################
##  4.  Create outlier-removed datasets for all outcomes ---------------------
###############################################################################

# Function to remove outliers (pg >= 5)
remove_outliers = function(data) {
  data %>%
    mutate(precision_gain = ifelse(pg >= pg_manual_threshold, NA, pg)) %>%
    filter(!is.na(precision_gain))
}

# Create outlier-removed datasets
df_long_outlier_removed_all     = remove_outliers(df_long_full_all)
df_long_outlier_removed_primary = remove_outliers(df_long_full_primary)

###############################################################################
##  Publication quality settings ---------------------------------------------
###############################################################################
pub_width  = 10
pub_height = 6.5
pub_dpi    = 600  # 600 dpi for publication quality

###############################################################################
##  5.  Generate all plots (All outcomes) ------------------------------------
###############################################################################

# All methods - All outcomes
df_binary_all_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", adjustment_type == "All")

p_binary_all_all = make_plot(df_binary_all_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_all_all.png", 
       p_binary_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Top-3 methods - All outcomes
df_binary_top3_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", adjustment_type == "Top-3")

p_binary_top3_all = make_plot(df_binary_top3_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_top3_all.png", 
       p_binary_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Baseline+ methods - All outcomes
df_binary_baseline_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", adjustment_type == "Baseline+")

p_binary_baseline_all = make_plot(df_binary_baseline_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_baseline_all.png", 
       p_binary_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous plots - All outcomes
df_continuous_all_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", adjustment_type == "All")

p_cont_all_all = make_plot(df_continuous_all_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_all_all.png", 
       p_cont_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_top3_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", adjustment_type == "Top-3")

p_cont_top3_all = make_plot(df_continuous_top3_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_top3_all.png", 
       p_cont_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_baseline_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", adjustment_type == "Baseline+")

p_cont_baseline_all = make_plot(df_continuous_baseline_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_baseline_all.png", 
       p_cont_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

###############################################################################
##  6.  Generate all plots (Primary outcomes only) ---------------------------
###############################################################################

# All methods - Primary outcomes
df_binary_all_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", adjustment_type == "All")

p_binary_all_primary = make_plot(df_binary_all_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_all_primary.png", 
       p_binary_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Top-3 methods - Primary outcomes
df_binary_top3_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", adjustment_type == "Top-3")

p_binary_top3_primary = make_plot(df_binary_top3_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_top3_primary.png", 
       p_binary_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Baseline+ methods - Primary outcomes
df_binary_baseline_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", adjustment_type == "Baseline+")

p_binary_baseline_primary = make_plot(df_binary_baseline_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_baseline_primary.png", 
       p_binary_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous plots - Primary outcomes
df_continuous_all_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", adjustment_type == "All")

p_cont_all_primary = make_plot(df_continuous_all_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_all_primary.png", 
       p_cont_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_top3_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", adjustment_type == "Top-3")

p_cont_top3_primary = make_plot(df_continuous_top3_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_top3_primary.png", 
       p_cont_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_baseline_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", adjustment_type == "Baseline+")

p_cont_baseline_primary = make_plot(df_continuous_baseline_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_baseline_primary.png", 
       p_cont_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

###############################################################################
##  7.  Build and print the comprehensive table (no CSV writing) -------------
###############################################################################
comprehensive_table = build_comprehensive_summary_table()

cat("\n========================================\n")
cat("Comprehensive PRECISION GAIN table (Method, #NA, #Outlier(Manual), #Tukey, #Shown, Panel)\n")
cat(paste0("Manual threshold: pg >= ", pg_manual_threshold, "\n"))
cat("Note: #Tukey shows outliers hidden by outlier.shape=NA\n")
cat("      #Outlier(Manual) shows outliers removed from data\n")
cat("      #Shown = actual count displayed in plots\n")
cat("========================================\n\n")
print(comprehensive_table)

# Display all 12 plots in console
cat("\n========================================\n")
cat("All plots saved at publication quality (600 dpi, white background)\n")
cat("Plots use outlier-removed data (pg >= 5 removed)\n")
cat("Boxplots use outlier.shape=NA to hide Tukey outliers\n")
cat("========================================\n\n")

cat("All Outcomes Plots:\n")
print(p_binary_all_all)
print(p_binary_top3_all)
print(p_binary_baseline_all)
print(p_cont_all_all)
print(p_cont_top3_all)
print(p_cont_baseline_all)

cat("\nPrimary Outcomes Plots:\n")
print(p_binary_all_primary)
print(p_binary_top3_primary)
print(p_binary_baseline_primary)
print(p_cont_all_primary)
print(p_cont_top3_primary)
print(p_cont_baseline_primary)
```

## Scaled Diff
```{r}
###############################################################################
##  DIFFERENCE VIOLIN PLOTS (OUTLIERS REMOVED FOR PLOTS + BIG SUMMARY TABLE)
###############################################################################

###############################################################################
##  0.  Long data for differences --------------------------------------------
###############################################################################

# Function to prepare long data for differences
prepare_long_diff_data = function(data) {
  data %>%
    select(outcome_group, starts_with("diff_")) %>%
    pivot_longer(cols      = starts_with("diff_"),
                 names_to  = "method_raw",
                 values_to = "diff") %>%
    mutate(
      # Keep track of the adjustment type
      adjustment_type = case_when(
        grepl("_Top-3$", method_raw) ~ "Top-3",
        grepl("_Baseline\\+$", method_raw) ~ "Baseline+",
        TRUE ~ "All"
      ),
      # Simplified method names
      method = case_match(
        method_raw,
        # All methods
        "diff_ANCOVA"                       ~ "ANCOVA",
        "diff_ANHECOVA"                     ~ "ANHECOVA",
        "diff_G_Logistic"                   ~ "G-Logistic",
        "diff_DML"                          ~ "DML",
        "diff_TMLE"                         ~ "TMLE",
        "diff_IPW"                          ~ "IPW",
        
        # Top-3 methods
        "diff_ANCOVA_Top-3"                 ~ "ANCOVA",
        "diff_ANHECOVA_Top-3"               ~ "ANHECOVA",
        "diff_G_Logistic_Top-3"             ~ "G-Logistic",
        "diff_DML_Top-3"                    ~ "DML",
        "diff_TMLE_Top-3"                   ~ "TMLE",
        "diff_IPW_Top-3"                    ~ "IPW",
        
        # Baseline+ methods
        "diff_ANCOVA_Baseline+"             ~ "ANCOVA",
        "diff_ANHECOVA_Baseline+"           ~ "ANHECOVA",
        "diff_G_Logistic_Baseline+"         ~ "G-Logistic",
        "diff_DML_Baseline+"                ~ "DML",
        "diff_TMLE_Baseline+"               ~ "TMLE",
        "diff_IPW_Baseline+"                ~ "IPW"
      )) %>%
    filter(!is.na(method))  # Remove rows where method couldn't be matched
}

# Create long data for both datasets
df_long_diff_full_all     = prepare_long_diff_data(df_new_all_outcomes)
df_long_diff_full_primary = prepare_long_diff_data(df_new_primary)

# Methods actually shown on plots by outcome type
.diff_method_set = list(
  binary     = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW"),
  continuous = c("ANCOVA", "ANHECOVA",               "DML", "TMLE", "IPW")
)

# Manual "extreme" outlier threshold for differences
diff_manual_threshold = 8

###############################################################################
##  1.  Helpers: outlier removal for plotting --------------------------------
##      Remove points where |diff| > 5 (manual threshold)
###############################################################################

# Remove outliers for plotting: drop manual |diff| > threshold
remove_diff_outliers_panel = function(panel_df) {
  panel_df %>%
    mutate(
      is_manual_out = abs(diff) > diff_manual_threshold
    ) %>%
    filter(!is.na(diff), !is_manual_out) %>%
    select(-is_manual_out)
}

###############################################################################
##  2.  Table builder for differences (BIG summary across all panels) ---------
##      Columns: Method | #NA | #Outlier(Manual) | #Tukey | #Shown | Panel
##      - #NA:               missing diff in raw slice
##      - #Outlier(Manual):  abs(diff) > diff_manual_threshold in raw non-NA
##      - #Tukey:            Tukey outliers hidden by outlier.shape=NA
##      - #Shown:            count after removing manual outliers (shown in plots)
###############################################################################

# Compute Tukey bounds per METHOD within the provided panel slice
compute_tukey_bounds = function(panel_df) {
  panel_df %>%
    filter(!is.na(diff)) %>%
    group_by(method) %>%
    summarise(
      Q1    = quantile(diff, 0.25, na.rm = TRUE),
      Q3    = quantile(diff, 0.75, na.rm = TRUE),
      IQR   = Q3 - Q1,
      lower = Q1 - 1.5 * IQR,
      upper = Q3 + 1.5 * IQR,
      .groups = "drop"
    )
}

build_comprehensive_diff_table = function() {
  outcome_types    = c("binary", "continuous")
  adjustment_types = c("All", "Top-3", "Baseline+")
  data_types       = c("all", "primary")
  
  all_rows = list()
  
  for (data_type in data_types) {
    df_raw = if (data_type == "primary") df_long_diff_full_primary else df_long_diff_full_all
    
    for (outcome_type in outcome_types) {
      method_levels = .diff_method_set[[outcome_type]]
      
      for (vs_type in adjustment_types) {
        # Raw slice for this panel (restrict to methods shown on plots)
        raw_slice = df_raw %>%
          filter(outcome_group == outcome_type,
                 adjustment_type == vs_type,
                 method %in% method_levels)
        
        # #NA
        nas = raw_slice %>%
          group_by(method) %>%
          summarise(`#NA` = sum(is.na(diff)), .groups = "drop")
        
        # Non-NA for outlier counting
        non_na = raw_slice %>% filter(!is.na(diff))
        
        # Manual outliers (|diff| > threshold)
        manual_tbl = non_na %>%
          group_by(method) %>%
          summarise(`#Outlier(Manual)` = sum(abs(diff) > diff_manual_threshold, na.rm = TRUE),
                    .groups = "drop")
        
        # Tukey outliers (for reference - hidden by outlier.shape=NA in plots)
        tb = compute_tukey_bounds(raw_slice)
        tukey_tbl = non_na %>%
          inner_join(tb, by = "method") %>%
          group_by(method) %>%
          summarise(`#Tukey` = sum(diff < lower | diff > upper, na.rm = TRUE),
                    .groups = "drop")
        
        # #Shown = after removing manual outliers (what appears in plots)
        cleaned = remove_diff_outliers_panel(raw_slice %>% filter(!is.na(diff)))
        shown_tbl = cleaned %>%
          group_by(method) %>%
          summarise(`#Shown` = n(), .groups = "drop")
        
        # Combine
        combo = nas %>%
          full_join(manual_tbl, by = "method") %>%
          full_join(tukey_tbl,  by = "method") %>%
          full_join(shown_tbl,  by = "method") %>%
          mutate(across(-method, ~ replace_na(., 0L))) %>%
          filter(method %in% method_levels) %>%
          arrange(factor(method, levels = method_levels)) %>%
          mutate(Panel = paste(data_type, outcome_type, vs_type, sep = "_")) %>%
          select(Method = method, `#NA`, `#Outlier(Manual)`, `#Tukey`, `#Shown`, Panel)
        
        all_rows[[length(all_rows) + 1]] = combo
      }
    }
  }
  
  bind_rows(all_rows)
}

###############################################################################
##  3.  Plot function for differences (uses OUTLIER-REMOVED data) ------------
###############################################################################
make_diff_plot = function(panel_clean_df, outcome_type) {
  
  # Set factor levels based on outcome type
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW")
  } else {
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE", "IPW")  # no G-Logistic
  }
  
  data = panel_clean_df %>%
    mutate(method = factor(method, levels = method_levels))
  
  # Counts for labels (post-removal; equals #Shown)
  method_counts = data %>%
    group_by(method) %>%
    summarise(n = n(), .groups = "drop")
  
  # x-axis label positions
  x_labels_df = data.frame(
    method = method_levels[method_levels %in% unique(data$method)],
    x_pos   = 1:length(method_levels[method_levels %in% unique(data$method)])
  )
  
  x_labels_counts = x_labels_df %>%
    left_join(method_counts, by = "method")
  
  p = ggplot(data, aes(method, diff, fill = method)) +
    geom_boxplot(colour = "grey25", alpha = .50, width = 0.5, outlier.shape = NA) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey40") +
    scale_fill_manual(values = method_colors) +
    labs(x = NULL, y = "Difference from Unadjusted Estimate") +
    coord_cartesian(ylim = c(-3, 3), clip = "off") +
    theme_minimal(base_size = 18) +
    theme(
      axis.text.x   = element_blank(),
      axis.ticks.x  = element_blank(),
      axis.text.y   = element_text(size = 16),
      axis.title.y  = element_text(size = 18),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", colour = NA),
      plot.background  = element_rect(fill = "white", colour = NA),
      legend.position  = "none",
      plot.margin      = margin(t = 5, r = 10, b = 60, l = 10)
    ) +
    geom_text(data = x_labels_counts, 
              aes(x = x_pos, y = -3.45, label = method),
              inherit.aes = FALSE, size = 5.5, lineheight = 0.85, hjust = 0.5) +
    geom_text(data = x_labels_counts, 
              aes(x = x_pos, y = -4.05, label = paste0("(", n, ")")),
              inherit.aes = FALSE, size = 4.5, hjust = 0.5)
  
  return(p)
}

###############################################################################
##  4.  Generate all difference plots (using OUTLIER-REMOVED data) -----------
###############################################################################

# Helper to get raw panel slice (before removal) given scopes
get_raw_panel = function(data_source, outcome_type, vs_type) {
  method_levels = .diff_method_set[[outcome_type]]
  data_source %>%
    filter(outcome_group == outcome_type,
           adjustment_type == vs_type,
           method %in% method_levels)
}

# Publication quality settings (assumes you defined method_colors elsewhere)
pub_width  = 10
pub_height = 6.5
pub_dpi    = 600

## ---- All outcomes
# Binary
raw_bin_all   = get_raw_panel(df_long_diff_full_all, "binary", "All")
clean_bin_all = remove_diff_outliers_panel(raw_bin_all)
p_diff_binary_all_all = make_diff_plot(clean_bin_all, "binary")
ggsave("cleaned_data/Plot/difference_binary_all_all.png",
       p_diff_binary_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_bin_top3   = get_raw_panel(df_long_diff_full_all, "binary", "Top-3")
clean_bin_top3 = remove_diff_outliers_panel(raw_bin_top3)
p_diff_binary_top3_all = make_diff_plot(clean_bin_top3, "binary")
ggsave("cleaned_data/Plot/difference_binary_top3_all.png",
       p_diff_binary_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_bin_base   = get_raw_panel(df_long_diff_full_all, "binary", "Baseline+")
clean_bin_base = remove_diff_outliers_panel(raw_bin_base)
p_diff_binary_baseline_all = make_diff_plot(clean_bin_base, "binary")
ggsave("cleaned_data/Plot/difference_binary_baseline_all.png",
       p_diff_binary_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous
raw_con_all   = get_raw_panel(df_long_diff_full_all, "continuous", "All")
clean_con_all = remove_diff_outliers_panel(raw_con_all)
p_diff_cont_all_all = make_diff_plot(clean_con_all, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_all_all.png",
       p_diff_cont_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_con_top3   = get_raw_panel(df_long_diff_full_all, "continuous", "Top-3")
clean_con_top3 = remove_diff_outliers_panel(raw_con_top3)
p_diff_cont_top3_all = make_diff_plot(clean_con_top3, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_top3_all.png",
       p_diff_cont_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_con_base   = get_raw_panel(df_long_diff_full_all, "continuous", "Baseline+")
clean_con_base = remove_diff_outliers_panel(raw_con_base)
p_diff_cont_baseline_all = make_diff_plot(clean_con_base, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_baseline_all.png",
       p_diff_cont_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

## ---- Primary outcomes
# Binary
raw_bin_all_p   = get_raw_panel(df_long_diff_full_primary, "binary", "All")
clean_bin_all_p = remove_diff_outliers_panel(raw_bin_all_p)
p_diff_binary_all_primary = make_diff_plot(clean_bin_all_p, "binary")
ggsave("cleaned_data/Plot/difference_binary_all_primary.png",
       p_diff_binary_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_bin_top3_p   = get_raw_panel(df_long_diff_full_primary, "binary", "Top-3")
clean_bin_top3_p = remove_diff_outliers_panel(raw_bin_top3_p)
p_diff_binary_top3_primary = make_diff_plot(clean_bin_top3_p, "binary")
ggsave("cleaned_data/Plot/difference_binary_top3_primary.png",
       p_diff_binary_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_bin_base_p   = get_raw_panel(df_long_diff_full_primary, "binary", "Baseline+")
clean_bin_base_p = remove_diff_outliers_panel(raw_bin_base_p)
p_diff_binary_baseline_primary = make_diff_plot(clean_bin_base_p, "binary")
ggsave("cleaned_data/Plot/difference_binary_baseline_primary.png",
       p_diff_binary_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous
raw_con_all_p   = get_raw_panel(df_long_diff_full_primary, "continuous", "All")
clean_con_all_p = remove_diff_outliers_panel(raw_con_all_p)
p_diff_cont_all_primary = make_diff_plot(clean_con_all_p, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_all_primary.png",
       p_diff_cont_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_con_top3_p   = get_raw_panel(df_long_diff_full_primary, "continuous", "Top-3")
clean_con_top3_p = remove_diff_outliers_panel(raw_con_top3_p)
p_diff_cont_top3_primary = make_diff_plot(clean_con_top3_p, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_top3_primary.png",
       p_diff_cont_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

raw_con_base_p   = get_raw_panel(df_long_diff_full_primary, "continuous", "Baseline+")
clean_con_base_p = remove_diff_outliers_panel(raw_con_base_p)
p_diff_cont_baseline_primary = make_diff_plot(clean_con_base_p, "continuous")
ggsave("cleaned_data/Plot/difference_continuous_baseline_primary.png",
       p_diff_cont_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

###############################################################################
##  5.  Build BIG comprehensive table (no writing to CSV) --------------------
###############################################################################
comprehensive_diff_table = build_comprehensive_diff_table()

cat("\n========================================\n")
cat("Comprehensive DIFFERENCE table (Method, #NA, #Outlier(Manual), #Tukey, #Shown, Panel)\n")
cat(paste0("Manual threshold: |diff| > ", diff_manual_threshold, "\n"))
cat("Note: #Tukey shows outliers hidden by outlier.shape=NA\n")
cat("      #Outlier(Manual) shows outliers removed from data\n")
cat("      #Shown = actual count displayed in plots\n")
cat("========================================\n\n")
print(comprehensive_diff_table)

###############################################################################
##  6.  Display all difference plots -----------------------------------------
###############################################################################
cat("\n========================================\n")
cat("All difference plots saved at publication quality (600 dpi, white background)\n")
cat("Plots use outlier-removed data (|diff| > 5 removed)\n")
cat("Boxplots use outlier.shape=NA to hide Tukey outliers\n")
cat("========================================\n\n")

cat("All Outcomes - Difference Plots:\n")
print(p_diff_binary_all_all)
print(p_diff_binary_top3_all)
print(p_diff_binary_baseline_all)
print(p_diff_cont_all_all)
print(p_diff_cont_top3_all)
print(p_diff_cont_baseline_all)

cat("\nPrimary Outcomes - Difference Plots:\n")
print(p_diff_binary_all_primary)
print(p_diff_binary_top3_primary)
print(p_diff_binary_baseline_primary)
print(p_diff_cont_all_primary)
print(p_diff_cont_top3_primary)
print(p_diff_cont_baseline_primary)

```


# N vs Var Ratio Plot
```{r}
###############################################################################
##  6.  Sample Size vs Variance Ratio Plots (3 versions) - LOESS + ALL PLOTS
###############################################################################

library(future)
library(furrr)

plan(multisession, workers = parallel::detectCores() - 1)

###############################################################################
##  Color palette for consistent colors across all plots
###############################################################################
method_colors = c(
  "ANCOVA" = "#F8766D",
  "ANHECOVA" = "#B79F00",
  "G-Logistic" = "#00BA38",
  "DML" = "#00BFC4",
  "TMLE" = "#619CFF",
  "IPW" = "#C77CFF"
)

# CORRECT APPROACH: Add Sample_Size directly when creating long data
prepare_long_data_with_size = function(data) {
  data %>%
    select(outcome_group, Sample_Size, starts_with("precision_gain_")) %>%
    pivot_longer(cols = starts_with("precision_gain_"),
                 names_to = "method_raw",
                 values_to = "pg") %>%
    mutate(
      # Track adjustment type
      adjustment_type = case_when(
        grepl("_Top-3$", method_raw) ~ "Top-3",
        grepl("_Baseline\\+$", method_raw) ~ "Baseline+",
        TRUE ~ "All"
      ),
      # Simplified method names (no adjustment type suffix)
      method = dplyr::case_match(
        method_raw,
        # All methods (AIPW removed)
        "precision_gain_ANCOVA"                       ~ "ANCOVA",
        "precision_gain_ANHECOVA"                     ~ "ANHECOVA",
        "precision_gain_G_Logistic"                   ~ "G-Logistic",
        "precision_gain_DML"                          ~ "DML",
        "precision_gain_TMLE"                         ~ "TMLE",
        "precision_gain_IPW"                          ~ "IPW",
        
        # Top-3 methods (same names, no suffix)
        "precision_gain_ANCOVA_Top-3"                 ~ "ANCOVA",
        "precision_gain_ANHECOVA_Top-3"               ~ "ANHECOVA",
        "precision_gain_G_Logistic_Top-3"             ~ "G-Logistic",
        "precision_gain_DML_Top-3"                    ~ "DML",
        "precision_gain_TMLE_Top-3"                   ~ "TMLE",
        "precision_gain_IPW_Top-3"                    ~ "IPW",
        
        # Baseline+ methods (same names, no suffix)
        "precision_gain_ANCOVA_Baseline+"             ~ "ANCOVA",
        "precision_gain_ANHECOVA_Baseline+"           ~ "ANHECOVA",
        "precision_gain_G_Logistic_Baseline+"         ~ "G-Logistic",
        "precision_gain_DML_Baseline+"                ~ "DML",
        "precision_gain_TMLE_Baseline+"               ~ "TMLE",
        "precision_gain_IPW_Baseline+"                ~ "IPW"
      )) %>%
    filter(!is.na(method))
}

# Create long data WITH Sample_Size
df_long_with_size_all = prepare_long_data_with_size(df_new_all_outcomes)
df_long_with_size_primary = prepare_long_data_with_size(df_new_primary)

cat("Sample size data prepared:\n")
cat("All outcomes:", nrow(df_long_with_size_all), "rows\n")
cat("Primary outcomes:", nrow(df_long_with_size_primary), "rows\n")

# Remove outliers (same as violin plots)
df_long_size_cleaned_all = df_long_with_size_all %>%
  mutate(precision_gain = ifelse(pg >= 2, NA, pg)) %>%
  filter(!is.na(precision_gain), !is.na(Sample_Size)) %>%
  mutate(prop_var_reduction = 1 - precision_gain)  # Transform to proportional variance reduction

df_long_size_cleaned_primary = df_long_with_size_primary %>%
  mutate(precision_gain = ifelse(pg >= 2, NA, pg)) %>%
  filter(!is.na(precision_gain), !is.na(Sample_Size)) %>%
  mutate(prop_var_reduction = 1 - precision_gain)  # Transform to proportional variance reduction

cat("After outlier removal:\n")
cat("All outcomes:", nrow(df_long_size_cleaned_all), "rows\n")
cat("Primary outcomes:", nrow(df_long_size_cleaned_primary), "rows\n")
cat("Sample size range:", min(df_long_size_cleaned_all$Sample_Size), 
    "to", max(df_long_size_cleaned_all$Sample_Size), "\n\n")

# Function for smoothed plot (log10 sample size) - USING LOESS
make_plot_smooth_log = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = log10(Sample_Size), y = prop_var_reduction, color = method)) +
    geom_smooth(method = "loess", span = 0.75, se = FALSE, linewidth = 1.2) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Log10(Sample Size)", y = "Proportional Variance Reduction", color = "Method") +
    coord_cartesian(ylim = c(-1, 1)) +
    theme_minimal(base_size = 18) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "inside",
          legend.position.inside = c(0.82, 0.82),
          legend.background = element_rect(fill = "white", color = "gray80", linewidth = 0.5),
          legend.text = element_text(size = 14),
          legend.title = element_text(size = 16),
          axis.text = element_text(size = 16),
          axis.title = element_text(size = 18))
}

# Function for scatter plot (original sample size)
make_plot_scatter = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = Sample_Size, y = prop_var_reduction, color = method)) +
    geom_point(alpha = 0.4, size = 1.5) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Sample Size", y = "Proportional Variance Reduction", color = "Method") +
    coord_cartesian(ylim = c(-1, 1)) +
    theme_minimal(base_size = 18) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "inside",
          legend.position.inside = c(0.82, 0.82),
          legend.background = element_rect(fill = "white", color = "gray80", linewidth = 0.5),
          legend.text = element_text(size = 14),
          legend.title = element_text(size = 16),
          axis.text = element_text(size = 16),
          axis.title = element_text(size = 18))
}

# Function for scatter plot (log10 sample size)
make_plot_scatter_log = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE", "IPW")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = log10(Sample_Size), y = prop_var_reduction, color = method)) +
    geom_point(alpha = 0.4, size = 1.5) +
    geom_hline(yintercept = 0, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Log10(Sample Size)", y = "Proportional Variance Reduction", color = "Method") +
    coord_cartesian(ylim = c(-1, 1)) +
    theme_minimal(base_size = 18) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "inside",
          legend.position.inside = c(0.82, 0.82),
          legend.background = element_rect(fill = "white", color = "gray80", linewidth = 0.5),
          legend.text = element_text(size = 14),
          legend.title = element_text(size = 16),
          axis.text = element_text(size = 16),
          axis.title = element_text(size = 18))
}

# Create plot configs - only the necessary columns
plot_configs = tibble::tibble(
  data_source = rep(c(rep("all", 6), rep("primary", 6)), 3),
  outcome_type = rep(rep(c("binary", "binary", "binary", "continuous", "continuous", "continuous"), 2), 3),
  vs_type = rep(rep(c("all", "top3", "baseline", "all", "top3", "baseline"), 2), 3),
  version = c(rep("smooth_log", 12), rep("scatter", 12), rep("scatter_log", 12))
) %>%
  mutate(
    plot_name = paste0("samplesize_", outcome_type, "_", vs_type, "_", data_source, "_", version)
  )

# Function to generate single plot - matches the column names exactly
generate_single_plot = function(data_source, outcome_type, vs_type, version, plot_name) {
  
  # Select appropriate dataset
  df_long_cleaned = if (data_source == "all") df_long_size_cleaned_all else df_long_size_cleaned_primary
  
  # Filter based on outcome type and adjustment type
  if (vs_type == "all") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, adjustment_type == "All")
  } else if (vs_type == "top3") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, adjustment_type == "Top-3")
  } else if (vs_type == "baseline") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, adjustment_type == "Baseline+")
  }
  
  # Check if we have data
  if (nrow(df_filtered) == 0) {
    warning(paste("No data for", plot_name))
    return(NULL)
  }
  
  # Create appropriate plot based on version
  p = if (version == "smooth_log") {
    make_plot_smooth_log(df_filtered, outcome_type)
  } else if (version == "scatter") {
    make_plot_scatter(df_filtered, outcome_type)
  } else if (version == "scatter_log") {
    make_plot_scatter_log(df_filtered, outcome_type)
  }
  
  return(list(plot_name = plot_name, plot = p))
}

###############################################################################
##  Publication quality settings ---------------------------------------------
###############################################################################
pub_width = 10
pub_height = 6.5
pub_dpi = 600
```
## smoothed log
```{r}
cat("\n========================================\n")
cat("Generating 12 Version 1 plots (Smoothed Log10 Scale)...\n")
cat(sprintf("Using %d cores\n", parallel::detectCores() - 1))
cat("========================================\n\n")

# Get indices for smooth_log version only
version1_indices = which(plot_configs$version == "smooth_log")

start_time = Sys.time()

results = future_pmap(
  plot_configs[version1_indices, ],
  generate_single_plot,
  .options = furrr_options(seed = TRUE),
  .progress = TRUE
)

end_time = Sys.time()

cat("\n========================================\n")
cat("12 plots generated\n")
cat(sprintf("Time elapsed: %.2f seconds\n", as.numeric(end_time - start_time, units = "secs")))
cat("========================================\n\n")

###############################################################################
##  Save all Version 1 plots (Smoothed Log10 Scale) with clear labels
###############################################################################
cat("\n", strrep("=", 70), "\n")
cat("SAVING VERSION 1: SMOOTHED (Log10 Scale) - ALL 12 PLOTS\n")
cat(strrep("=", 70), "\n\n")

for (i in seq_along(version1_indices)) {
  idx = version1_indices[i]
  
  # Get plot details
  outcome = plot_configs$outcome_type[idx]
  vs = plot_configs$vs_type[idx]
  data_src = plot_configs$data_source[idx]
  
  # Create descriptive label for console output
  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  vs_label = case_when(
    vs == "all" ~ "All Methods",
    vs == "top3" ~ "Top-3 Methods",
    vs == "baseline" ~ "Baseline+ Methods"
  )
  data_label = ifelse(data_src == "all", "ALL OUTCOMES", "PRIMARY OUTCOMES ONLY")
  
  # Create filename
  filename = paste0("cleaned_data/Plot/", plot_configs$plot_name[idx], ".png")
  
  # Save the plot
  ggsave(filename, results[[i]]$plot, 
         width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")
  
  cat(sprintf("✓ Saved: %s - %s [%s]\n", outcome_label, vs_label, data_label))
  cat(sprintf("  File: %s\n\n", filename))
}

cat(strrep("=", 70), "\n")
cat("ALL 12 VERSION 1 PLOTS SAVED\n")
cat(strrep("=", 70), "\n")

plan(sequential)
```


# 6 Panel Plot
## Efficiency Gain
```{r}
# helper to build a single row with a skinny label column
row_with_label = function(label_plot, p_left, p_right,
                          label_width = 0.11,
                          left_weight = 1,
                          right_weight = 1.00) {
  (label_plot | p_left | p_right) +
    plot_layout(widths = c(label_width, left_weight, right_weight))
}

create_6panel_figure = function(outcome_type, data_type) {
  # pick the violin plots based on outcome_type and data_type
  if (outcome_type == "binary") {
    if (data_type == "all") {
      p_violin_all = p_binary_all_all
      p_violin_top3 = p_binary_top3_all
      p_violin_baseline = p_binary_baseline_all
    } else { # primary
      p_violin_all = p_binary_all_primary
      p_violin_top3 = p_binary_top3_primary
      p_violin_baseline = p_binary_baseline_primary
    }
  } else { # continuous
    if (data_type == "all") {
      p_violin_all = p_cont_all_all
      p_violin_top3 = p_cont_top3_all
      p_violin_baseline = p_cont_baseline_all
    } else { # primary
      p_violin_all = p_cont_all_primary
      p_violin_top3 = p_cont_top3_primary
      p_violin_baseline = p_cont_baseline_primary
    }
  }

  # Get smooth plots for all three covariate adjustment methods
  idx_all = which(plot_configs$outcome_type == outcome_type &
                    plot_configs$vs_type == "all" &
                    plot_configs$data_source == data_type &
                    plot_configs$version == "smooth_log")
  idx_top3 = which(plot_configs$outcome_type == outcome_type &
                     plot_configs$vs_type == "top3" &
                     plot_configs$data_source == data_type &
                     plot_configs$version == "smooth_log")
  idx_baseline = which(plot_configs$outcome_type == outcome_type &
                         plot_configs$vs_type == "baseline" &
                         plot_configs$data_source == data_type &
                         plot_configs$version == "smooth_log")
  
  p_smooth_all = results[[idx_all]]$plot
  p_smooth_top3 = results[[idx_top3]]$plot
  p_smooth_baseline = results[[idx_baseline]]$plot

  # Create label plots for each covariate adjustment method
  base_label_theme = theme_void() + theme(plot.margin = margin(0,0,0,0))
  
  label_all = ggplot() + 
    annotate("text", x=0, y=0, label="All covariates",
             size=8, fontface="bold", angle=90) + 
    base_label_theme
  
  label_top3 = ggplot() + 
    annotate("text", x=0, y=0, label="Top-3 covariates",
             size=8, fontface="bold", angle=90) + 
    base_label_theme
  
  label_baseline = ggplot() + 
    annotate("text", x=0, y=0, label="Baseline+ covariates",
             size=8, fontface="bold", angle=90) + 
    base_label_theme

  # Build three rows
  row1 = row_with_label(label_all, p_violin_all, p_smooth_all,
                        label_width = 0.11, left_weight = 1, right_weight = 1.00)
  row2 = row_with_label(label_top3, p_violin_top3, p_smooth_top3,
                        label_width = 0.11, left_weight = 1, right_weight = 1.00)
  row3 = row_with_label(label_baseline, p_violin_baseline, p_smooth_baseline,
                        label_width = 0.11, left_weight = 1, right_weight = 1.00)

  # Stack all three rows
  combined = row1 / row2 / row3 + plot_layout(heights = c(1, 1, 1))
  combined
}

# Configuration for 4 figures (2 outcome types × 2 data types)
fig_configs = tibble::tribble(
  ~outcome_type, ~data_type,   ~fig_name,
  "binary",      "all",        "combined_binary_all",
  "binary",      "primary",    "combined_binary_primary",
  "continuous",  "all",        "combined_continuous_all",
  "continuous",  "primary",    "combined_continuous_primary"
)

# Adjusted dimensions for 3x2 layout (taller since we have 3 rows)
combined_width = 23
combined_height = 21  # Increased height for 3 rows

for (i in 1:nrow(fig_configs)) {
  outcome = fig_configs$outcome_type[i]
  data_type = fig_configs$data_type[i]
  fig_name = fig_configs$fig_name[i]

  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  data_label = ifelse(data_type == "all", "All Outcomes", "Primary Outcomes")

  cat(sprintf("Creating figure %d/4: %s - %s...\n", i, outcome_label, data_label))

  combined_fig = create_6panel_figure(outcome, data_type)

  filename = paste0("cleaned_data/Plot/", fig_name, ".png")
  ggsave(filename, combined_fig,
         width = combined_width, height = combined_height, dpi = pub_dpi, bg = "white")

  cat(sprintf("✓ Saved: %s\n  Dimensions: %d × %d inches @ %d dpi\n\n",
              filename, combined_width, combined_height, pub_dpi))

  print(combined_fig)
}

cat("\n========================================\n")
cat("ALL 4 SIX-PANEL FIGURES CREATED AND SAVED\n")
cat("========================================\n")
cat(sprintf("• Each figure: %d × %d inches @ %d dpi\n", 
            combined_width, combined_height, pub_dpi))
cat("• Layout: Label (left) | Violin plots | Smoothed plots\n")
cat("          Row 1: All covariates\n")
cat("          Row 2: Top-3 covariates\n")
cat("          Row 3: Baseline+ covariates\n")
cat("========================================\n\n")
```

## Scaled Diff
```{r}
  # Helper to build a single row with label and two plots
  row_with_label_diff = function(label_plot, p_continuous, p_binary,
                                  label_width = 0.11,
                                  left_weight = 1,
                                  right_weight = 1) {
    (label_plot | p_continuous | p_binary) +
      plot_layout(widths = c(label_width, left_weight, right_weight))
  }
  
  create_diff_6panel_figure = function(data_type) {
    # Select the appropriate difference plots based on data_type
    if (data_type == "all") {
      p_binary_all = p_diff_binary_all_all
      p_binary_top3 = p_diff_binary_top3_all
      p_binary_baseline = p_diff_binary_baseline_all
      p_cont_all = p_diff_cont_all_all
      p_cont_top3 = p_diff_cont_top3_all
      p_cont_baseline = p_diff_cont_baseline_all
    } else { # primary
      p_binary_all = p_diff_binary_all_primary
      p_binary_top3 = p_diff_binary_top3_primary
      p_binary_baseline = p_diff_binary_baseline_primary
      p_cont_all = p_diff_cont_all_primary
      p_cont_top3 = p_diff_cont_top3_primary
      p_cont_baseline = p_diff_cont_baseline_primary
    }
    
    # Create label plots for each covariate adjustment method
    base_label_theme = theme_void() + theme(plot.margin = margin(0,0,0,0))
    
    label_all = ggplot() + 
      annotate("text", x=0, y=0, label="All covariates",
               size=8, fontface="bold", angle=90) + 
      base_label_theme
    
    label_top3 = ggplot() + 
      annotate("text", x=0, y=0, label="Top-3 covariates",
               size=8, fontface="bold", angle=90) + 
      base_label_theme
    
    label_baseline = ggplot() + 
      annotate("text", x=0, y=0, label="Baseline+ covariates",
               size=8, fontface="bold", angle=90) + 
      base_label_theme
    
    # Build three rows (label | continuous | binary)
    row1 = row_with_label_diff(label_all, p_cont_all, p_binary_all,
                                label_width = 0.11, left_weight = 1, right_weight = 1)
    row2 = row_with_label_diff(label_top3, p_cont_top3, p_binary_top3,
                                label_width = 0.11, left_weight = 1, right_weight = 1)
    row3 = row_with_label_diff(label_baseline, p_cont_baseline, p_binary_baseline,
                                label_width = 0.11, left_weight = 1, right_weight = 1)
    
    # Stack all three rows
    combined = row1 / row2 / row3 + plot_layout(heights = c(1, 1, 1))
    combined
  }
  
  # Configuration for 2 difference figures (2 data types)
  diff_fig_configs = tibble::tribble(
    ~data_type,   ~fig_name,
    "all",        "combined_diff_all",
    "primary",    "combined_diff_primary"
  )
  
  # Use same dimensions as before
  combined_width = 23
  combined_height = 21
  
  for (i in 1:nrow(diff_fig_configs)) {
    data_type = diff_fig_configs$data_type[i]
    fig_name = diff_fig_configs$fig_name[i]
    
    data_label = ifelse(data_type == "all", "All Outcomes", "Primary Outcomes")
    
    cat(sprintf("Creating difference figure %d/2: %s...\n", i, data_label))
    
    combined_fig = create_diff_6panel_figure(data_type)
    
    filename = paste0("cleaned_data/Plot/", fig_name, ".png")
    ggsave(filename, combined_fig,
           width = combined_width, height = combined_height, dpi = pub_dpi, bg = "white")
    
    cat(sprintf("✓ Saved: %s\n  Dimensions: %d × %d inches @ %d dpi\n\n",
                filename, combined_width, combined_height, pub_dpi))
    
    print(combined_fig)
  }
  
  cat("\n========================================\n")
  cat("ALL 2 DIFFERENCE SIX-PANEL FIGURES CREATED AND SAVED\n")
  cat("========================================\n")
  cat(sprintf("• Each figure: %d × %d inches @ %d dpi\n", 
              combined_width, combined_height, pub_dpi))
  cat("• Layout: Label (left) | Continuous differences | Binary differences\n")
  cat("          Row 1: All covariates\n")
  cat("          Row 2: Top-3 covariates\n")
  cat("          Row 3: Baseline+ covariates\n")
  cat("========================================\n\n")
```


# N Hist
```{r}
# Create output directory if it doesn't exist
dir.create("cleaned_data/Plot", recursive = TRUE, showWarnings = FALSE)

# Create a data frame
df = data.frame(sample_size = df_meta$'Sample Size')

# Calculate summary statistics
mean_size = mean(df$sample_size)
median_size = median(df$sample_size)
n_studies = length(df$sample_size)

###############################################################################
## Plot 1: Original Linear Scale Histogram
###############################################################################

p = ggplot(df, aes(x = sample_size)) +
  geom_histogram(bins = 30, 
                 fill = "#4CAF50", 
                 color = "white", 
                 alpha = 0.8,
                 boundary = 0) +
  geom_vline(aes(xintercept = mean_size), 
             color = "#FF5722", 
             linetype = "dashed", 
             linewidth = 1.2,
             alpha = 0.8) +
  geom_vline(aes(xintercept = median_size), 
             color = "#2196F3", 
             linetype = "dotted", 
             linewidth = 1.2,
             alpha = 0.8) +
  labs(x = "Sample Size",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p)
# ggsave("cleaned_data/Plot/sample_size_linear.png", p, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 2: Custom Bins (RECOMMENDED for skewed data)
###############################################################################

# Create custom bins with wider intervals for larger values
df_binned = df %>%
  mutate(
    size_category = cut(sample_size, 
                       breaks = c(0, 50, 100, 200, 500, 1000, Inf),
                       labels = c("0-50", "51-100", "101-200", 
                                 "201-500", "501-1000", "1000+"),
                       include.lowest = TRUE)
  )

# Count by category
bin_summary = df_binned %>%
  count(size_category) %>%
  mutate(percentage = round(n/sum(n)*100, 1))

p_custom = ggplot(df_binned, aes(x = size_category)) +
  geom_bar(fill = "#4CAF50", alpha = 0.8, color = "white") +
  geom_text(stat = "count", aes(label = after_stat(count)), 
            vjust = -0.5, size = 5, fontface = "bold") +
  labs(x = "Sample Size Range",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    axis.text.x = element_text(angle = 0),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.1, 0))

print(p_custom)
ggsave("cleaned_data/Plot/sample_size_custom_bins.png", p_custom, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 3: Square Root Transformation
###############################################################################

p_sqrt = ggplot(df, aes(x = sqrt(sample_size))) +
  geom_histogram(bins = 20, 
                 fill = "#FF9800", 
                 color = "white", 
                 alpha = 0.8) +
  scale_x_continuous(
    breaks = sqrt(c(0, 100, 500, 1000, 2000, 4000, 6000)),
    labels = scales::comma_format()(c(0, 100, 500, 1000, 2000, 4000, 6000))
  ) +
  labs(x = "Sample Size (√ scale)",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p_sqrt)
# ggsave("cleaned_data/Plot/sample_size_sqrt.png", p_sqrt, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 4: Log-Transformed Distribution
###############################################################################

p_log = ggplot(df, aes(x = log10(sample_size))) +
  geom_histogram(bins = 25, 
                 fill = "#9C27B0", 
                 color = "white", 
                 alpha = 0.8) +
  labs(x = "Log10(Sample Size)",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p_log)
# ggsave("cleaned_data/Plot/sample_size_log.png", p_log, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Additional Analysis: Categorize Studies by Size
###############################################################################

df = df %>%
  mutate(size_category_detailed = case_when(
    sample_size < 100 ~ "Small (< 100)",
    sample_size >= 100 & sample_size < 500 ~ "Medium (100-499)",
    sample_size >= 500 & sample_size < 1000 ~ "Large (500-999)",
    sample_size >= 1000 ~ "Very Large (≥ 1000)"
  ))

# Print summary
cat("\n========================================\n")
cat("Sample Size Summary Statistics\n")
cat("========================================\n")
print(summary(df$sample_size))

cat("\n\nDistribution by Size Category:\n")
category_summary = df %>%
  count(size_category_detailed) %>%
  mutate(percentage = round(n/sum(n)*100, 1))
print(category_summary)

cat("\n\nDistribution by Custom Bins:\n")
print(bin_summary)

cat("\n========================================\n")
cat("All plots saved to cleaned_data/Plot/\n")
cat("========================================\n")
```

# Pub Hist
```{r}
###############################################################################
##  Publication Year Histogram
###############################################################################
# Prepare data
df_pub_year = data.frame(
  pub_year = df_meta$PublicationYear
) %>%
  filter(!is.na(pub_year))

# Create histogram
p_pub_year = ggplot(df_pub_year, aes(x = pub_year)) +
  geom_histogram(binwidth = 1, fill = "#2196F3", color = "white", alpha = 0.8) +
  labs(x = "Publication Year",
       y = "Number of Trials") +
  theme_minimal(base_size = 18) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(breaks = seq(1940, 2030, by = 5)) +
  scale_y_continuous(breaks = function(x) seq(0, ceiling(max(x)), by = 2))

# Display and save
print(p_pub_year)
ggsave("cleaned_data/Plot/publication_year_histogram.png", p_pub_year, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Summary Statistics
###############################################################################
cat("\n=== Publication Year Summary ===\n")
cat("Number of trials:", nrow(df_pub_year), "\n")
cat("Year range:", min(df_pub_year$pub_year), "-", max(df_pub_year$pub_year), "\n")
cat("\nYear Distribution:\n")
print(summary(df_pub_year$pub_year))
cat("\nTrials per decade:\n")
df_pub_year %>%
  mutate(decade = floor(pub_year / 10) * 10) %>%
  count(decade) %>%
  arrange(decade) %>%
  print()
cat("\nPlot saved to cleaned_data/Plot/publication_year_histogram.png\n")
```




# N. Cova vs N Plot
```{r}
###############################################################################
##  Covariates vs Sample Size - Scatter Plots Only
###############################################################################
# Prepare data: get mean covariates per trial and merge with sample size
df_cov_summary = df_comparison %>% 
  group_by(Trial_No) %>% 
  summarise(mean_covariates = round(mean(N_Covariates, na.rm = TRUE)), 
            .groups = 'drop')

# Merge with sample size data from df_meta (using Trial_ID)
df_cov_size = df_meta %>%
  select(Trial_ID, Sample_Size = `Sample Size`) %>%
  inner_join(df_cov_summary, by = c("Trial_ID" = "Trial_No")) %>%
  filter(!is.na(Sample_Size), !is.na(mean_covariates))

# Calculate correlation
correlation = cor(df_cov_size$Sample_Size, df_cov_size$mean_covariates, 
                  use = "complete.obs")

###############################################################################
## Original Scale Version (Scatter Only)
###############################################################################
p_cov_size = ggplot(df_cov_size, aes(x = Sample_Size, y = mean_covariates)) +
  geom_point(alpha = 0.6, size = 3, color = "#2196F3") +
  labs(x = "Sample Size",
       y = "Average Number of Covariates") +
  theme_minimal(base_size = 18) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(labels = scales::comma_format())

# Display and save
print(p_cov_size)
ggsave("cleaned_data/Plot/covariates_vs_sample_size.png", p_cov_size, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Log10 Version (Scatter with reference curves)
###############################################################################
# Get the y-axis range from the original plot
y_range = range(df_cov_size$mean_covariates, na.rm = TRUE)

# Get the range for reference curves
log_sample_size_range = range(log10(df_cov_size$Sample_Size), na.rm = TRUE)
log_x_seq = seq(log_sample_size_range[1], log_sample_size_range[2], length.out = 200)

# Create reference curve data
ref_curve1 = data.frame(log_x = log_x_seq, y = 10^log_x_seq)
ref_curve2 = data.frame(log_x = log_x_seq, y = 10^log_x_seq / 5)

# Filter curves to stay within y-axis range
ref_curve1 = ref_curve1 %>% filter(y >= y_range[1], y <= y_range[2])
ref_curve2 = ref_curve2 %>% filter(y >= y_range[1], y <= y_range[2])

# Find good positions for labels (around 75% along each curve)
label_pos1 = ref_curve1[round(nrow(ref_curve1) * 0.75), ]
label_pos2 = ref_curve2[round(nrow(ref_curve2) * 0.75), ]

p_cov_size_log = ggplot(df_cov_size, aes(x = log10(Sample_Size), y = mean_covariates)) +
  geom_point(alpha = 0.6, size = 3, color = "#2196F3") +
  geom_line(data = ref_curve1, 
            aes(x = log_x, y = y),
            color = "#E91E63", 
            linewidth = 1,
            inherit.aes = FALSE) +
  geom_line(data = ref_curve2, 
            aes(x = log_x, y = y),
            color = "#FF9800", 
            linewidth = 1,
            inherit.aes = FALSE) +
  annotate("text", x = label_pos1$log_x, y = label_pos1$y, 
           label = "n = p", color = "#E91E63", size = 5, fontface = "bold",
           hjust = -0.2, vjust = -0.5) +
  annotate("text", x = label_pos2$log_x, y = label_pos2$y, 
           label = "n = 5p", color = "#FF9800", size = 5, fontface = "bold",
           hjust = -0.2, vjust = 1.5) +
  labs(x = "Log10(Sample Size)",
       y = "Average Number of Covariates") +
  coord_cartesian(ylim = y_range) +
  theme_minimal(base_size = 18) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  )

# Display and save log version
print(p_cov_size_log)
ggsave("cleaned_data/Plot/covariates_vs_sample_size_log.png", p_cov_size_log, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Summary Statistics
###############################################################################
cat("\n=== Covariates vs Sample Size Summary ===\n")
cat("Number of trials:", nrow(df_cov_size), "\n")
cat("Correlation coefficient:", round(correlation, 3), "\n")
cat("\nSample Size Summary:\n")
print(summary(df_cov_size$Sample_Size))
cat("\nNumber of Covariates Summary:\n")
print(summary(df_cov_size$mean_covariates))
cat("\nBoth plots saved to cleaned_data/Plot/\n")
cat("  - covariates_vs_sample_size.png (original scale)\n")
cat("  - covariates_vs_sample_size_log.png (log10 scale with reference curves)\n")
cat("\nReference curves on log plot:\n")
cat("  - n = p (pink): Sample size equals number of covariates\n")
cat("  - n = 5p (orange): Sample size equals 5 times number of covariates\n")
```


# Research Area Pie Chart
```{r}
# Consolidate similar research areas
df_meta_consolidated <- df_meta %>%
  mutate(Research_Area_Consolidated = case_when(
    `Research Area` %in% c("Anesthesiology") ~ "Anesthesiology",
    `Research Area` %in% c("HIV") ~ "HIV/AIDS",
    `Research Area` %in% c("Maternal and Child Health", "Obstetrics", "Neonatology") ~ "Maternal & Child Health",
    `Research Area` %in% c("Neurology", "Neuropsychology") ~ "Neurology",
    `Research Area` %in% c("COVID-19", "Tuberculosis", "Vaccinology") ~ "Infectious Disease",
    `Research Area` %in% c("Mental Health", "Addiction Medicine") ~ "Mental Health",
    `Research Area` %in% c("Cardiovascular Disease", "Hypertension") ~ "Cardiovascular",
    TRUE ~ `Research Area`
  ))

# Count and prepare data
area_counts <- df_meta_consolidated %>%
  count(Research_Area_Consolidated) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    label = ifelse(percentage > 3, 
                   paste0(Research_Area_Consolidated, "\n(", n, ")"),
                   "")
  )

# Plot research area pie chart
p2 <- ggplot(area_counts, 
             aes(x = "", y = n, fill = Research_Area_Consolidated)) +
  geom_bar(stat = "identity", width = 1, color = "white", linewidth = 0.5) +
  coord_polar("y", start = 0) +
  scale_fill_viridis_d(option = "turbo") +
  theme_void() +
  theme(
    legend.title = element_text(size = 20, face = "bold"),
    legend.text = element_text(size = 18),
    legend.position = "right"
  ) +
  labs(fill = "Research Area") +
  geom_text(aes(label = ifelse(n >= 3, n, "")), 
            position = position_stack(vjust = 0.5),
            color = "white", size = 3.5, fontface = "bold")

# Display and save
print(p2)
ggsave("cleaned_data/Plot/research_area_pie.png", p2, 
       width = 10, height = 6, dpi = 600, bg = "white")

# Print summary
cat("\n=== Research Area Summary ===\n")
print(area_counts %>% select(-label))
```

# Rand Scheme Pie Chart 
```{r}
# Count and prepare data for Randomization Scheme
randomization_counts <- df_meta %>%
  # Combine Stratified and Stratified Block into Stratified
  mutate(`Randomization Scheme(High Level)` = case_when(
    `Randomization Scheme(High Level)` %in% c("Stratified", "Stratified Block") ~ "Stratified",
    TRUE ~ `Randomization Scheme(High Level)`
  )) %>%
  count(`Randomization Scheme(High Level)`) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    label = paste0(`Randomization Scheme(High Level)`, "\n(", n, ", ", round(percentage, 1), "%)")
  )

# Create color palette with updated categories
rand_colors <- c(
  "Stratified" = "#E41A1C",
  "Simple" = "#377EB8", 
  "Block" = "#4DAF4A",
  "Stratified Rerandomization" = "#FF7F00",
  "Biased Coin" = "#FFFF33"
)

# Plot randomization scheme pie chart
p1 <- ggplot(randomization_counts, 
             aes(x = "", y = n, fill = `Randomization Scheme(High Level)`)) +
  geom_bar(stat = "identity", width = 1, color = "white", linewidth = 0.5) +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = rand_colors) +
  theme_void() +
  theme(
    legend.title = element_text(size = 20, face = "bold"),
    legend.text = element_text(size = 18),
    legend.position = "right"
  ) +
  labs(fill = "Randomization Scheme") +
  geom_text(aes(label = n), 
            position = position_stack(vjust = 0.5),
            color = "white", size = 4, fontface = "bold")

# Display and save
print(p1)
ggsave("cleaned_data/Plot/randomization_scheme_pie.png", p1, 
       width = 8, height = 5, dpi = 600, bg = "white")

# Print summary
cat("\n=== Randomization Scheme Summary ===\n")
print(randomization_counts %>% select(-label))
```



# Processing Flowchart
```{r}
flowchart = grViz("
digraph data_curation {
  # ==== GLOBAL GRAPH SETTINGS ====
  graph [layout = dot, rankdir = TB, fontname = Helvetica, ranksep = 1.2, nodesep = 0.5]
  node  [shape = rectangle, style = filled, fontname = Helvetica, fontsize = 12, height = 1.2, width = 2.5]
  edge  [penwidth = 1.5]
  
  # ================== ROW 1: Left → Right (LIGHTBLUE) ==================
  {
    rank = same;
    
    search [label = 'Search Public Databases\\nKeywords: randomized controlled trial,\\nrandomized trial,\\nrandomized clinical trial',
            fillcolor = lightblue]
    
    databases [label = 'Databases:\\n• Dryad\\n• Harvard Dataverse\\n• Zenodo\\n\\nR Packages (CRAN)', 
               fillcolor = lightblue]
    
    criteria [label = 'Selection Criteria:\\n• Clear data dictionary\\n• Key variables present\\n• Published paper available\\n• Confirmed RCT design', 
              fillcolor = lightblue]
    
    datasets [label = '50 RCT Datasets:\\n• 38 from Dryad\\n• 2 from Harvard Dataverse\\n• 2 from Zenodo \\n• 8 from R packages', 
              fillcolor = lightblue]
  }
  
  # Row 1 connections (left to right)
  search -> databases -> criteria -> datasets
  
  # ================== ROW 2: Right → Left (LIGHTCORAL) ==================
  {
    rank = same;
    
    cleaning_start [label = 'Data Cleaning Process', 
                    fillcolor = lightcoral]
    
    extract [label = 'Extract Variables:\\n• Baseline covariates\\n• Treatment assignment\\n• Primary outcomes\\n• Secondary outcomes', 
             fillcolor = lightcoral]
    
    missing_std [label = 'Standardize Missing Values:\\nRename all to NA', 
                 fillcolor = lightcoral]
    
    reshape [label = 'Reshape Data:\\nConvert to wide format', 
             fillcolor = lightcoral]
  }
  
  # Row 2 connections (right to left)
  reshape -> missing_std -> extract -> cleaning_start [dir = back]
  
  # ================== ROW 3: Left → Right (PEACH) ==================
  {
    rank = same;
    
    missing_start [label = 'Missing Data Handling', 
                   fillcolor = '#FFE4B5']
    
    outcome_filter [label = 'Filter Outcomes:\\nRemove outcomes with\\nmissingness > 40%', 
                    fillcolor = '#FFE4B5']
    
    patient_filter [label = 'Remove Patients:\\nExclude patients with\\nmissing outcome values', 
                    fillcolor = '#FFE4B5']
    
    covariate_impute [label = 'Impute Covariates:\\n• Continuous → Mean imputation\\n• Categorical → Mode imputation', 
                      fillcolor = '#FFE4B5']
  }
  
  # Row 3 connections (left to right)
  missing_start -> outcome_filter -> patient_filter -> covariate_impute
  
  # ================== VERTICAL CONNECTIONS ==================
  # Row 1 to Row 2 (datasets → cleaning_start with arrow)
  datasets -> cleaning_start [weight = 0]
  
  # Row 2 to Row 3 (reshape → missing_start with arrow)
  reshape -> missing_start [weight = 0]
}
")

# Display
flowchart

# Save to file

flowchart %>%
  export_svg() %>%
  charToRaw() %>%
  rsvg_png("cleaned_data/Plot/data_curation_flowchart.png", width = 4800, height = 2400)

cat('Flowchart saved to cleaned_data/Plot/data_curation_flowchart.png\n')

```

# Error Rate
## TMLE
```{r}
###############################################################################
##  ERROR RATE AND MEAN/MEDIAN VARIANCE REDUCTION FOR INDIVIDUAL SL METHODS --
###############################################################################
# Individual SL methods (All covariates - base versions only, no VS1 or VS2)
individual_sl_methods = c("SL_glm", "SL_glmnet", "SL_rpart", "SL_gam", "SL_nnet", 
                          "SL_svm", "SL_xgboost","SL_bartMachine", "SL_randomForest")

###############################################################################
##  Function to calculate error rate and mean/median variance reduction -------
###############################################################################
calculate_sl_stats = function(data, outcome_type) {
  
  # Filter by outcome type
  if (outcome_type == "continuous") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("continuous", "continuous proportion"))
  } else if (outcome_type == "binary") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("binary", "composite binary"))
  }
  
  # Initialize results dataframe
  results = data.frame(
    method = character(),
    error_rate = numeric(),
    mean_variance_reduction = numeric(),
    median_variance_reduction = numeric(),  # Added median column
    n_total = integer(),
    n_valid = integer(),
    n_na = integer(),
    stringsAsFactors = FALSE
  )
  
  # Loop through each individual SL method
  for (method in individual_sl_methods) {
    # Get the precision gain column name for this method (base version only)
    pg_col = paste0("How much precision gain can ", method, "_TMLE provide?")
    
    # Check if column exists
    if (pg_col %in% colnames(data_filtered)) {
      
      # Extract precision gain values
      pg_values = data_filtered[[pg_col]]
      
      # Calculate statistics
      n_total = length(pg_values)
      n_na = sum(is.na(pg_values))
      error_rate = n_na / n_total
      n_valid = n_total - n_na
      
      # Calculate mean and median variance reduction (1 - precision_gain), excluding NA
      if (n_valid > 0) {
        var_reduction = 1 - pg_values
        mean_var_reduction = mean(var_reduction, na.rm = TRUE)
        median_var_reduction = median(var_reduction, na.rm = TRUE)  # Calculate median
      } else {
        mean_var_reduction = NA
        median_var_reduction = NA
      }
      
      # Add to results
      results = rbind(results, data.frame(
        method = method,
        error_rate = error_rate,
        mean_variance_reduction = mean_var_reduction,
        median_variance_reduction = median_var_reduction,  # Add median to results
        n_total = n_total,
        n_valid = n_valid,
        n_na = n_na,
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Round numeric columns for better display
  results = results %>%
    mutate(
      error_rate = round(error_rate, 2),
      mean_variance_reduction = round(mean_variance_reduction, 4),
      median_variance_reduction = round(median_variance_reduction, 4)  # Round median
    )
  
  return(results)
}


###############################################################################
##  Calculate and display results with enhanced formatting -------------------
###############################################################################
# Binary outcomes - All outcomes
cat("\n========================================\n")
cat("BINARY OUTCOMES - ALL OUTCOMES\n")
cat("Individual SL Methods (All Covariates)\n")
cat("========================================\n\n")

binary_all_sl_stats = calculate_sl_stats(df_comparison, "binary")
# Display with desired column order
print(binary_all_sl_stats[, c("method", "error_rate", "mean_variance_reduction", 
                                "median_variance_reduction", "n_total", "n_valid", "n_na")])

# Continuous outcomes - All outcomes
cat("\n========================================\n")
cat("CONTINUOUS OUTCOMES - ALL OUTCOMES\n")
cat("Individual SL Methods (All Covariates)\n")
cat("========================================\n\n")

continuous_all_sl_stats = calculate_sl_stats(df_comparison, "continuous")
# Display with desired column order
print(continuous_all_sl_stats[, c("method", "error_rate", "mean_variance_reduction", 
                                   "median_variance_reduction", "n_total", "n_valid", "n_na")])
```

## AIPW
```{r}
###############################################################################
##  ERROR RATE AND MEAN/MEDIAN VARIANCE REDUCTION FOR INDIVIDUAL SL METHODS --
###############################################################################
# Individual SL methods (All covariates - base versions only, no VS1 or VS2)
individual_sl_methods = c("SL_glm", "SL_glmnet", "SL_rpart", "SL_gam", "SL_nnet", 
                          "SL_svm", "SL_xgboost","SL_bartMachine", "SL_randomForest")

###############################################################################
##  Function to calculate error rate and mean/median variance reduction -------
###############################################################################
calculate_sl_stats = function(data, outcome_type) {
  
  # Filter by outcome type
  if (outcome_type == "continuous") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("continuous", "continuous proportion"))
  } else if (outcome_type == "binary") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("binary", "composite binary"))
  }
  
  # Initialize results dataframe
  results = data.frame(
    method = character(),
    error_rate = numeric(),
    mean_variance_reduction = numeric(),
    median_variance_reduction = numeric(),  # Added median column
    n_total = integer(),
    n_valid = integer(),
    n_na = integer(),
    stringsAsFactors = FALSE
  )
  
  # Loop through each individual SL method
  for (method in individual_sl_methods) {
    # Get the precision gain column name for this method (base version only)
    pg_col = paste0("How much precision gain can ", method, "_AIPW provide?")
    
    # Check if column exists
    if (pg_col %in% colnames(data_filtered)) {
      
      # Extract precision gain values
      pg_values = data_filtered[[pg_col]]
      
      # Calculate statistics
      n_total = length(pg_values)
      n_na = sum(is.na(pg_values))
      error_rate = n_na / n_total
      n_valid = n_total - n_na
      
      # Calculate mean and median variance reduction (1 - precision_gain), excluding NA
      if (n_valid > 0) {
        var_reduction = 1 - pg_values
        mean_var_reduction = mean(var_reduction, na.rm = TRUE)
        median_var_reduction = median(var_reduction, na.rm = TRUE)  # Calculate median
      } else {
        mean_var_reduction = NA
        median_var_reduction = NA
      }
      
      # Add to results
      results = rbind(results, data.frame(
        method = method,
        error_rate = error_rate,
        mean_variance_reduction = mean_var_reduction,
        median_variance_reduction = median_var_reduction,  # Add median to results
        n_total = n_total,
        n_valid = n_valid,
        n_na = n_na,
        stringsAsFactors = FALSE
      ))
    }
  }
  
  # Round numeric columns for better display
  results = results %>%
    mutate(
      error_rate = round(error_rate, 2),
      mean_variance_reduction = round(mean_variance_reduction, 4),
      median_variance_reduction = round(median_variance_reduction, 4)  # Round median
    )
  
  return(results)
}


###############################################################################
##  Calculate and display results with enhanced formatting -------------------
###############################################################################
# Binary outcomes - All outcomes
cat("\n========================================\n")
cat("BINARY OUTCOMES - ALL OUTCOMES\n")
cat("Individual SL Methods (All Covariates)\n")
cat("========================================\n\n")

binary_all_sl_stats = calculate_sl_stats(df_comparison, "binary")
# Display with desired column order
print(binary_all_sl_stats[, c("method", "error_rate", "mean_variance_reduction", 
                                "median_variance_reduction", "n_total", "n_valid", "n_na")])

# Continuous outcomes - All outcomes
cat("\n========================================\n")
cat("CONTINUOUS OUTCOMES - ALL OUTCOMES\n")
cat("Individual SL Methods (All Covariates)\n")
cat("========================================\n\n")

continuous_all_sl_stats = calculate_sl_stats(df_comparison, "continuous")
# Display with desired column order
print(continuous_all_sl_stats[, c("method", "error_rate", "mean_variance_reduction", 
                                   "median_variance_reduction", "n_total", "n_valid", "n_na")])
```


# CAG & CAL
```{r}
###############################################################################
##  CAG AND CAL CALCULATION --------------------------------------------------
###############################################################################

# Function to calculate CAG and CAL for a given method and outcome type
calculate_cag_cal = function(data, outcome_type, method_name, adjustment_type = "All") {
  
  # Filter by outcome type
  if (outcome_type == "continuous") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("continuous", "continuous proportion"))
  } else if (outcome_type == "binary") {
    data_filtered = data %>%
      filter(`Outcome Type` %in% c("binary", "composite binary"))
  }
  
  # Construct column names based on adjustment type
  if (adjustment_type == "All") {
    pval_col = paste0(method_name, "_pval")
  } else if (adjustment_type == "Top-3") {
    pval_col = paste0(method_name, "_VS1_pval")
  } else if (adjustment_type == "Baseline+") {
    pval_col = paste0(method_name, "_VS2_pval")
  }
  
  # Check if columns exist
  if (!("Unadjust_pval" %in% colnames(data_filtered)) || 
      !(pval_col %in% colnames(data_filtered))) {
    return(list(CAG = NA, CAL = NA))
  }
  
  # Get p-values
  unadjust_pval = data_filtered$Unadjust_pval
  adjusted_pval = data_filtered[[pval_col]]
  
  # Filter to cases where both p-values are non-NA
  valid_cases = !is.na(unadjust_pval) & !is.na(adjusted_pval)
  unadjust_pval = unadjust_pval[valid_cases]
  adjusted_pval = adjusted_pval[valid_cases]
  
  # Calculate CAG: unadjusted is NOT significant (>= 0.05) AND adjusted IS significant (< 0.05)
  cag_cases = (unadjust_pval >= 0.05) & (adjusted_pval < 0.05)
  cag_count = sum(cag_cases)
  cag_probability = cag_count / length(unadjust_pval)  # as proportion
  
  # Calculate CAL: unadjusted IS significant (< 0.05) AND adjusted is NOT significant (>= 0.05)
  cal_cases = (unadjust_pval < 0.05) & (adjusted_pval >= 0.05)
  cal_count = sum(cal_cases)
  cal_probability = cal_count / length(unadjust_pval)  # as proportion
  
  return(list(CAG = cag_probability, CAL = cal_probability))
}

###############################################################################
##  Build the complete table ------------------------------------------------
###############################################################################

# Define methods and their names in the data
methods = data.frame(
  display_name = c("ANCOVA", "ANHECOVA", "IPW", "G-Logistic", "DML", "TMLE"),
  data_name = c("ANCOVA", "ANHECOVA", "IPW", "Logistic G-Computation", "DML", "TMLE"),
  stringsAsFactors = FALSE
)

# Define adjustment types
adjustment_types = c("All", "Top-3", "Baseline+")

# Initialize results dataframe
results = data.frame(
  Method = character(),
  `Covariate selection` = character(),
  Continuous_CAG = numeric(),
  Continuous_CAL = numeric(),
  Binary_CAG = numeric(),
  Binary_CAL = numeric(),
  stringsAsFactors = FALSE,
  check.names = FALSE
)

# Loop through methods and adjustment types
for (i in 1:nrow(methods)) {
  method_display = methods$display_name[i]
  method_data = methods$data_name[i]
  
  for (adj_type in adjustment_types) {
    # Calculate for continuous outcomes
    cont_results = calculate_cag_cal(df_comparison, "continuous", method_data, adj_type)
    
    # Calculate for binary outcomes
    binary_results = calculate_cag_cal(df_comparison, "binary", method_data, adj_type)
    
    # Add to results
    results = rbind(results, data.frame(
      Method = method_display,
      `Covariate selection` = adj_type,
      Continuous_CAG = cont_results$CAG,
      Continuous_CAL = cont_results$CAL,
      Binary_CAG = binary_results$CAG,
      Binary_CAL = binary_results$CAL,
      stringsAsFactors = FALSE,
      check.names = FALSE
    ))
  }
}

# Round to 2 decimal places
results = results %>%
  mutate(
    Continuous_CAG = round(Continuous_CAG, 2),
    Continuous_CAL = round(Continuous_CAL, 2),
    Binary_CAG = round(Binary_CAG, 2),
    Binary_CAL = round(Binary_CAL, 2)
  )

# Print the table
cat("\n========================================\n")
cat("CAG AND CAL TABLE\n")
cat("Values are proportions (not percentages)\n")
cat("========================================\n\n")
print(results)

# Optional: Create a more formatted version for display
results_formatted = results %>%
  mutate(
    `Continuous outcome` = paste0(sprintf("%.2f", Continuous_CAG), " / ", 
                                   sprintf("%.2f", Continuous_CAL)),
    `Binary outcome` = paste0(sprintf("%.2f", Binary_CAG), " / ", 
                              sprintf("%.2f", Binary_CAL))
  ) %>%
  select(Method, `Covariate selection`, `Continuous outcome`, `Binary outcome`)

cat("\n========================================\n")
cat("CAG AND CAL TABLE (FORMATTED)\n")
cat("CAG / CAL format (proportions)\n")
cat("========================================\n\n")
print(results_formatted)
```


